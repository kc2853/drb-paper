%!TEX root = main.tex

\iffalse
\subsection{Public Verifiability}
\label{appendix:pv}
Public verifiability of a DRB can be defined by the following game. Suppose the advantage of $\adv$ is given by
\[
\left\lvert 1 - Pr\left[b = b' \middle\vert \begin{array}{l}
y_0 = \drboutput_\epochv;\\
y_1 \gets \adv(priv_\epochv, pub_\epochv);\\
b \gets \{0, 1\};\\
b' \gets \mathcal{V}(y_b, pub_\epochv)
\end{array}\right]
\right\rvert
\]
where the protocol runs among honest participants and $\adv$ (which has access to private information $priv_\epochv$ in \epoch $\epochv$ as a $t$-limited participant), $pub_\epochv$ denotes public information emitted in \epoch $\epochv$, and $\mathcal{V}$ is a third party verifier. Then this advantage is negligible such that $\adv$ cannot fool $\mathcal{V}$ into accepting $\tilde{\drboutput_\epochv} \neq \drboutput_\epochv$ as a valid DRB output.
\fi

% \iffalse
% \section{Verifiable Delay Function (VDF)}
% \label{appendix:vdf}

% A VDF must satisfy the following three properties:
% \begin{itemize}
% \item $\epsilon$-evaluation time. $\mathsf{Eval}(pp, x)$ runs in time at most $(1 + \epsilon) T$, for all $x$ and all $pp$ output by $\mathsf{Setup}(\lambda, T)$.
% \item Sequentiality. A parallel algorithm $\adv$, using at most $poly(\lambda)$ processors, that runs in time less than $T$ cannot compute the function. Specifically, for a random $x$ and $pp$ output by $\mathsf{Setup}(\lambda, T)$, if $(y, \pi) = \mathsf{Eval}(pp, x)$ then $Pr[\adv(pp, x) = y]$ is $\negl(\lambda)$.
% \item Uniqueness. For an input $x$ and $T$, exactly one $y$ will be accepted by $\mathsf{Verify}$ with negligible error probability. Specifically, let $\adv$ be an efficient algorithm that given $pp$ as input, outputs $(x, y, \pi)$ such that $\mathsf{Verify}(pp, x, y, \pi) = 1$. Then $Pr[\mathsf{Eval}(pp, x) \neq y]$ is $\negl(\lambda)$.
% \end{itemize}
% For sequentiality, computing $y$ using $\mathsf{Eval}(pp,x)$ requires $T$ sequential squarings even on a parallel computer with $poly(\lambda)$ processors. Computing proof $\pi$ increases the running time to $(1+\epsilon)T$ as needed for $\epsilon$-evaluation time.

% Pietrzak's~\cite{pietrzak2018simple} and Wesolowski's~\cite{wesolowski2019efficient} proposals differ in the way $\pi$ is generated and verified. Both proof systems have their own strengths. Wesolowski's proof system generates a shorter proof (1 group element versus $\log T$ elements) and enjoys better verifier complexity (2 exponentiations versus $2 \log T$). Pietrzak's proof system enjoys better prover complexity requiring $O(\sqrt{T})$ group operations as opposed to Wesolowski's $O(T)$.

% \subsection{Trapdoor VDF}
% \label{appendix:tvdf}
% Trapdoor VDFs~\cite{wesolowski2019efficient, schindler2021randrunner} are an extension and modification of traditional VDFs in which the $\mathsf{Setup}$ algorithm in addition to the public parameters $pp$ also outputs a trapdoor (secret key) $sk$ to the participant invoking the algorithm. The parameter $pp$ is published whereas $sk$ is kept secret. Furthermore, the algorithm $\mathsf{TrapdoorEval}$ provides an alternate way to evaluate the VDF efficiently, i.e. within time $\phi{(poly{(\lambda)})}$ to participants which know the trapdoor $sk$. Participants without this knowledge can still use the $\mathsf{Eval}$ algorithm to compute the output in $(1+\epsilon)T$ sequential steps.
% Trapdoor VDFs can be described by a set of four algorithms as follows.
% \begin{itemize}
%     \item $\mathsf{Setup}(\lambda, T) \rightarrow (pp, sk)$ is a randomized algorithm that takes a security parameter $\lambda$ and a delay parameter $T$ and outputs public parameters $pp$ and a trapdoor secret key $sk$.
%     \item $\mathsf{VerifySetup}(\lambda, pp) \rightarrow \{0, 1\}$ returns 1 if the validity of $pp$ can be successfully checked, returns 0 otherwise.
%     \item $\mathsf{Eval}(pp, x) \rightarrow (y, \pi)$ takes an input $x$ along with the public parameters $pp$ and outputs $y$ and a proof $\pi$.
%     \item $\mathsf{TrapdoorEval}(pp, x, sk) \rightarrow (y, \pi)$ takes an input $x$ and $pp$ along with trapdoor $sk$ and outputs $y$ and a proof $\pi$ such that the algorithm takes less than time $T$ to complete unlike $\mathsf{Eval}$.
%     \item $\mathsf{Verify}(pp, x, y, \pi) \rightarrow \{0, 1\}$ outputs 1 if $y$ is the correct evaluation of the VDF on input $x$ and $T$.
% \end{itemize}

% Due to the introduction of trapdoors and strong uniqueness, in contrast to traditional VDFs, trapdoor-VDF must satisfy the following properties:

% \begin{itemize}
%     \item $\epsilon$-evaluation time. $\mathsf{Eval}(pp, x)$ runs in time at most $(1 + \epsilon) T$, for all $x$ and all $pp$ output by $\mathsf{Setup}(\lambda)$.
%     \item Sequentiality without trapdoor. A parallel algorithm $\adv$, using at most $poly(\lambda)$ processors, that runs in time less than $T$ cannot compute the function without the knowledge of a secret trapdoor. Specifically, for a random $x$ and all $pp$ output by $\mathsf{Setup}(\lambda, T)$, if $(y, \pi)$ is the output of $\mathsf{Eval}(pp, x)$ or $\mathsf{TrapdoorEval}(pp, x, sk)$, then the probability that $\adv$ can compute $y$ in less than $T$ steps is negligible.
%     \item Strong uniqueness. For each input $x$ and all public parameters $pp$, exactly one $y$ will be accepted by $\mathsf{Verify}$ with negligible error probability even if the public parameters have been adversarially generated. Specifically, let $\adv$ be an efficient algorithm that outputs $(pp, x, y, \pi)$ such that $\mathsf{Verify}(pp, x, y, \pi) = 1$. Then $Pr[\mathsf{Eval}(pp, x) \neq y]$ is negligible.
% \end{itemize}
% \fi

% \iffalse
\subsection{Verifiable Secret Sharing (VSS)}
\label{appendix:vss}

VSS schemes have two security requirements.
\begin{itemize}
    \item Secrecy. If the dealer is honest, then the probability of an adversary learning
    any information about the dealer's secret in the sharing phase is $\negl(\lambda)$.
    \item Correctness. If the dealer is honest, then the honest nodes output the secret
    $s$ at the end of the reconstruction phase with a high probability of $1 - \negl(\lambda)$.
\end{itemize}
Feldman-VSS~\cite{feldman1987practical} and Pedersen-VSS~\cite{pedersen1991non} are the most commonly used VSS schemes.\\\\
\noindent\textbf{Feldman-VSS.}
\label{appendix:feldmanVSS}
The following summarizes a simple VSS scheme proposed by Paul Feldman for sharing a secret $s$ among $n$ participants where any subset of $t + 1$ among them can reconstruct the group secret.

\begin{itemize}
\item $\mathsf{ShareGen}(s) \rightarrow (\{s_i\}, C)$ with $s \in \groupZ_q$ involves the dealer sampling $t$ random coefficients $a_1, \ldots, a_t \in \groupZ_q$ and constructing $p(x) = s + a_1x+ a_2x^2 +\ldots+a_tx^t$. The shares are computed as $s_i = p(i)$ in mod $q$ for $1\le i \le n$ and shared privately with each participant. The commitments to the secret $C_0 = g^s$ as well as coefficients $C_j = g^{a_j}$ for $j = 1,\ldots,t$ are also broadcast by the dealer.
\item $\mathsf{ShareVerify}(s_i, C) \rightarrow \{0, 1\}$ involves each participant $P_i$ checking if:
$$g^{s_i} = \prod_{j = 0}^{t} C_j^{i^j} = C_0 C_1^i C_2^{i^2} \cdots C_{t}^{i^{t}}$$
If it does not hold for some $i$, then $P_i$ broadcasts an accusation against the dealer, who has to respond by broadcasting the correct $s_i$. Correct reconstruction is achieved by filtering out shares that do not satisfy $\mathsf{ShareVerify}$.
\item $\mathsf{Recon}(A, \{s_i\}_{i \in A}) \rightarrow s$ outputs the secret $s$ by performing Lagrange interpolation (see Appendix~\ref{appendix:lagrange}) with $t + 1$ valid shares from the reconstruction set $A$ of nodes:
$$s = p(0) = \sum_{j \in A} p(j) \lambda_{0, j, A}$$
\end{itemize}

The verifiability in Feldman-VSS comes from inclusion of commitments to the coefficients. These commitments enable participants to verify the validity of the shares that they receive from the dealer.
% \fi

% \iffalse
% \subsection{Pedersen-VSS}
% \label{appendix:pedersenVSS}
% A la Pedersen commitment, Pedersen-VSS is a variation that couples the commitment to $p(x)$ with another randomly chosen polynomial. By removing the assumption that $g^s$ is known beforehand as part of the commitment to the coefficients, it results in a secret sharing scheme which is unconditionally secure for the dealer. It can be summarized as follows:

% \textbf{Setup.} In addition to parameters $p,q,g$ inherent to Feldman-VSS, it uses an element $h$ in the subgroup of $\groupZ^*_p$ generated by $g$. It is assumed that the adversary cannot find the discrete logarithm of $h$ relative to the base $g$.

% \begin{itemize}
% \item $\mathsf{ShareGen}(s) \rightarrow (\{s_i\}, C)$ with $s \in \groupZ_q$ involves the dealer sampling two random polynomials $p(x) = a_0 + a_1x+ \ldots+a_tx^t$ and $p'(x) = b_0 + b_1x +\ldots+b_tx^t$ where $a_i, b_i \in \groupZ_q$ and the secret $s = a_0 = p(0)$ while $s' = b_0 = p'(0)$. The shares are computed as $(s_i = p(i), s'_i = p'(i))$ in mod $q$ for $1 \le i \le n$ and are shared with each participant privately. Also distributed from the dealer are coupled commitments to coefficients of $p$ and $p'$, i.e. $C_j = g^{a_j} h^{b_j}$ for $j = 0, ..., t$.
% \item $\mathsf{ShareVerify}(s_i, C) \rightarrow \{0, 1\}$ involves each participant $P_i$ with shares $(s_i, s'_i)$ and the public polynomial coefficient commitments checking if:
% $$g^{s_i} h^{s'_i} = \prod_{j = 0}^{t} C_j^{i^j}$$
% Similar to Feldman-VSS, any accusation of incorrect sharing against dealer by a participant $P_i$ would require the dealer to broadcast $(s_i, s'_i)$.
% \item $\mathsf{Recon}(A, \{s_i\}_{i \in A}) \rightarrow s$ outputs the secret $s$ by performing Lagrange interpolation with $t + 1$ valid shares of $p(x)$ from the reconstruction set $A$:
% $$s = p(0) = \sum_{j \in A} p(j) \lambda_{0, j, A}$$
% \end{itemize}

% Effectively, what Pedersen-VSS is able to achieve is the decoupling of $g^s$ (as the public key corresponding to the secret key $s$) and $g^{s} h^{s'}$ (as a published commitment for verification purposes). In other words, the share verification process does not (even information-theoretically) leak any information regarding the initial secret $s$, a fact that is not true with Feldman-VSS. This is useful when VSS is used as a subprotocol for distributed key generation, where an adversary is otherwise able to bias the outcome.
% \fi

% \iffalse
% \section{RandShare}
% \label{appendix:randshare}
% RandShare~\cite{syta2017scalable} uses VSS as a subprotocol, extended by adopting the concept of barrier, a specific point in the protocol execution after which the output is fixed and guaranteed to complete successfully. In RandShare, the barrier is reached when the first honest node reveals his shares.
% RandShare proceeds as follows.

% \begin{enumerate}
%     \item \textbf{Share Distribution.} Each participant $P_j$ executes the distribution phase $\mathsf{VSS.ShareGen}(s^{(j)})$ as the dealer, publishing the polynomial commitments and securely sending the shares $s_i^{(j)}$ to all other participants $P_i$, $1\le i\le n$.
%     \item \textbf{Share Verification and Consensus.} To ensure that all honest participants have a consistent view of the secrets that will be recovered after the barrier or if the protocol run has already failed , a Byzantine agreement protocol is run in combination with $\mathsf{VSS.ShareVerify}$. This ensures that at least $t + 1$ honest participants have verified the secret and will be able to recover it. Let $\mathcal{S}$ be the set of secrets that have been agreed upon by the participants.
%     \item \textbf{Share Reconstruction.} If $\lvert \mathcal{S} \rvert \ge t + 1$, each of these secrets $s^{(j)}$ where $j \in \mathcal{S}$ is recovered by collecting at least $t + 1$ shares of the secret and reconstructing it using $\mathsf{VSS.Recon}$. Otherwise, the protocol fails.
%     \item \textbf{Aggregation.} Final randomness is $\drboutput_\epochv = \sum_{j \in \mathcal{S}} s^{(j)}$.

% \end{enumerate}
% \fi

\subsection{Distributed Key Generation (DKG)}
\label{appendix:dkg}
One of the best known DKG schemes is Joint-Feldman~\cite{pedersen1991threshold}, proposed by Pedersen.\\\\
%As discussed in~\cite{gennaro1999secure}, Joint-Feldman does not guarantee uniform randomness or secrecy of the shared secret key. Joint-Pedersen, proposed in the same paper, uses Pedersen commitments~\cite{pedersen1991non} to guarantee uniform randomness by increasing the number of communication rounds by one. Nevertheless, it has been shown that the public key biasability should not be a problem for applications that use DKG as a subprotocol for distributed randomness.\\\\
\noindent\textbf{Joint-Feldman.}
\label{appendix:jointFeldman}
 In this DKG scheme, each participant use Feldman-VSS to share a randomly chosen secret. The protocol is implemented as follows.
\begin{itemize}
    \item $\mathsf{DKG}(1^\lambda, t, n) \rightarrow (sk_i, pk_i, pk)$ proceeds in two phases---Sharing and Reconstruction.
    \begin{enumerate}
        \item In Sharing phase, each participant $P_i$ runs Feldman-VSS by choosing a random polynomial over $\groupZ_q$ of degree $t$, $p_i(z) = \sum_{j = 0}^{t} a_{ij} z^j$ and sending a subshare $s_{ij} = p_i(j)$ mod $q$ to each participant $P_j$ privately. \\
        To satisfy the verifiability portion of VSS, $P_i$ also broadcasts $C_{ik} = g^{a_{ik}}$ for $k = 0, \ldots, t$. Let the commitment corresponding to the secret be denoted by $y_i = C_{i0}$.

        Each participant $P_j$ also verifies the shares he receives from other participants by performing verification steps of Feldman-VSS on each subshare. If the verification for an index $i$ fails, $P_j$ broadcasts a complaint against $P_i$. If $P_i$ receives more than $t$ complaints, then $P_i$ is disqualified. Otherwise, $P_i$ reveals the subshare $s_{ij}$ for every $P_j$ that has broadcast a complaint. We call $\committee$ the set of non-disqualified participants.

        \item Reconstruction phase calculates the keys based on $\committee$.
        The group public key is calculated as $pk = \prod_{i \in \committee} y_i$ where the individual public keys are $pk_i = y_i$. Each participant $P_j$'s share of the group secret is computed as $sk_j = \sum_{i \in \committee} s_{ij}$ mod $q$. Though not computed explicitly, the group secret key $sk$ is equal to both $\sum_{i \in \committee} a_{i0}$ mod $q$ and the Lagrange interpolation involving the shares $\{sk_j\}_{j \in \committee}$.
    \end{enumerate}
\end{itemize}

% \iffalse
% \subsection{Joint-Pedersen}
% \label{appendix:jointPedersen}
% The biasability of Joint-Feldman comes from the fact that the decision on who will be part of $\committee$ is made after the adversary has seen the $y_i$'s of all the participants. This happens because $y_i = C_{i0}$ is published as part of the commitment (required to prove correctness of sharing). Joint-Pedersen solves this by decoupling the output $y_i$ from the commitments for proving correctness by using Pedersen-VSS. This results in $\committee$ and the secret $x$ being determined first, and an additional run of Feldman-VSS to recover $y_i$'s. It is implemented as follows:
% \begin{itemize}
%     \item $\mathsf{DKG}(1^\lambda, t, n) \rightarrow (sk_i, pk_i, pk)$ involves two phases---Sharing and Reconstruction. However, the Reconstruction phase requires an additional run of Feldman-VSS to recover the public keys.
%     \begin{enumerate}
%     \item Sharing phase involves each participant $P_i$ running Pedersen-VSS by choosing two random polynomials over $\groupZ_q$ of degree $t$, $p_i(z) = \sum_{j = 0}^{t} a_{ij} z^j$ and $p'_i(z) = \sum_{j = 0}^{t} b_{ij} z^j$ and sending subshares ($s_{ij} = p_i(j)$, $s'_{ij} = p'_i(j)$) in mod $q$ to each participant $P_j$ privately and broadcasting the commitments $C_{ik} = g^{a_{ik}} h^{b_{ik}}$ for $k = 0, \ldots, t$ to prove correctness. Note that unlike Joint-Feldman, publishing $C_{ik}$ does not reveal any information about $y_i = g^{a_{i0}}$.\\
%     Each participant $P_j$ verifies the shares he receives from other participants by performing share verification step of Pedersen-VSS on each subshare. If the verification for an index $i$ fails, $P_j$ broadcasts a complaint against $P_i$.
%     If $P_i$ receives more than $t$ complaints, then $P_i$ is disqualified. Otherwise, $P_i$ reveals the subshare $(s_{ij}, s'_{ij})$ for every $P_j$ that has broadcast a complaint. We call $\committee$ the set of non-disqualified participants.

%     \item Reconstruction is a two-part process. The first part involves calculating each participant's share of group secret and implicitly recovering the group secret based on $\committee$, like in Joint-Feldman. Each participant $P_j$'s share of the group secret is calculated as $sk_j = \sum_{i \in \committee} s_{ij}$ mod $q$. The group secret key $sk$ is equal to the Lagrange interpolation involving the shares $\{sk_j\}_{j \in \committee}$.

%     The second part of Reconstruction phase involves extracting $pk$ by an additional run of Feldman-VSS because unlike Joint-Feldman, we do not have the corresponding shares $y_i = g^{a_{i0}}$'s required its calculation. Each participant $P_i \in \committee$ exposes $y_i = g^{a_{i0}}$ as follows:
%         \begin{enumerate}
%             \item Each participant $P_i \in \committee$ broadcasts the commitment to the coefficient of the secret polynomial $p_i(z)$ as $A_{ik} = g^{a_{ik}}$ for $k = 0, \ldots, t$. Let $y_i = A_{i0}$.
%             \item Each $P_j$ verifies the values broadcast by each other participant $P_i$ are consistent with the shares $s_{ij}$ shared earlier in a similar way as Feldman-VSS. If the verification fails, $P_j$ broadcasts a complaint against $P_i$ by posting the shares $s_{ij}$ and $s'_{ij}$.
%             \item For any participant $P_i$ that receives at least one valid complaint, all the other participants run the reconstruction phase of Pedersen-VSS to recover the secret polynomial $p_i(z)$.
%             \item Finally, the group public key is calculated as $pk = \prod_{i \in \committee} y_i = \prod_{i \in \committee} g^{a_{i0}}$ where $y_i$ is individual public key $pk_i$ for participant $P_i$.
%         \end{enumerate}
%     \end{enumerate}
% \end{itemize}
% \fi

\subsection{Publicly Verifiable Secret Sharing (PVSS)}
\label{appendix:pvss}
PVSS can be described by the following algorithms.
\begin{itemize}
    \item $\mathsf{Setup}(\lambda) \rightarrow pp$ generates the public parameters $pp$, an implicit input to all other algorithms.
    \item $\mathsf{KeyGen}(\lambda) \rightarrow (sk_i, pk_i)$ generates the PVSS key pair used for encryption and decryption for node $i$.
    \item $\mathsf{Enc}(pk_i, m) \rightarrow c$ and $\mathsf{Dec}(sk_i, c) \rightarrow m'$ are subalgorithms used to encrypt and decrypt the share to node $i$, respectively. Both $\mathsf{Enc}$ and $\mathsf{Dec}$ may optionally output a proof (e.g. $\pi_{DLEQ}$).
    \item $\mathsf{ShareGen}(s) \rightarrow (\{\mathsf{Enc}(pk_i, s_i)\}, \{s'_i\}, \pi)$ with $s'_i = \mathsf{Dec}(sk_i, \mathsf{Enc}(pk_i, s_i))$ is a two-part process. First, the dealer with secret $s$ generates secret shares $\{s_i\}$ and sends each encrypted share $\mathsf{Enc}(pk_i, s_i)$ to node $i$ with an optional encryption proof $\pi_{Enc_{i}}$. Second, node $i$ decrypts the received encrypted share to generate $s'_i$ and broadcasts it with an optional decryption proof $\pi_{Dec_{i}}$. Note that it is possible that $s'_i \neq s_i$. In fact, $s'_i = h^{s_i}$ is standard due to certain PVSS implementation details. $\pi$ incorporates $\{\pi_{Enc_{i}}\}$ and $\{\pi_{Dec_{i}}\}$ as well as any auxiliary proof necessary.
    \item $\mathsf{ShareVerify}(\{\mathsf{Enc}(pk_i, s_i)\}, \{s'_i\}, \pi) \rightarrow \{0, 1\}$ verifies if $\mathsf{ShareGen}$ is correct overall using $\pi$.
    \item $\mathsf{Recon}(A, \{s'_i\}_{i \in A}) \rightarrow s'$ reconstructs the shared secret $s'$ via Lagrange interpolation (in the exponent) from a set $A$ of $t + 1$ nodes whose contributions are passed by the $\mathsf{ShareVerify}$ algorithm. Typically, $s' = h^s$ in the landscape.
\end{itemize}

PVSS is a secure VSS scheme providing the following additional guarantee:
\begin{itemize}
    \item Public Verifiability. If the $\mathsf{ShareVerify}$ algorithm returns 1, then the scheme is valid in a publicly verifiable manner with high probability $1 - \negl(\lambda)$.\\
\end{itemize}

% \iffalse
\noindent\textbf{Schoenmakers PVSS.}
\label{appendix:schoenmakersPVSS}
One of the most common PVSS schemes used in practice is one by Schoenmakers~\cite{schoenmakers1999simple}. As typical, the setup involves $g, h \in \groupG_q$. Additionally, each participant $P_i$ generates a secret key $x_i \in \groupZ^*_q$ and registers $y_i = h^{x_i}$ as its public key.

\begin{itemize}
\item $\mathsf{ShareGen}(s) \rightarrow (\{\mathsf{Enc}(y_i, s_i)\}, \{s'_i\}, \pi)$ with $s'_i$ equal to $\mathsf{Dec}(x_i, \mathsf{Enc}(y_i, s_i))$ first involves production of $\{\mathsf{Enc}(y_i, s_i)\}$ by the dealer with secret $s$. Namely, the dealer picks a random polynomial $p$ of degree $t$ with coefficients in $\groupZ_q$
\[
p(x) = \sum_{i = 0}^{t} a_i x^i
\]
where $s = p(0) = a_0$ and computes $Y_i = \mathsf{Enc}(y_i, s_i) = y_i^{p(i)}$, which is sent to each node $i$ along with information needed to prove its correctness: $C_j = g^{a_j}$ for $0 \leq j \leq t$ such that $X_i = \prod_{j = 0}^{t} C_j^{i^j} = g^{p(i)}$ and $\mathsf{DLEQ}(g, X_i, y_i, Y_i)$ (see Appendix~\ref{appendix:dleq}). Upon receiving $Y_i$, node $i$ computes $s'_i = \mathsf{Dec}(x_i, Y_i) = Y_i^{1 / x_i} = h^{p(i)}$ and generates information needed to prove its correctness: $\mathsf{DLEQ}(h, y_i, s'_i, Y_i)$.
\item $\mathsf{ShareVerify}(\{Y_i\}, \{s'_i\}, \pi) \rightarrow \{0, 1\}$ verifies the encryption proof of correctness $\mathsf{DLEQ}(g, X_i, y_i, Y_i)$ where $X_i$'s are computed from $C_j$'s as well as the decryption proof of correctness $\mathsf{DLEQ}(h, y_i, s'_i, Y_i)$.
\item $\mathsf{Recon}(A, \{s'_i\}_{i \in A}) \rightarrow h^s$ performs the following Lagrange interpolation in the exponent
\[
\prod_{i \in A} (s'_i)^{\lambda_{0, i, A}} = h^{\sum_{i \in A} p(i) \lambda_{0, i, A}} = h^{p(0)} = h^s
\]
where $\lambda_{0, i, A}$ denotes the Lagrange coefficients. Note that, unlike VSS, the scheme does not require the knowledge of the values $p(i)$ by the participants. The secret keys $x_i$ are not exposed as well and thus can be reused.
\end{itemize}

% \subsection{Scrape PVSS}
% \label{appendix:scrapePVSS}
% Following the work of~\cite{cascudo2017scrape}, we define a $[n, k, d]$ code $C$ to be a linear error correcting code over $\groupZ_q$ of length $n$, dimension $k$, and minimum distance $d$. Its dual code $C^\perp$ is the vector space consisting of vectors $c^\perp \in \groupZ_q^n$ such that $\langle c, c^\perp \rangle = 0$ for all $c \in C$. Scrape's PVSS verification relies on the following lemma.
% \begin{lemma}
% If $v \in \groupZ_q^n \setminus C$ and $c^\perp$ is chosen uniformly at random in $C^\perp$, then $Pr\left[\langle v, c^\perp \rangle = 0\right]$ is exactly $\frac{1}{q}$.
% \end{lemma}

% Assuming that $n < q$, we harness Reed-Solomon codes $C$ of the form
% \[
% C = \{(p(1), p(2), ..., p(n)) : p(x) \in \groupZ_q[x], \deg p(x) \leq k - 1\}
% \]
% where $p(x)$ ranges over all polynomials in $\groupZ_q[x]$ of degree at most $k - 1$. Then $C$ represents a $[n, k, n - k + 1]$ code while $C^\perp$ is a $[n, n - k, k + 1]$ code given by
% \[
% C^\perp = \{(\mu_1 f(1), ..., \mu_n f(n)) : f(x) \in \groupZ_q[x], \deg f(x) \leq n - k - 1\}
% \]
% where $\mu_i = \prod_{j = 1, j \neq i}^n \frac{1}{i - j}$.

% Overall, Scrape PVSS is an optimization to Schoenmakers PVSS requiring $O(n)$ exponentiations to verify $n$ shares as opposed to $O(n t)$ exponentiations, leveraging the above coding theory related to Reed-Solomon codes. The idea is that the dealer, instead of committing to each polynomial coefficient via $C_j$, computes and distributes $v_i = g^{p(i)}$ directly, in which case each verifier needs to sample a random codeword $c^\perp = (c_1^\perp, ..., c_n^\perp)$ from $C^\perp$ and run a verification test involving all $v_i$'s at once.

% Scrape PVSS comes in two flavors: $PVSS_{DDH}$ and $PVSS_{DBS}$. The former relies on the DDH (decisional Diffie-Hellman) assumption while the latter uses a bilinear pairing and thus relies on the DBS (decisional bilinear square) assumption~\cite{heidarvand2008public}.\\

% \noindent\underline{$PVSS_{DDH}$}
% \begin{itemize}
% \item $\mathsf{ShareGen}(s) \rightarrow (\{\mathsf{Enc}(y_i, s_i)\}, \{s'_i\}, \pi)$ with $s'_i$ equal to $\mathsf{Dec}(x_i, \mathsf{Enc}(y_i, s_i))$ is the same as that of Schoenmakers PVSS except the fact that $v_i = g^{p(i)}$ is computed and sent directly by the dealer as opposed to $C_j$'s. The encryption and decryption proofs $\mathsf{DLEQ}(g, v_i, y_i, Y_i)$ and $\mathsf{DLEQ}(h, y_i, s'_i, Y_i)$ remain unchanged.
% \item $\mathsf{ShareVerify}(\{Y_i\}, \{s'_i\}, \pi) \rightarrow \{0, 1\}$ additionally requires a verifier to sample a random codeword $c^\perp = (c_1^\perp, ..., c_n^\perp)$ from $C^\perp$ (dual code of $C$ corresponding to the secret sharing instance) and run the following verification test given by
% \[
% \prod_{i = 1}^n v_i^{c_i^\perp} = g^{\sum_{i = 1}^n p(i) c_i^\perp} = g^{\langle c, c^\perp \rangle} = g^0 = 1
% \]
% where $\langle \cdot, \cdot \rangle$ denotes an inner product. It is in this way that $O(n)$ exponentiations are needed to verify $n$ shares.
% \item $\mathsf{Recon}(A, \{s'_i\}_{i \in A}) \rightarrow h^s$ is the same as that of Schoenmakers PVSS.
% \end{itemize}

% \noindent\underline{$PVSS_{DBS}$}\\
% $PVSS_{DBS}$ provides a different flavor to $PVSS_{DDH}$, as it uses a bilinear pairing (without loss of generality) $e: \groupG \times \groupG \rightarrow \groupG_T$ with $\groupG = \langle g \rangle = \langle h \rangle$ for two independent generators of $\groupG$ and $\groupG_T$ denoting a cyclic group of prime order $q$. Fundamentally similar to $PVSS_{DDH}$, the scheme necessitates appropriate algebraic modifications accordingly while the final shared secret is $e(h^s, h)$ rather than $h^s$.
% \begin{itemize}
% \item $\mathsf{ShareGen}(s) \rightarrow (\{\mathsf{Enc}(y_i, s_i)\}, \{s'_i\}, \pi)$ with $s'_i$ equal to $\mathsf{Dec}(x_i, \mathsf{Enc}(y_i, s_i))$ is the same as in $PVSS_{DDH}$ except that both encryption and decryption proofs of correctness are no longer necessary.
% \item $\mathsf{ShareVerify}(\{Y_i\}, \{s'_i\}, \pi) \rightarrow \{0, 1\}$ instead requires a verifier to essentially replace the encryption and decryption proofs with verifying two pairing equations, respectively. The encryption proof $\mathsf{DLEQ}(g, v_i, y_i, Y_i)$ is replaced by verifying the pairing equation $e(v_i, y_i) = e(g, Y_i)$. The decryption proof $\mathsf{DLEQ}(h, y_i, s'_i, Y_i)$ is replaced by verifying the pairing equation $e(s'_i, y_i) = e(h, Y_i)$. The same verification test
% \[
% \prod_{i = 1}^n v_i^{c_i^\perp} = 1
% \]
% is also run.
% \item $\mathsf{Recon}(A, \{s'_i\}_{i \in A}) \rightarrow e(h^s, h)$ outputs $e(h^s, h)$ as the shared secret after the corresponding Lagrange interpolation in the exponent outputs $h^s$.
% \end{itemize}
% \fi

% \iffalse
% \subsection{Albatross}
% \label{appendix:albatross}
% Albatross~\cite{cascudo2020albatross} achieves its improvement over Scrape using the following techniques.\\

% \noindent\textbf{Packed Shamir Secret Sharing.} Packed Shamir secret sharing is a generalization of Shamir secret sharing that allows to secret-share a vector of $\ell$ elements from a field rather than a single element. The key point is that every share is still one element of the field and therefore the sharing has the same computational cost of $\theta(n)$ exponentiations as regular Shamir secret sharing. This is accomplished by having the dealer choose a polynomial $p$ of degree $t+\ell-1$ uniformly at random and use a set of $\ell$ distinct points for secret sharing $\ell$ secrets, e.g. $(s_0, s_1, ..., s_{\ell - 1}) = (p(0), p(-1), ..., p(-(\ell - 1)))$, and another set of $n$ distinct points on the same polynomial for the shares sent by the dealer to each participant, e.g. $(p(1), ..., p(n))$. Any subset of $t+\ell$ points can be used to reconstruct the secret polynomial via Lagrange interpolation and recover the $\ell$ secrets. Note that the usual Shamir secret sharing corresponds to when $\ell = 1$.\\

% \noindent\textbf{Linear Perfect $t$-resilient functions.} Instead of computing the final randomness from PVSS reconstructions as $\prod_{j \in \committee} h^{s^{(j)}}$ like in Scrape, Albatross uses a $t$-resilient function for randomness extraction.

% A $\groupZ_q$-linear $t$-resilient function is a linear function $\groupZ_q^r \rightarrow \groupZ_q^u$ given by a matrix $M \in \groupZ_q^{u \times r}$ such that the output is uniformly distributed in $\groupZ_q^u$ as long as $r-t$ coordinates of the input are uniformly distributed in $\groupZ_q^{r-t}$, even if the other $t$ coordinates are completely controlled by the adversary. Such a function can only exist if $u \le r-t$.

% In the presence of some participant withholding its secret $s$, PVSS only allows us to recover $h^s$ (for some public generator of $h$ of the group) instead of the secret $s$. This would require us to apply $t$-resilient function in the exponent. So, given $h_1, \ldots, h_r$ where $h_i = h^{x_i}$ and $x_i$ is private, goal is to extract $(\hat{h_1},\ldots, \hat{h_u}) \in \groupG_q^u$ which is uniformly random. It is achieved by applying the $t$-resilient function given by matrix $M$ to the exponents, i.e., $\hat{h_i} = h^{y_i}$ where $\vec{x} \mapsto \vec{y} = M \cdot \vec{x}$. This can be evaluated efficiently with $O(n^2 \log n)$ exponentiations by choosing $M$ to be a certain type of Vandermonde matrix and adapting the Cooley-Tukey Fast Fourier transform algorithm to work in the exponent (FFTE)~\cite{cascudo2020albatross} of the group.

% In Albatross, we assume $n$ participants, of which the static adversary corrupts at most $t$ participants where $t < \frac{n - 1}{2}$. We define $\ell = n - 2t > 0$. The output of the protocol will be $\ell^2$ elements of $\groupG_q$. Similar to Scrape, the protocol proceeds in five phases: Commit, Verify, Reveal, Recover, and Output.
% \begin{enumerate}
%     \item \textbf{Commit.} Every participant $P_j$ acts as dealer for packed PVSS and publishes encrypted shares and encryption proofs for recovering $\ell$ secrets $h^{s^{(j)}_{0}}, \ldots, h^{s^{(j)}_{\ell-1}}$.
%     \item \textbf{Verify.} Every participant executes the sharing verification phase on every shared secret. Since verification is public, this fixes the set $\committee$ of the first $n - t = t + \ell$ participants who have correctly shared.
%     \item \textbf{Reveal.} Every participant $P_j \in \committee$ opens the Shamir secret $(s^{(j)}_{0}, \ldots, s^{(j)}_{\ell-1})$. The other participants verify its consistency with the sharing posted before. The protocol proceeds to the Recover phase only if all the participants in $\committee$ have not opened their secrets correctly. Otherwise, it proceeds to Case 1 of Output phase.
%     \item \textbf{Recover.} For each participant $P_a$ that do not open their secret during the Reveal phase, other participants publish the decrypted shares of the secret. Once $t+\ell$ valid shares are published, Lagrange interpolation is used to reconstruct the polynomial and recover the secrets $h^{s^{(a)}_{0}}, \ldots, h^{s^{(a)}_{\ell-1}}$. Then it proceeds to Case 2 of Output phase.
%     \item \textbf{Output.}
%         \begin{itemize}
%             \item \textit{Case 1.} When all the participants in $\committee$ have opened their secrets correctly, we have a $(n-t) \times \ell$ matrix $S$ with rows indexed by the participants $P_a \in \committee$ and each row corresponding to its $\ell$ opened secrets $(s^{(a)}_{0}, \ldots, s^{(a)}_{\ell-1})$. The final randomness $\drboutput$ with $\ell^2$ elements is computed by each participant as $\drboutput = h^U$, where $U = M \cdot S \in \groupZ_q^{\ell \times \ell}$.

%             \item \textit{Case 2.} Otherwise, we have a $(n-t) \times \ell$ matrix $T$ with rows indexed by the participants $P_a \in \committee$ where the row corresponding to $P_a$ is $(h^{s^{(a)}_{0}}, \ldots, h^{s^{(a)}_{\ell-1}})$. The final $\ell \times \ell$ randomness matrix $\drboutput$ is computed as $\drboutput = M \diamond T$ by applying FFTE to each column $T^{(j)}$ of $T$ producing column $\drboutput^{(j)}$ of $\drboutput$.
%         \end{itemize}
% \end{enumerate}

% \subsection{SecRand}
% \label{appendix:secRand}
% SecRand~\cite{guo2020secRand} uses Scrape PVSS (see Appendix~\ref{appendix:scrapePVSS} for details) as a subprotocol. After initial setup using $\mathsf{PVSS.KeyGen}$, SecRand proceeds in four phases---Share Distribution, Share Verification, Aggregation, and Reconstruction. The Share Distribution and Share Verification phases proceed in a similar way as Commit and Verify phases of Scrape. However, since SecRand does not have a Reveal phase like Scrape, the participants are not required to publish commitments to their secret $\mathsf{Com}(s, r_0)$ during Share Distribution phase. The other two phases proceed as follows.

% \begin{enumerate}
%     \setcounter{enumi}{2}
%     \item \textbf{Aggregation.} After the Share Distribution and Share Verification phases, every participant $P_i$ would have a valid encrypted share of each of the $n$ secrets, $\mathsf{Enc}(pk_i, s_i^{(j)})$ for $1 \le j \le n$. $P_i$ decrypts these shares to recover $\tilde{s}_i^{(j)}$ (need not be $s_i^{(j)}$ as per Appendix~\ref{appendix:pvss}) and calculates its group secret share as follows:
%     $$\tilde{s}_i = \prod_{j=1}^{n}\tilde{s}_i^{(j)}$$
%     $P_i$ then broadcasts $\tilde{s}_i$ along with a proof of correct decryption $\pi_i$.
%     \item \textbf{Reconstruction.} Every participant verifies the correctness of decryption using $\mathsf{PVSS.ShareVerify}$. Once $t + 1$ valid group secret shares are distributed, the complete group secret $\tilde{s} = h^s$ is reconstructed through $\mathsf{PVSS.Recon}$. The final beacon output is $\drboutput_\epochv = H(\tilde{s})$.
% \end{enumerate}
% \fi
% \iffalse
% \section{Threshold Encryption}
% \label{appendix:thresholdEnc}

%     Following the work of~\cite{cortier2013distributed}, a $(t, n)$-threshold encryption scheme should provide the following properties:
%     \begin{itemize}
%         \item Completeness. For any $1 \le t \le n$ and for every admissible plaintext $m$, if the keys have been honestly generated with $\mathsf{DKG}(1^\lambda, t, n)$, the plaintext encrypted with $\mathsf{Enc}(pk, m)$ and a set of at least $t + 1$ honest participants have computed the correct decryption shares with $\mathsf{DecShare}(sk_i, c)$, then we require $\mathsf{Rec}(A, c, pk, \{pk_i\}_{i \in A}, \{d_i\}_{i \in A}) = m$.
%         \item Robustness. For any ciphertext $c$ and any two sets $A \neq A'$ of $t + 1$ nodes with valid decryption shares such that $\mathsf{Rec}(A, c, pk, \{pk_i\}_{i \in A}, \{d_i\}_{i \in A}) \neq 0$ and $\mathsf{Rec}(A', c, pk, \{pk_i\}_{i \in A'}, \{d_i\}_{i \in A'}) \neq 0$, it holds that $\mathsf{Rec}(A, c, pk, \{pk_i\}_{i \in A}, \{d_i\}_{i \in A}) = \mathsf{Rec}(A', c, pk, \{pk_i\}_{i \in A'}, \{d_i\}_{i \in A'})$.
%         \item IND-CPA against static corruptions. A $(t, n)$ threshold cryptosystem is said to be IND-CPA secure if for any polynomial time adversary $\adv$ corrupting at most $t$ participants at the beginning of the protocol, $\adv$, who acts on behalf of corrupted nodes, has negligible advantage in a game $\mathsf{Exp}^{\mathsf{cpa}}_{\adv}$ played against challenger, who acts on behalf of the remaining participants. In other words,
%         $$|Pr[\mathsf{Exp}_{\adv}^{\mathsf{cpa}}(\lambda) = 1] - 1/2| < \negl(\lambda)$$

%         The game $\mathsf{Exp}^{\mathsf{cpa}}_{\adv}$ proceeds as follows:
%         \begin{enumerate}
%             \item The adversary $\adv$ and the challenger run together $\mathsf{DKG}(1^\lambda, t, n)$, at the end of which the adversary learns the individual secret and public keys of all the corrupted nodes. It also obtains the group public key $pk$.
%             \item $\adv$ then chooses two admissible messages $m_0$, $m_1$ of equal length and sends it to the challenger.
%             \item The challenger randomly chooses one of them $\beta \gets \{0, 1\}$ and sends $\mathsf{Enc}(pk, m_{\beta})$ back to the adversary.
%             \item Finally, $\adv$ outputs its guess $\beta' \in \{0,1\}$.
%         \end{enumerate}
%         The output of the game is 1 if $\beta' = \beta$ and 0 otherwise and the advantage of $\adv$ is defined as $|Pr[\beta' = \beta] - 1/2|$.
%     \end{itemize}
% \fi

\subsection{Threshold ElGamal Cryptosystem}
\label{appendix:thrElGamal}
A $(t, n)$-threshold ElGamal cryptosystem~\cite{desmedt1990Threshold, fouque2001threshold, cherniaeva2019homomorphic}, with an elliptic curve $E$ over $\mathbb{F}_p$ and its cyclic subgroup $\groupG_q$ with generator $G$, is implemented as follows.
\begin{itemize}
    \item $\mathsf{DKG}(1^\lambda, t, n) \rightarrow (sk_i, pk_i, pk)$ runs a typical DKG.
    \item $\mathsf{Enc}(pk, m) \rightarrow (A, B)$ outputs ciphertext $c = (A, B) = (r G, m G + r \cdot pk)$ given $m, r \in \groupZ_q$ and $pk = sk \cdot G$.
    \item $\mathsf{DecShare}(sk_i, c) \rightarrow D_i$ outputs decryption share $D_i = sk_i \cdot A$ for $c = (A, B)$ using individual secret key $sk_i$.
    \item $\mathsf{Rec}(\tilde{A}, c, pk, \{pk_i\}_{i \in \tilde{A}}, \{D_i\}_{i \in \tilde{A}}) \rightarrow m$ reconstructs the point $D = sk \cdot A$ from $\{D_i\}_{i \in \tilde{A}}$ (given a set $\tilde{A}$ of $t + 1$ honest nodes) via Lagrange interpolation and outputs $m = B - D$.
\end{itemize}

% \iffalse
% \section{Verifiable Random Function (VRF)}
% \label{appendix:vrf}
% A VRF~\cite{micali1999verifiable,dodis2005verifiable} is a function that, given an input $x$ and a secret key $sk$, generates a unique, pseudorandom output $y$ as well as a proof $\pi$ verifying that the computation has been done correctly. Due to $\pi$, it is possible to repeatedly generate new pseudorandom outputs with one $sk$ and varying inputs in a verifiable manner whereas otherwise (e.g. using a classical pseudorandom function) one needs to divulge the secret key and sacrifice its reusability for public verification purposes. It can be represented by the following tuple of algorithms:
% \begin{itemize}
% \item $\mathsf{Prove}(sk, x) \rightarrow (F_{sk}(x), \pi_{sk}(x))$ generates the pseudorandom output $F_{sk}(x)$ and its proof of correctness $\pi_{sk}(x)$ given input $x$ and secret key $sk$.
% \item $\mathsf{Verify}(pk, x, y, \pi) \rightarrow \{0, 1\}$ outputs 1 if it is verified that $y = F_{sk}(x)$ using the proof $\pi$ and 0 otherwise.
% \end{itemize}

% Furthermore, a VRF satisfies the following three properties:
% \begin{enumerate}
% \item Provability. If $(y, \pi) = \mathsf{Prove}(sk, x)$, then the tuple is accepted by the $\mathsf{Verify}$ algorithm such that $\mathsf{Verify}(pk, x, y, \pi) = 1$.
% \item Uniqueness. There does not exist $(y_1, \pi_1) \neq (y_2, \pi_2)$ such that $\mathsf{Verify}(pk, x, y_1, \pi_1) = \mathsf{Verify}(pk, x, y_2, \pi_2) = 1$.
% \item Pseudorandomness. The output is indistinguishable from a random number from a uniform distribution except with negligible probability. This can be written as follows.
% \[
% Pr\left[b = b' \middle\vert \begin{array}{l}
% (x, st) \gets \adv^{\mathsf{Prove}(\cdot)}_{1}(pk);\\
% y_0 = F_{sk}(x);\\
% y_1 \gets \{0, 1\}^{\ell_{VRF}};\\
% b \gets \{0, 1\};\\
% b' \gets \adv^{\mathsf{Prove}(\cdot)}_{2}(y_b, st)
% \end{array}\right] \leq \frac{1}{2} + \negl(\lambda)
% \]
% for any probabilistic polynomial-time algorithm $\adv = (\adv_1, \adv_2)$, which does not query the oracle on $x$.
% \end{enumerate}

% \subsection{Verifiable Unpredictable Function (VUF)}
% \label{appendix:vuf}
% A VUF~\cite{micali1999verifiable,dodis2005verifiable} is a VRF except the last property of pseudorandomness is replaced by the following unpredictability property.
% \begin{itemize}
% \item Unpredictability. The output is unpredictable except with negligible probability. In other words:
% \[
% Pr\left[y = F_{sk}(x) \middle\vert (x, y) \gets \adv^{\mathsf{Prove}(\cdot)}(pk)\right] \leq \negl(\lambda)
% \]
% for any probabilistic polynomial-time algorithm $\adv$, which does not query the oracle on $x$.
% \end{itemize}
% \fi

% \iffalse
% \subsection{Distributed Verifiable Random Function (DVRF)}
% \label{appendix:dvrf}
% A DVRF satisfies the following properties (some of which are inherited from what a VRF should satisfy).
% \begin{itemize}
% \item Provability (Robustness). If $(y, \pi)$ is output by the $\mathsf{Combine}$ algorithm, then it is accepted by the $\mathsf{Verify}$ algorithm.
% \item Uniqueness. There does not exist $(y_1, \pi_1) \neq (y_2, \pi_2)$ such that $\mathsf{Verify}(pk, \{pk_i\}, x, y_1, \pi_1) = \mathsf{Verify}(pk, \{pk_i\}, x, y_2, \pi_2) = 1$.
% \item Pseudorandomness. An adversary corrupting $t$ nodes cannot distinguish a DVRF output from a uniformly random value except with negligible probability.
% \item Consistency. $\mathsf{Combine}(A, \{(y_i, \pi_i)\}_{i \in A})$ should yield the same $y$ for any set $A$ of $t + 1$ nodes whose outputs of $\mathsf{PartialEval}(sk_i, x)$ are accepted by $\mathsf{PartialVerify}(pk_i, x, y_i, \pi_i)$.
% \end{itemize}
% \fi

\begin{table*}[h!]
\aboverulesep=0ex
\belowrulesep=0ex
% \footnotesize
\renewcommand{\arraystretch}{1}
\begin{threeparttable}
\caption{Committee-Based DRB}
\label{table:committee-based}
\begin{tabularx}{\textwidth}{|c|c|c|l|l|}
\cmidrule{4-5}
\multicolumn{3}{c|}{} & \multicolumn{2}{c|}{Step 2: Beacon Output Generation} \\
\cmidrule{4-5}
\multicolumn{3}{c|}{} & \multicolumn{1}{c|}{Fresh per-node entropy} & \multicolumn{1}{c|}{$\drboutput_{\epochv - 1}$ \& precommitted per-node entropy} \\
\cmidrule{1-5}
\multirow{5}{*}{\spheading[0.44\textwidth]{\mbox{Step 1: Committee Selection}}} & \multirow{3}{*}[-2.8cm]{Public} & RR & \begin{tabular}{@{}l@{}}\textbf{BRandPiper}\\\textit{Step 1}: Node $i \equiv \epochv \pmod n$\\\textit{Step 2}: Share-aggregate-reconstruct\end{tabular} & \\
\cmidrule{3-5}
& & RS & \begin{tabular}{@{}l@{}}\textbf{Ouroboros}\\\textit{Step 1}: Follow-the-satoshi~\cite{bentov2014proof,kiayias2017ouroboros}\\\textit{Step 2}: Share-reconstruct-aggregate\end{tabular} & \begin{tabular}{@{}l@{}}\textbf{HydRand}\\\textit{Step 1}: Node $i \equiv \drboutput_{\epochv - 1} \pmod{\tilde{n}}$\\\textit{Step 2}: $\drboutput_\epochv = H(\drboutput_{\epochv - 1} \mathbin\Vert h^{e_{\tilde{\epochv}}})$\\\\\textbf{GRandPiper}\\\textit{Step 1}: Node $i \equiv \drboutput_{\epochv - 1} \pmod{\tilde{n}}$\\\textit{Step 2}: $\drboutput_\epochv = H(h^{e_{\tilde{\epochv}}}, \drboutput_{\epochv - 1}, ..., \drboutput_{\epochv - t})$\end{tabular} \\
\cmidrule{3-5}
& & LS & \begin{tabular}{@{}l@{}}\textbf{RandHound\todo{better macro for this table?}}\\\textit{Step 1}: Node $\argmin_{i} H(C \mathbin\Vert pk_i)$\\\textit{Step 2}: Share-reconstruct-aggregate\\\\\textbf{SPURT, OptRand}\\\textit{Step 1}: Node $i \equiv \epochv \pmod n$\\\textit{Step 2}: Share-aggregate-reconstruct\end{tabular} & \\
\cmidrule{2-5}
& \multirow{2}{*}[-0.55cm]{Private} & VRF & \begin{tabular}{@{}l@{}}\textbf{NV++}\\\textit{Step 1}: $VRF_{sk}(\drboutput_{\epochv - 1} \mathbin\Vert nonce) < target$\\\textit{Step 2}: Threshold ElGamal\end{tabular} & \begin{tabular}{@{}l@{}}\textbf{Algorand}\\\textit{Step 1}: $VRF_{sk}(\drboutput_{\epochv - 1} \mathbin\Vert role) < target$\\\textit{Step 2}: $\drboutput_\epochv = VRF_{sk}(\drboutput_{\epochv - 1} \mathbin\Vert \epochv)$\\\\\textbf{Ouroboros Praos}\tnote{1}\\\textit{Step 1}: $VRF_{sk}(\drboutput_{\epochv - 1} \mathbin\Vert slot \mathbin\Vert \mathsf{TEST}) < target$\\\textit{Step 2}: $\drboutput_\epochv = H(\drboutput_{\epochv - 1} \mathbin\Vert epoch \mathbin\Vert \rho_1 \mathbin\Vert ... \mathbin\Vert \rho_K)$\end{tabular} \\
\cmidrule{3-5}
& & Hash chain & & \begin{tabular}{@{}l@{}}\textbf{Caucus}\tnote{2}\\\textit{Step 1}: $H(h_\epochv \oplus \drboutput_{\epochv - 1}) < target$\\\textit{Step 2}: $\drboutput_\epochv = h_\epochv \oplus \drboutput_{\epochv - 1}$\end{tabular} \\
\cmidrule{1-5}
\end{tabularx}
\begin{tablenotes}[flushleft]
\footnotesize
\item Note that public committee selection mechanisms (Section~\ref{subsubsection:public-committee-selection}) include RR (round-robin), RS (random selection), and LS (leader-based selection) while details regarding private committee selection can be found in Section~\ref{subsubsection:private-committee-selection}. For details on the two columns under beacon output generation, see Sections~\ref{subsubsection:fresh} and~\ref{subsubsection:precommitted}.
\item[1] The protocol is a variant of Algorand. While $|\committee_\epochv|$ is expected to be one in Algorand (with 1 final winner per lottery and 1 lottery per \epoch), that in Ouroboros Praos is expected to be $K$ where each \epoch consists of $K$ slots and thus $K$ per-slot lotteries. Parameters $slot$ and $epoch$ denote the slot and \epoch numbers, respectively, and $\rho_i = VRF_{sk_i}(\drboutput_{\epochv - 1} \mathbin\Vert slot_i \mathbin\Vert \mathsf{NONCE})$ is returned by the slot leader of $slot_i$. $\mathsf{TEST}$ and $\mathsf{NONCE}$ are strings.
\item[2] In Caucus, a VRF is replaced by a hash function combined with a hash chain, i.e. a list ($h_1, ..., h_m$) with $h_\epochv = H(h_{\epochv + 1})$ for all $\epochv = 1, ..., m - 1$ where $h_m = s$ for some random seed. A hash chain provides the functionality of provably committing to private inputs as one publicizes one $h_\epochv$ at a time (i.e. $h_\epochv$ in \epoch $\epochv$). Each node independently generates a private hash chain. One downside is that the hash chain needs to be periodically regenerated, as $m$ is finite.
\end{tablenotes}
\end{threeparttable}
\end{table*}

% \section{Distributed Verifiable Random Function (DVRF)}
\subsection{DDH-DVRF}
\label{appendix:ddh-dvrf}
DDH-DVRF (from the decisional Diffie-Hellman assumption) is described by the following DVRF algorithms.
\begin{itemize}
\item $\mathsf{DKG}(1^\lambda, t, n)$ runs a typical DKG.
\item $\mathsf{PartialEval}(sk_i, x)$ outputs $(y_i, \pi_i)$ where $y_i = H(x)^{sk_i}$ and $\pi_i = \mathsf{DLEQ}(g, g^{sk_i}, H(x), H(x)^{sk_i})$ denoting the non-interactive Chaum-Pedersen protocol (see Appendix~\ref{appendix:dleq}).
\item $\mathsf{PartialVerify}(pk_i, x, y_i, \pi_i)$ is equivalent to $\mathsf{DLEQ}\text{-}\mathsf{Verify}(g, pk_i, H(x), y_i, \pi_i)$ (Appendix~\ref{appendix:dleq}) and verifies the correctness of the $\mathsf{PartialEval}$ algorithm using $\pi_i$.
\item $\mathsf{Combine}(A, \{(y_i, \pi_i)\}_{i \in A})$ outputs $(y, \pi)$ where $y = \prod_{i \in A} y_i^{\lambda_{0, i, A}}$ and $\pi = \{(y_i, \pi_i)\}_{i \in A}$. Details related to Lagrange coefficients $\lambda_{0, i, A}$ are included in Appendix~\ref{appendix:lagrange}.
\item $\mathsf{Verify}(pk, \{pk_i\}, x, y, \pi)$ verifies all partial proofs via $\mathsf{PartialVerify}$ for all $i \in A$ from $\pi$ and checks $y = \prod_{i \in A} y_i^{\lambda_{0, i, A}}$.
\end{itemize}

\subsection{GLOW-DVRF}
\label{appendix:glow-dvrf}
Providing a compact proof $\pi$, GLOW-DVRF uses a bilinear pairing $e: \groupG_1 \times \groupG_2 \rightarrow \groupG_T$ similar to BLS (Appendix~\ref{appendix:bls}) such that the setup includes hash functions $H_1: \{0, 1\}^* \rightarrow \groupG_1$ and $H_2: \groupG_1 \rightarrow \{0, 1\}^{y(\lambda)}$. While resembling DDH-DVRF, the following algebraic modifications are made due to pairings.
\begin{itemize}
\item $\mathsf{DKG}(1^\lambda, t, n)$ is adapted so that $pk_i$ resides in $\groupG_1$ while $pk$ resides in $\groupG_2$. This is achieved by letting $(pk_i, pk) = (g_1^{sk_i}, g_2^{sk})$ for $g_1 \in \groupG_1$ and $g_2 \in \groupG_2$. The purpose of this is to facilitate a compact proof in the final $\mathsf{Verify}$ step.
\item $\mathsf{PartialEval}(sk_i, x)$ outputs $(y_i, \pi_i)$ where $y_i = H_1(x)^{sk_i}$ and $\pi_i = \mathsf{DLEQ}(g_1, g_1^{sk_i}, H_1(x), H_1(x)^{sk_i})$.
\item $\mathsf{PartialVerify}(pk_i, x, y_i, \pi_i)$ is equivalent to $\mathsf{DLEQ}\text{-}\mathsf{Verify}(g_1, pk_i, H_1(x), y_i, \pi_i)$ and verifies the correctness of the $\mathsf{PartialEval}$ algorithm using $\pi_i$.
\item $\mathsf{Combine}(A, \{(y_i, \pi_i)\}_{i \in A})$ outputs $(y, \pi)$ where $\pi = \prod_{i \in A} y_i^{\lambda_{0, i, A}}$ and $y = H_2(\pi)$. Note that $\pi$ is a group element.
\item $\mathsf{Verify}(pk, \{pk_i\}, x, y, \pi)$ verifies $y = H_2(\pi)$ and a pairing equation $e(\pi, g_2) = e(H_1(x), pk)$.
\end{itemize}

\subsection{Dfinity-DVRF}
\label{appendix:dfinity-dvrf}
Dfinity-DVRF is given by the following DVRF algorithms.
\begin{itemize}
\item $\mathsf{DKG}(1^\lambda, t, n)$ is adapted so that both $pk_i$ and $pk$ reside in $\groupG_2$. This is achieved by letting $(pk_i, pk) = (g_2^{sk_i}, g_2^{sk})$ for $g_2 \in \groupG_2$. The purpose of this is to facilitate the check of some pairing equation in both $\mathsf{PartialVerify}$ and $\mathsf{Verify}$.
\item $\mathsf{PartialEval}(sk_i, x)$ outputs $(y_i, \pi_i)$ where $y_i = H_1(x)^{sk_i}$ and $\pi_i = \text{$\perp$}$. The reason for a null proof is that a pairing equation check is used in $\mathsf{PartialVerify}$ (i.e. the differentiator from GLOW-DVRF) with no need for any auxiliary information.
\item $\mathsf{PartialVerify}(pk_i, x, y_i, \pi_i)$ checks a pairing equation $e(y_i, g_2) = e(H_1(x), pk_i)$.
\item $\mathsf{Combine}(A, \{(y_i, \pi_i)\}_{i \in A})$ equals that in GLOW-DVRF.
\item $\mathsf{Verify}(pk, \{pk_i\}, x, y, \pi)$ equals that in GLOW-DVRF.
\end{itemize}

\subsection{Other Cryptographic Primitives}
\subsubsection{Lagrange Interpolation}
\label{appendix:lagrange}
Given a non-empty reconstruction set $A \subset \groupZ_q$, the \textit{Lagrange basis polynomials} are given by $\lambda_{j, A}(x) = \prod_{k \in A \setminus \{j\}} \frac{x - k}{j - k} \in \groupZ_q[X]$ such that the \textit{Lagrange coefficients} $\lambda_{i, j, A} = \lambda_{j, A}(i) \in \groupZ_q$ enable the equality $p(i) = \sum_{j \in A} p(j) \lambda_{i, j, A}$ for any polynomial $p \in \groupZ_q[X]$ of degree at most $|A| - 1$. The process of computing this equality is called \textit{Lagrange interpolation}.

\subsubsection{BLS Signature}
\label{appendix:bls}
Introduced by Boneh, Lynn, and Shacham in 2003, the BLS signature scheme~\cite{boneh2001short} consists of the following tuple of algorithms given a key pair $(sk, pk)$.
\begin{itemize}
\item $\mathsf{Sign}_{sk}(m) \rightarrow H_1(m)^{sk}$ outputs a digital signature $\sigma = H_1(m)^{sk}$ given secret key $sk$ and message $m$ where $H_1$ is a hash function such that $H_1: \{0, 1\}^* \rightarrow \groupG_1$.
\item $\mathsf{Verify}_{pk}(m, \sigma) \rightarrow \{0, 1\}$ verifies $\sigma$ given signature $\sigma$, message $m$, and public key $pk$ via $e(\sigma, g_2) = e(H_1(m), pk)$.
\end{itemize}
Note that BLS uses a bilinear pairing $e: \groupG_1 \times \groupG_2 \rightarrow \groupG_T$ with $\groupG_1 = \langle g_1 \rangle$, $\groupG_2 = \langle g_2 \rangle$, $\groupG_T$ denoting a cyclic group of prime order $q$, and the following requirements.
\begin{itemize}
\item Bilinearity. $e(g_1^x, g_2^y) = e(g_1, g_2)^{x y}$ for all $x, y \in \groupZ^*_q$.
\item Non-degeneracy. $e(g_1, g_2) \neq 1$.
\item Computability. $e(g_1, g_2)$ can be efficiently computed.
\end{itemize}

The threshold variant~\cite{boldyreva2003threshold} of BLS (i.e. threshold BLS) requires $\mathsf{Sign}_{sk}(m)$ to be computed by $t + 1$ out of $n$ nodes. This is achieved via DKG such that $sk$ denotes the implied group secret key whereas each node broadcasts its partial signature $H_1(m)^{sk_i}$, $t + 1$ of which from the set $A$ of honest nodes are combined to generate
\[
H_1(m)^{sk} = \prod_{i \in A} \left(H_1(m)^{sk_i}\right)^{\lambda_{0, i, A}}
\]
via Lagrange interpolation in the exponent.

\subsubsection{NIZK of Discrete Logarithm Equality (DLEQ)}
\label{appendix:dleq}
Also known as the Chaum-Pedersen protocol~\cite{chaum1992wallet}, the $\Sigma$ protocol~\cite{damgaard2002sigma} for proving that the two discrete logarithms are equal without revealing the discrete logarithm value itself can be turned into a NIZK by applying the Fiat-Shamir heuristic~\cite{fiat1986prove}. Namely, the prover can non-interactively prove the knowledge of $\alpha$ such that $(h_1, h_2) = (g_1^\alpha, g_2^\alpha)$ via $\pi_{DLEQ} = \mathsf{DLEQ}(g_1, h_1, g_2, h_2)$ with group elements in $\groupG_q$.\\

\noindent\underline{$\mathsf{DLEQ}(g_1, h_1, g_2, h_2)$}\\
\textit{Input:} $g_1, h_1, g_2, h_2 \in \groupG_q$, $\alpha \in \groupZ_q$\\
\textit{Output:} $\pi = (e, s)$
\vspace{-\topsep}
\begin{enumerate}
\item $A_1 = g_1^w, A_2 = g_2^w$ for $w \sample \groupZ_q$
\item $e = H(h_1, h_2, A_1, A_2)$
\item $s = w - \alpha \cdot e \pmod q$
\item $\pi = (e, s)$
\end{enumerate}

\noindent\underline{$\mathsf{DLEQ}\text{-}\mathsf{Verify}(g_1, h_1, g_2, h_2, \pi)$}\\
\textit{Input:} $g_1, h_1, g_2, h_2 \in \groupG_q$, $\pi = (e, s)$\\
\textit{Output:} $b \in \{0, 1\}$
\vspace{-\topsep}
\begin{enumerate}
\item $A'_1 = g_1^s h_1^e, A'_2 = g_2^s h_2^e$
\item $e' = H(h_1, h_2, A'_1, A'_2)$
\item $b = \begin{cases}
1 & \text{if $e' = e$}\\
0 & \text{otherwise}
\end{cases}$
\end{enumerate}

\subsubsection{NIZK of Correct ElGamal Encryption (CE)}
\label{appendix:ce}
Via $\pi_{CE} = \mathsf{CE}(G, Q, A, B)$~\cite{cherniaeva2019homomorphic} where $G \in \groupG_q$ and $(Q, A, B) = (x G, r G, m G + r Q)$, the prover can non-interactively prove the knowledge of $(m, r)$ and thus prove the legitimacy of an ElGamal encryption (e.g. as opposed to exploiting its malleability). Note that the additive notation is used to handle points on an elliptic curve.\\

\noindent\underline{$\mathsf{CE}(G, Q, A, B)$}\\
\textit{Input:} $G, Q, A, B \in \groupG_q$, $m, r \in \groupZ_q$\\
\textit{Output:} $\pi = (e, z_1, z_2)$
\vspace{-\topsep}
\begin{enumerate}
\item $T = s_1 G + s_2 Q, E = s_2 G$ for $s_1, s_2 \sample \groupZ_q$
\item $e = H(A, B, T, E)$
\item $z_1 = s_1 + m \cdot e \pmod q, z_2 = s_2 + r \cdot e \pmod q$
\item $\pi = (e, z_1, z_2)$
\end{enumerate}

\noindent\underline{$\mathsf{CE}\text{-}\mathsf{Verify}(G, Q, A, B, \pi)$}\\
\textit{Input:} $G, Q, A, B \in \groupG_q$, $\pi = (e, z_1, z_2)$\\
\textit{Output:} $b \in \{0, 1\}$
\vspace{-\topsep}
\begin{enumerate}
\item $T' = z_1 G + z_2 Q - e B, E' = z_2 G - e A$
\item $e' = H(A, B, T', E')$
\item $b = \begin{cases}
1 & \text{if $e' = e$}\\
0 & \text{otherwise}
\end{cases}$
\end{enumerate}