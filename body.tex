%!TEX root = main.tex

\section{Introduction}
Public, trustworthy randomness has been a useful tool for millennia, dating at least to the earliest known use of dice around 3000 BCE. Today, periodic public randomness is crucial to applications including gambling and lotteries~\cite{bonneau2015bitcoin}, electronic voting~\cite{adida2008helios}, selecting parameters for cryptographic protocols~\cite{baigneres2015trap, lenstra2015random}, leader election in Proof of Stake protocols~\cite{gilad2017algorand, kiayias2017ouroboros}, and blockchain sharding~\cite{al2017chainspace, kokoris2018omniledger}. The concept of a \emph{randomness beacon} was first formalized by Rabin~\cite{rabin1983Rabin} to describe an ideal service that emits fresh random numbers at regular intervals in a way that no party can manipulate. Because no such ideal beacon exists, various protocols are used to approximate this beacon functionality for practical use.
%solutions ranging from centralized approaches (relying on a single source or organization) to distributed approaches (decentralizing the randomness generation among a set of nodes) are used to approximate it.

\textbf{Centralized Beacons.} Relying on a trusted third party like NIST~\cite{fischer2011public,kelsey2019reference} or random.org~\cite{haahr2010random} might be the simplest way to realize a beacon. It carries drawbacks typically associated with centralized services, such as the risk of compromise or misbehavior and the inability of the end user to verify the correctness of the beacon.
%For this reason, it is strongly desirable to construct a beacon with no trusted party or central point of failure.

\textbf{Public Implicit Beacons.} Another approach is to construct a beacon using publicly available implicit sources of entropy such as stock market data~\cite{clark2010use} or Proof of Work (PoW) blockchains like Bitcoin~\cite{nakamoto2008bitcoin, bentov2016bitcoin, bonneau2015bitcoin, han2020randchain}. However, these entropy sources are potentially vulnerable to malicious insiders (e.g. high-frequency traders making unnatural trades to fix stock prices, financial exchanges blocking trades or reporting incorrect data, miners that can withhold blocks or choose between colliding blocks, etc.). The entropy of these sources can also be difficult to precisely measure. While potentially secure and low-cost in practice, we will not discuss these approaches in detail in this survey.

\textbf{Distributed Randomness Beacons.}
A natural approach to reduce complete trust in a centralized beacon is to use a distributed beacon protocol capable of gracefully handling a minority of Byzantine participants and a potentially untrusted network. We call a beacon realized in this manner a \textit{distributed randomness beacon} (DRB). DRB protocols are typically round-based, producing a fresh random output in each round.

\textbf{Contribution.} The goal of the paper is to systematize the current progress on DRBs specifically. We propose a generalized framework encompassing all distributed randomness protocols in the landscape. To aid comparison and discussion of properties, we provide an overview of these protocols along with the various cryptographic building blocks used to construct them. We identify two key components of DRB design: selection of entropy providers and beacon output generation, which can be decoupled from each other. Enabling a more holistic analysis of a DRB as a result, we also provide new insights and discussion on potential attack vectors, countermeasures, and techniques that lead to better scalability.

\textbf{Paper organization.} We begin with preliminaries including our system model, a strawman DRB under perfect synchrony (an ideal assumption), commit-reveal~\cite{blum1983coin}, and the definition of an ideal DRB in Section \ref{section:preliminaries}. Section \ref{section:vdf} introduces protocols using verifiable delay functions~\cite{boneh2018verifiable}, which (assuming secure VDFs can be realized) offer the best security and simplicity. Then from Section \ref{section:commit-reveal-punish} to \ref{section:dvrf}, we introduce non-VDF-based DRB protocols based on the number of nodes contributing \textit{marginal entropy} (i.e. per-round randomness that is independently generated at a node level) in each round. Sections \ref{section:commit-reveal-punish} and \ref{section:commit-reveal-recover} review protocols in which all nodes contribute marginal entropy. These protocols vary in mechanisms used to recover from faulty nodes, including financial punishment~\cite{youcai2017randao, david2020economically}, threshold secret sharing~\cite{schoenmakers1999simple, cascudo2017scrape}, and threshold encryption~\cite{desmedt1990Threshold}. Section \ref{section:committee-based} covers committee-based protocols in which each round includes an extra committee selection step, after which only a committee (non-empty proper subset) of nodes contributes marginal entropy. These protocols are more complex but can offer greater communication efficiency with large numbers of nodes. Section \ref{section:dvrf} covers pseudorandom protocols that do not require any marginal entropy; these protocols can be highly efficient but have no mechanism to recover from compromise. We conclude with discussion and comparisons in Sections \ref{section:discussions}--\ref{section:conclusion}, including a comparison of all studied protocols in Table~\ref{table:comparison}.

\section{Preliminaries}
\label{section:preliminaries}
% We delineate the necessary preliminaries in this section, starting with the description of our system model (including threat model) relevant in all protocols portrayed in this paper (unless stated otherwise). We then introduce a strawman DRB assuming a perfectly synchronous network (with zero latency) as well as the classical commit-reveal~\cite{blum1983coin}. Identifying problems in both, we define the security of an ideal DRB.
\subsection{System Model}
We consider a system model with $\nodes = \{P_1, P_2, ..., P_n\}$ comprising $n$ participants (also called nodes), also often denoted by $\nodes = \{1, 2, ..., n\}$ for the purpose of algebraic formulations without loss of generality. Out of $n$, up to $t$ faulty nodes (deemed \textit{Byzantine}) may engage in incorrect (arbitrary) behavior during a protocol run, and an adversary $\adv$ that controls up to $t$ such nodes is called \textit{$t$-limited}. Otherwise, nodes that are \textit{honest} abide by the specified protocol.

We assume a standard public key infrastructure (PKI) such that all nodes know each others' public keys, and that all nodes are connected via point-to-point secure (providing authenticity) communication channels. All messages exchanged by honest nodes are digitally signed by the sender, and recipients always validate each message before proceeding. By default, we assume a \textit{synchronous} network, in which there exists some known finite message delay bound $\Delta$. This means that an adversary can delay a message by at most $\Delta$.

Moreover, we assume a computationally bounded adversary $\adv$ runs in PPT (probabilistic polynomial time) and that $\adv$ cannot break standard cryptographic constructions such as hash functions, digital signatures, etc. The three ways in which $\adv$ can deviate from a protocol are omitting a message (i.e. \textit{withholding attack}), sending invalid messages, and colluding to coordinate an attack based on private information shared among Byzantine nodes. Additionally, $\adv$ has the power to perform a \textit{grinding attack}, in which $\adv$ privately precomputes and iterates through as many combinations of inputs to an algorithm as possible in order to derive a desirable output. By default, we assume a \textit{static} adversary that chooses nodes to be corrupted before a protocol run whereas an \textit{adaptive} adversary can choose nodes to be corrupted at any time during a protocol run (although we assume a model where nodes remain corrupted once corrupted).

We denote our computational model's security parameter by $\lambda$. We call a function $negl(\lambda)$ \textit{negligible} if for all $c > 0$ there exists a $\lambda_0$ such that $negl(\lambda) < \frac{1}{\lambda^c}$ for all $\lambda > \lambda_0$. The group elements $g, h \in \groupG$ are generators of $\groupG$ while $p, q$ denote primes where $q \mid p - 1$ (unless stated explicitly) such that $\groupG_q$ is a group of prime order $q$. The notation $tuple[0]$ denotes the first element of $tuple$. Furthermore, we model any hash function $H(\cdot)$ as a random oracle. In the context of a distributed randomness beacon, we use $r$ to denote round number and $\drboutput_r$ to denote the \textit{beacon output} (i.e. the distributed randomness output) in round $r$. The \textit{entropy-providing committee} denoted by $\committee_r$ refers to a non-empty proper subset of nodes (hereafter called \textit{entropy providers}) that proactively generate and provide marginal entropy in round $r$. $\committee_r$ can include all nodes, some but not all nodes, one node (i.e. a leader), or no node.

\subsection{Strawman Protocol: Rock-Paper-Scissors}
Distributed randomness assuming perfect synchrony is straightforward. Consider the following one-round ``rock-paper-scissors'' protocol where each participant $i$ broadcasts its \textit{entropy contribution} (i.e. independently generated randomness) $e_i \in \mathbb{Z}_p$ to every other participant at the same time as per simultaneity observed (say) in rock-paper-scissors. Naturally, its protocol output $\drboutput$ (via addition in a finite group) can be given by
\[
\drboutput = \sum_{i = 1}^n e_i
\]
such that applying this mechanism $\tilde{r}$ times at $\tilde{r}$ chronological timestamps would yield a DRB.
% \joenote{Round notation not introduced yet?}

This protocol is simple and, under a perfect synchrony assumption, is secure as long as any single participant chooses its $e_i$ randomly. However, security falls apart completely once messages can be delayed.
%assumption is never true. In fact, situations can change dramatically in a practical setting where participants can go offline (perhaps temporarily) due to network failure, messages can be delayed either non-significantly or significantly, and Byzantine attackers can try to predict or bias the randomness to their benefit.
Consider a simple scenario with three participants $\{P_1, P_2, P_3\}$ participating to produce $\drboutput = e_1 + e_2 + e_3$. If $P_3$ can read $e_1$ and $e_2$ before sending $e_3$ (due to non-zero message latency) to $P_1$ and $P_2$, then $P_3$ can fix the output $\drboutput$ to any value $\tilde{\drboutput}$ by choosing $e_3 = \tilde{\drboutput} - e_1 - e_2$. Effectively, the protocol cannot tolerate any Byzantine participants without perfect synchrony.

\subsection{Commit-Reveal}
\label{subsection:commit-reveal}
A classic fix for the above issue is to introduce a cryptographic commitment step before each party reveals its entropy contribution.
\begin{enumerate}
\item \underline{Commit}. Each participant $P_i$ broadcasts a cryptographic commitment $C_i = \mathsf{Com}(e_i, r_i)$ (with fresh randomness $r_i$) to its entropy contribution $e_i$ rather than $e_i$ itself. Note that $\mathsf{Com}(x, r_0)$ denotes a cryptographic commitment to $x$ with hiding and binding properties~\cite{blum1983coin,damgaard1998commitment}.
\item \underline{Reveal}. Once all participants have shared their corresponding commitments, each participant $P_i$ then opens its commitment by revealing the pair $(e_i, r_i) = \mathsf{Open}(e_i, r_i)$. In turn, $P_i$ verifies each received pair $(e_j, r_j)$ for $j \neq i$ by recomputing $C_j = \mathsf{Com}(e_j, r_j)$. Given that these checks pass, the final output $\drboutput$ can canonically be given by
\[
\drboutput = \sum_{i = 1}^n e_i
\]
all of which can be repeated to produce a DRB. If any of the checks do not pass, however, the protocol aborts.
\end{enumerate}

With the additional commit step, it becomes impossible for any participant to manipulate the output $\drboutput$, as their values are bound by commitments published before any participants reveal. Nonetheless, the protocol can still be biased, as the last participant $P_k$ to reveal can in fact compute $\drboutput$ earlier than others and hence can decide not to reveal $(e_k, r_k)$ if $\drboutput$ is not to its liking. This is called the \textit{last-revealer attack}. Note that this attack is indistinguishable from a faulty node going offline, and indeed the protocol also has no robustness against non-Byzantine faults in this basic form.

\subsection{Ideal Distributed Randomness Beacon}
Clearly, a DRB should prevent any one participant from tampering with (e.g. predicting, biasing, or aborting) each round's output. The beacon output should also be verifiable by any third party. Based on these requirements, the overall security properties of an ideal DRB are given by the following.

\begin{definition}[Ideal distributed randomness beacon]
\todo{rewrite definitions based on $\adv = (\adv_0, \adv_1, \adv_2)$ and $\drboutput_b$ where $\drboutput_1 \gets \Pi_{\adv_1, \chal_1}$ vs $\drboutput_0 \gets \Pi_{\chal_0}$}
A distributed randomness beacon is \textit{ideal} or \textit{secure} if it satisfies the following four properties.
\begin{enumerate}
\item Bias Resistance (or Unbiasability). No PPT adversary $\adv$ can bias any $c$ bits of $\drboutput_r$. In other words, $\adv$ cannot force $c$ bits of $\drboutput_r$ to be some arbitrarily chosen bits with probability greater than $\frac{1}{2^c} + negl(\lambda)$.
\item Unpredictability. Similarly, $\adv$ cannot predict any $c$ bits of $\drboutput_r$ with probability greater than $\frac{1}{2^c} + negl(\lambda)$. The protocol satisfies \textit{$d$-unpredictability}~\cite{bhat2020randpiper} for $d \in \mathbb{N}$ if this is true for any round greater than or equal to $r + d$ (where $r$ denotes the current round).
\item Liveness. A la game-based security, we can define liveness~\cite{guo2020secRand} by requiring that the advantage of $\adv$ denoted by $Pr[\drboutput_r = \text{$\perp$}]$ (i.e. the probability that the honest beacon output at the end of round $r$ is null) is negligible, given a DRB that runs among honest participants and $\adv$.
% \item Public Verifiability. Any third party should be able to verify the beacon output based on public information. See Appendix \ref{appendix:pv} for a game-based formulation.
\end{enumerate}
\end{definition}

We next begin our discussion of various approaches to realizing an ideal DRB, starting with protocols based on verifiable delay functions.

\section{VDF-Based Protocols}
\label{section:vdf}
One way to prevent the last-revealer attack is to add a delay function after collecting each node's entropy contribution, delaying the derivation of $\drboutput_r$. As long as the delay is suitably long, no participant can predict what effect its contribution will have on the output before its share must be published. A verifiable delay function (VDF)~\cite{boneh2018verifiable,boneh2018survey} can be used to accomplish this.

\begin{definition}[Verifiable delay function]
A \textit{verifiable delay function} (VDF) is a function that takes a specified number of sequential steps to compute (even with a large amount of parallelism available) but takes exponentially less time to verify once computed. It can be described by the following algorithms.
\begin{itemize}
\item $\mathsf{Setup}(\lambda, T) \rightarrow pp$ is a randomized algorithm that outputs public parameters $pp$ given security parameter $\lambda$ and time bound $T$.
\item $\mathsf{Eval}(pp, x) \rightarrow (y, \pi)$ outputs $y$ in $T$ sequential steps and a proof $\pi$ given $pp$ and an input $x$.
\item $\mathsf{Verify}(pp, x, y, \pi) \rightarrow \{0, 1\}$ outputs 1 if $y$ is the correct evaluation of the VDF on input $x$ and 0 otherwise.
\end{itemize}
\end{definition}

The two well-known VDF proposals, one due to Pietrzak~\cite{pietrzak2018simple} and the other due to Wesolowski~\cite{wesolowski2019efficient}, make use of the (believed) inherently sequential nature of repeated squaring in a group of unknown order.
VDFs can be used to derive unbiasable randomness either from existing, biasable protocols (e.g. commit-reveal or public implicit beacons) or as the building block for an entirely new protocol (like RandRunner~\cite{schindler2021randrunner}).

\subsection{Modifying Commit-Reveal}
\label{subsection:modifying-commit-reveal}
The Unicorn protocol~\cite{lenstra2015random} uses the Sloth function (a VDF precursor based on computing square roots modulo a prime) in a manner similar to commit-reveal. In fact, commitments are no longer needed; participants simply publish their entropy contributions directly. Unicorn can be improved using a VDF in place of Sloth to achieve an exponential gap between computation and verification times. We refer to this VDF-based Unicorn as \textit{Unicorn++}. It runs as follows.
\begin{enumerate}
    \item \textbf{Collect.} Every participant $P_i$ broadcasts its entropy contribution $e_i$ between time $t_1$ and $t_2$ (assuming synchronized clocks). At $t_2$, they are combined into $seed_r = H(e_1,\ldots, e_n)$.
    \item \textbf{Evaluate.} Some party evaluates the VDF with $seed_r$ and a chosen delay parameter $T$ (part of $pp$) via
    $$y_r, \pi_r = \mathsf{VDF.Eval}(pp, seed_r)$$
    such that $\drboutput_r = H(y_r)$, which is posted and can be efficiently verified by any observer using $\pi_r$ via $\mathsf{VDF.Verify}$.
\end{enumerate}

As long as $T$ is longer than the duration of $t_2 - t_1$, Unicorn++ successfully defends against any attack possible by the last entropy provider. Also desirably, it is unbiasable by an adversary that controls $n - 1$ of the participants, as even one honest entropy contribution requires computation of $\mathsf{VDF.Eval}$ from scratch. The downside of the protocol is that \emph{somebody} must evaluate the VDF, which is slow by design (it does not matter for security who evaluates, since VDFs are deterministic and verifiable).
Thyagrajan et al.~\cite{thyagarajan2021opensquare} recently proposed a protocol for outsourcing VDF evaluation.

We quickly note a variation of above: as proposed in~\cite{bunz2017proofs, bonneau2015bitcoin}, beacons using stock prices~\cite{clark2010use} or PoW blockchains~\cite{nakamoto2008bitcoin, bentov2016bitcoin, han2020randchain} (which are otherwise susceptible to manipulation) can be used to supply $seed_r$ in Collect. Such schemes are collectively denoted by \textit{Ext. Beacon+VDF} in Table~\ref{table:comparison}.
Unfortunately, they do not easily compare to other DRBs, as the security model depends on the cost of manipulating the external beacon, which has not yet been formally analyzed.

% TODO: need to add Thyagarajan protocol\cite{Thyagarajan21timedcommitments}

\subsection{Chain of VDFs}
\label{subsection:randrunner}
The disadvantage of above is that each round may require consensus~\cite{castro1999practical} on inputs to the VDF, incurring communication cost. Also, the rate at which beacon outputs are generated is limited by $T$. RandRunner~\cite{schindler2021randrunner} tackles these issues by leveraging a VDF design that builds a deterministic chain of outputs (more precisely, a chain of $n$ interleaved VDFs each set up by a node) to bypass per-round consensus while allowing each round's duration to be independent of $T$ in the optimistic case. As a result, the protocol achieves lower communication complexity as well as more beacon outputs generated per time frame. Trapdoor VDFs~\cite{wesolowski2019efficient} with the strong uniqueness property~\cite{schindler2021randrunner} serve as its key building block.

\begin{definition}[Strongly unique trapdoor VDF]
A \textit{strongly unique trapdoor VDF} extends VDF by allowing any participant who knows the \textit{trapdoor} (e.g. $p, q$ for RSA's $N = p q$) to efficiently evaluate the VDF without $T$ sequential steps. Moreover, it provides \textit{strong uniqueness}, i.e. uniqueness even when VDF's public parameters are adversarially generated. It can be described by the algorithms $\mathsf{TVDF} = (\mathsf{Setup}, \mathsf{VerifySetup}, \mathsf{TrapdoorEval}, \mathsf{Eval}, \mathsf{Verify})$, extending those of a traditional VDF with the following.
\begin{itemize}
    \item $\mathsf{VerifySetup}(\lambda, pp) \rightarrow \{0, 1\}$ verifies the validity of $pp$.
    \item $\mathsf{TrapdoorEval}(pp, x, sk) \rightarrow (y, \pi)$ outputs $y$ in time less than $T$ (unlike $\mathsf{Eval}$) and a proof $\pi$ given $pp$, an input $x$, and the trapdoor $sk$.
\end{itemize}
\end{definition}

Wesolowski's VDF~\cite{wesolowski2019efficient} is not strongly unique, as knowing the trapdoor allows an adversary to forge proofs accepted by $\mathsf{VDF.Verify}$. As a result, RandRunner uses Pietrzak's VDF~\cite{pietrzak2018simple}. After an initial Setup phase, RandRunner reiterates its Execution phase as follows.
\begin{enumerate}
    \item \textbf{Setup.} Each participant $P_i$ executes $\mathsf{TVDF.Setup}$ to compute its public parameters $pp_i$ and the corresponding secret trapdoor $sk_i$ and broadcasts $pp_i$, which is verified by others via $\mathsf{TVDF.VerifySetup}$. This ensures that the uniqueness of Pietrzak's VDF is guaranteed. At the end, all participants should have the same set of public parameters $\{pp_i\}_{i = 1, ..., n}$. The initial value $\drboutput_0$ used to bootstrap the protocol is also agreed upon.
    \item \textbf{Execution.} A unique leader for round $r$, $l_r$ is selected via either round-robin (i.e. taking turns in some permuted order) or random selection (i.e. using $\drboutput_{r - 1}$ as seed, originally called randomized sampling). The implications of each are discussed in Section \ref{subsubsection:public-committee-selection}. Each round can proceed in two ways depending on $l_r$'s status.
    \begin{itemize}
        \item \textbf{Honest Leader (Common Case).} The leader advances the protocol into the next round by broadcasting
        $$y_r, \pi_r = \mathsf{TVDF.TrapdoorEval}(pp_{l_r}, H_1(\drboutput_{r - 1}), sk_{l_r})$$
        in which case other nodes check the correctness of the received values via $\mathsf{TVDF.Verify}$. Then the beacon output is
        $$\drboutput_r = H_2(y_r)$$
        where $H_1$ and $H_2$ map values from the beacon output space to the VDF space and vice versa.
        \item \textbf{Dishonest Leader.} Given a dishonest leader that withholds or broadcasts an invalid message, every non-leader computes and broadcasts the round's VDF output via
        $$y_r, \pi_r = \mathsf{TVDF.Eval}(pp_{l_r}, H_1(\drboutput_{r - 1}))$$
        in $T$ sequential steps. Then $\drboutput_r = H_2(y_r)$ similarly.
    \end{itemize}
\end{enumerate}

Consequently, RandRunner generates each beacon output rapidly with only $O(n)$ communication complexity in the common case. Adversarial leaders can increase the round duration to $T$ (or more with network delay $\Delta$) and the communication complexity to $O(n^2)$. Due to its \textit{pseudorandomness} (as opposed to \textit{true randomness}~\cite{cascudomt, das2021spurt}) sprouting from the deterministic nature of VDFs, RandRunner exhibits two other beneficial properties. First, liveness is retained even with a dishonest majority and when network connectivity breaks down completely, as a node can simply compute the beacon outputs over time via $\mathsf{TVDF.Eval}$. Second, it is impossible to bias the beacon once bootstrapped such that even the strongest adversary can only predict but not bias. These benefits have a counterpart, however. Namely, RandRunner can never achieve the ideal 1-unpredictability property due to the existence of leaders that can withhold and adversaries with higher compute power. In other words, the parameter $d$ as in RandRunner's $d$-unpredictability must be greater than one but can be calculated and bounded~\cite{schindler2021randrunner} depending on assumptions.

\section{Commit-Reveal-Punish}
\label{section:commit-reveal-punish}
Another approach to preventing last-revealer attacks are \textit{commit-reveal-punish} schemes, which assume that all participants are rational entities and use financial penalties to discourage withholding shares. This requires some form of \textit{escrow} (e.g. smart contracts on Ethereum~\cite{wood2014ethereum}) to collect initial deposits from the participants as part of their commitment, which can be \emph{slashed} (destroyed) or redistributed if misbehavior is detected. Commit-reveal-punish schemes defend against the last-revealer attack either by forcing every participant to reveal~\cite{youcai2017randao, andrychowicz2014secure, bentov2014use} or by tolerating some number of withholding participants via a threshold variant of commit-reveal~\cite{david2020economically}. These two approaches are summarized in the following.

\subsection{Enforcing Every Reveal}
Extending a basic commit-reveal, RANDAO~\cite{youcai2017randao} implements commit-reveal-punish in the most literal sense via punishing participants that withhold during the reveal phase by confiscating (and redistributing) each deposit of $m$ coins required during the initial commit phase. If no one withholds, all participants receive their deposits back, and all entropy contributions are aggregated and broadcast as $\drboutput_r$ as usual.

The drawback of protocols like RANDAO is two-fold. First, honest failures are also punished without much flexibility. Second, a high deposit of $m = O(n^2)$ is required to provide fairness in certain scenarios~\cite{andrychowicz2014secure, bentov2014use}. These imply that the protocol is suitable in cases where each participant is expected to be highly available and possess an ample supply of coins, but not otherwise.
Deploying these protocols in practice also requires an understanding of the value to participants of manipulating the beacon (to ensure the opportunity cost of lost deposits is higher). This assumption is reasonable for applications such as a lottery but may not apply for a public beacon whose use may not be known in advance.

% Note that it is possible to optimize in a lottery setting (i.e. where we choose a random winner not a number) such that constant or no deposits are required~\cite{bartoletti2017constant, miller2017zero} by constructing a binary-tree tournament consisting of $n - 1$ two-player lottery instances (which can be realized as per~\cite{andrychowicz2014fair,andrychowicz2014secure}) in $O(\log n)$ rounds where a participant automatically loses by not revealing. While this mechanism allows the protocol to tolerate withholding, it is unclear as to how to extend a random winner into a random number for the purpose of a DRB.

\subsection{Rational Threshold Commit-Reveal}
Economically Viable Randomness (EVR)~\cite{david2020economically} provides an alternative requiring constant deposits while tolerating (honest) faults to an extent. This is achieved by devising a threshold variant of commit-reveal (i.e. in which $t + 1$, as opposed to all $n$, nodes reveal to compute $\drboutput_r$) and having an incentive mechanism around it. The threshold nature also invites collusion, which is counteracted by EVR's \textit{informing} mechanism: if the escrow is notified of collusion (via informing), it rewards the informer and slashes the deposits of all others (\textit{collective punishment}). Realizing this, nodes are discouraged to collude, fearing another node within the collusion would inform.

EVR requires multiple cryptographic building blocks (many are used by other DRBs as well), which we introduce here. EVR uses Escrow-DKG~\cite{david2019rational}, an extension of DKG (distributed key generation)~\cite{pedersen1991threshold,gennaro1999secure}, to realize a threshold commit-reveal. DKG allows a set of $n$ nodes to collectively generate a pair $(sk, pk)$ of group secret and public keys such that $sk$ is shared and ``implied'' (i.e. never computed explicitly) by $n$ nodes via the following building blocks.

\begin{definition}[$(t, n)$-secret sharing]
A \textit{$(t, n)$-secret sharing} scheme (also known as Shamir's secret sharing~\cite{shamir1979share}) allows a dealer to share a secret $s = p(0)$ for some \textit{secret sharing polynomial} $p \in \mathbb{Z}_q[X]$ of degree $t$ among $n$ participants each holding a \textit{share} $s_i = p(i)$ for $i = 1, ..., n$. Any subset of $t + 1$ or more participants can reconstruct the secret $s$ via \textit{Lagrange interpolation} (see Appendix \ref{appendix:lagrange}), but smaller subsets cannot.
\end{definition}

\begin{definition}[Verifiable secret sharing]
\textit{Verifiable secret sharing} (VSS)~\cite{feldman1987practical, pedersen1991non} protects a $(t, n)$-secret sharing scheme against a malicious dealer sending incorrect shares by providing an additional verification step per share. VSS can be described by the following algorithms.
\begin{itemize}
    \item $\mathsf{Setup}(\lambda) \rightarrow pp$ generates the public parameters $pp$, an implicit input to all other algorithms.
    \item $\mathsf{ShareGen}(s) \rightarrow (\{s_i\}, C)$ is executed by the dealer with secret $s$ to generate secret shares $\{s_i\}$ (each of which is sent to node $i$ correspondingly) as well as commitment $C$ to the secret sharing polynomial of degree $t$.
    \item $\mathsf{ShareVerify}(s_i, C) \rightarrow \{0, 1\}$ verifies the correctness of the share $s_i$ using $C$.
    \item $\mathsf{Recon}(A, \{s_i\}_{i \in A}) \rightarrow s$ reconstructs $s$ via Lagrange interpolation from a set $A$ of $t + 1$ nodes that pass $\mathsf{ShareVerify}$.
\end{itemize}
See Appendix \ref{appendix:vss} for details.
% Feldman-VSS and Pedersen-VSS are two of the most popular VSS protocols. See Appendix \ref{appendix:vss} for details.
\end{definition}

\begin{definition}[Distributed key generation]
A \textit{distributed key generation} (DKG)~\cite{pedersen1991threshold,gennaro1999secure} allows $n$ participants to collectively generate a \textit{group public key} (for an implied \textit{group secret key}), \textit{individual secret keys}, and \textit{individual public keys} without a trusted third party. It does so by running $n$ instances of VSS (with each participant acting as a dealer for its independent secret). Unlike secret sharing schemes, DKG can be used repeatedly for an unlimited number of times, as the group secret key does not need to be computed explicitly.
\begin{itemize}
    \item $\mathsf{DKG}(1^\lambda, t, n) \rightarrow (sk_i, pk_i, pk)$ outputs the $i$-th node's secret key, its public key (e.g. $pk_i = g^{sk_i}$), and a group public key $pk$ (e.g. $pk = g^{sk}$) for an implied group secret key $sk$ given security parameter $1^\lambda$, $n$, and threshold parameter $t$.
\end{itemize}
See Appendix \ref{appendix:dkg} for details.
% Joint-Feldman and Joint-Pedersen are two of the most popular DKG protocols. See Appendix \ref{appendix:dkg} for details.
\end{definition}

\begin{definition}[Escrow-DKG]
Escrow-DKG~\cite{david2019rational} is a rational variant of DKG with the following variations.
\begin{itemize}
    \item Unlike traditional DKG, Escrow-DKG does not a priori assume a $t$-limited adversary. However, it assumes the participants are rational in a setting where collusion of more than $t$ participants would be financially punished such that, effectively, we have a $t$-limited adversary.
    \item It assumes an escrow denoted by $\mathcal{G}$.
    \item Escrow-DKG has a deposit requirement, considers how a DKG may fail, and associates a financial penalty to each failure case to disincentivize misbehavior.
\end{itemize}
\end{definition}

The crux is that EVR adapts Escrow-DKG to realize a DRB by using the group secret (i.e. the implied group secret key $sk$ after a DKG) as $\drboutput_r$, retrievable from $t + 1$ $sk_i$'s. EVR proceeds in four phases---Setup, Commit, Inform, and Reveal.
\begin{enumerate}
    \item \textbf{Setup.} Every participant registers by depositing 1 coin per secret (i.e. entropy contribution), and $\mathcal{G}$ accordingly sets the threshold parameter $t = 2n / 3$ required for Escrow-DKG. It also sets the \textit{illicit profit bound} (i.e. bound on extra profit an adversary can gain as a result of using EVR's beacon output as opposed to an ideal beacon's output) $P = n - t = n / 3$ and the \textit{informing reward} $\ell = n$.
    \item \textbf{Commit.} Escrow-DKG is run, and each participant ends up with an individual key pair $(sk_i, pk_i)$ as well as $pk$.
    \item \textbf{Inform.} Any colluding participant that preemptively knows $\drboutput_r$ can inform $\mathcal{G}$ to earn a high informing reward ($\ell$) obtained via collective punishment. Due to this phase, the incentive is that no one should collude.
    \item \textbf{Reveal.} $\drboutput_r = sk$ is reconstructed once $t + 1$ (or more) honest participants reveal their $sk_i$'s. Initial deposits are returned after verification by $\mathcal{G}$. If $\drboutput_r$ is not reconstructed by the end, $\mathcal{G}$ also initiates collective punishment.
\end{enumerate}

While a node's malicious behaviors in EVR are limited to withholding to abort the protocol during Reveal or colluding to learn $\drboutput_r$ before Reveal, its security comes from the fact that both are disincentivized. First, setting $P = n - t$ makes withholding unprofitable, as $n - t$ or more participants that withhold to successfully abort EVR would earn at most $P$ at the cost of losing their deposits. This prevents biasability. Second, setting $\ell = n$ makes informing more profitable than any illicit profit such that any coalition of nodes colluding to preemptively learn $\drboutput_r$ is disincentivized due to the inevitability of an informer. This prevents predictability.

Despite the benefits of the threshold nature and constant deposits enabling a flexible incentive mechanism, EVR requires further economic assumptions beyond those needed for commit-reveal-punish. Specifically, EVR assumes a limit $P$ on illicit profit and a bound on the total number of coins $n / 3$ (a participant with more coins than this is not allowed to join EVR as per decentralization assumption~\cite{david2020economically}).

\section{Commit-Reveal-Recover}
\label{section:commit-reveal-recover}
Without an escrow to enforce desired behaviors, commit-reveal-recover variants extend commit-reveal and defend against the last-revealer attack by providing a mechanism to \textit{recover} or \textit{reconstruct} a participant's entropy contribution if withheld. This can be achieved by either threshold secret sharing or threshold encryption. Protocols based on commit-reveal-recover assume a $t$-limited adversary and require the cooperation of at least $t + 1$ nodes to reconstruct such that two desirable properties are achieved simultaneously: there is no need for all $n$ nodes to reveal while any subset of $t$ Byzantine nodes cannot collude to preemptively reconstruct. Note that there is an inherent tradeoff here: while a smaller value of $t$ provides greater fault tolerance, it also means that a smaller subset can collude to predict the beacon output in advance.
% "greater honest fault tolerance"

\subsection{From Threshold Secret Sharing}
Building on $(t, n)$-secret sharing, commit-reveal-recover variants based on threshold secret sharing often use PVSS (publicly verifiable secret sharing)~\cite{schoenmakers1999simple, cascudo2017scrape} as a subprotocol in order to allow any external party (not just the participants) to verify the correctness of sharing and reconstruction.

\begin{definition}[Publicly verifiable secret sharing]
\textit{Publicly verifiable secret sharing} (PVSS) extends VSS by enabling public verification. It can be realized by the algorithms $\mathsf{PVSS} = (\mathsf{Setup}, \mathsf{KeyGen}, \mathsf{Enc}, \mathsf{Dec}, \mathsf{ShareGen}, \mathsf{ShareVerify}, \mathsf{Recon})$, extending those of VSS. To provide public verifiability, PVSS requires $\mathsf{PVSS.ShareGen}$ to use keys (secret-public key pair per participant) generated by $\mathsf{PVSS.KeyGen}$ to encrypt and decrypt shares via $\mathsf{PVSS.Enc}$ and $\mathsf{PVSS.Dec}$ as subroutines and to generate proofs, e.g. NIZK (non-interactive zero-knowledge) proofs, for public verification as another subroutine. Then $\mathsf{PVSS.ShareVerify}$ can be run by anyone (not just the participants). See Appendix \ref{appendix:pvss} for details.
\end{definition}

The idea in these commit-reveal-recover variants is that each participant generates a secret (i.e. entropy contribution), distributes PVSS shares to each other participant, and receives $n$ respective shares of $n$ other participants' secrets. These shares are then used to compute $\drboutput_r$ via Lagrange interpolation ($\mathsf{PVSS.Recon}$) in case some nodes withhold. Based on when and how such Lagrange interpolation takes place, we subdivide the protocols into the following categories: commit-reveal-recover, share-reconstruct-aggregate, and share-aggregate-reconstruct.

\subsubsection{Commit-Reveal-Recover}
Extending commit-reveal, \textit{commit-reveal-recover} adds another step to the commit phase where every participant is additionally required to distribute PVSS shares of its corresponding secret so that others can reconstruct it via Lagrange interpolation (\textit{recover}) if withheld during reveal. The tradeoff is additional communication cost, which could be amplified multiplicatively in the recover phase if $O(n)$ Lagrange interpolations need to take place. Scrape~\cite{cascudo2017scrape} adopts this technique.\\

\noindent\textbf{Scrape.} Scrape introduces its own PVSS scheme~\cite{cascudo2017scrape} specifically designed for efficiency in commit-reveal-recover. The initial setup for Scrape requires generating $(sk_i, pk_i)$ for each of the $n$ participants using $\mathsf{PVSS.KeyGen}$. The protocol then proceeds as follows.
\begin{enumerate}
\item \textbf{Commit.} Every participant $P_j$ executes $\mathsf{PVSS.ShareGen}(s^{(j)})$ as a dealer and publishes the encrypted shares $\mathsf{Enc}(pk_i, s^{(j)}_i)$ for $1 \le i \le n$ and encryption proofs. $P_j$ also publishes a commitment to the secret exponent $\mathsf{Com}(s^{(j)}, r_j)$ (with fresh randomness $r_j$).
\item \textbf{Verify.} For every set of published encrypted shares and proofs, all participants run $\mathsf{PVSS.ShareVerify}$ to verify correct encryption. Let $\committee_r$ be the set of all participants with published commitments and valid shares.
\item \textbf{Reveal.} Once $t + 1$ participants have distributed their commitments and valid shares, every participant $P_j$, $j \in \committee_r$ opens its commitment, and shares $\mathsf{Open}(s^{(j)}, r_j)$.
\item \textbf{Recover.} For every participant $P_a \in \committee_r$ that withholds $\mathsf{Open}(s^{(a)}, r_a)$ in Reveal phase, other participants $P_j$ for $j \neq a$ reconstruct $h^{s^{(a)}}$ via $\mathsf{PVSS.Recon}$, which requires each participant to publish its decrypted share $h^{s_j^{(a)}}$ and the proof of correct decryption passing $\mathsf{PVSS.ShareVerify}$.
\item \textbf{Aggregate.} The final randomness is $\drboutput_r = \prod_{j \in \committee_r} h^{s^{(j)}}$.
\end{enumerate}

Note that Scrape, in the optimistic case (without Recover), is basically a commit-reveal with $O(n^2)$ PVSS shares distributed in the network during commit, $O(n)$ per node. In the worst case (with Recover), it requires an entirely new round of communication and potentially $O(n)$ Lagrange interpolations.\\

\noindent\textbf{Albatross.} Extending Scrape, Albatross~\cite{cascudo2020albatross} provides an improved amortized communication complexity of $O(n)$ per beacon output by generating a batch of $O(n^2)$ beacon outputs per round (as opposed to Scrape's one). This is achieved by two techniques: packed Shamir secret sharing and linear $t$-resilient functions~\cite{cascudo2020albatross}, each of which contributes a multiplicative factor of $O(n)$ to the number of beacon outputs produced per round.

\subsubsection{Share-Reconstruct-Aggregate}
Another approach is to skip the commit-reveal phase and by default reconstruct each secret shared via PVSS. In other words, we can remove the $\mathsf{Com}(s^{(j)}, r_j)$ portion from Scrape's commit (\textit{share}), perform Lagrange interpolation per secret for a total of $O(n)$ times (\textit{reconstruct}), and sum up the interpolated secrets to output $\drboutput_r$ (\textit{aggregate}). While the resulting \textit{share-reconstruct-aggregate} saves a round of communication from Scrape's worst case, its average case does incur substantial communication cost due to $O(n)$ Lagrange interpolations, each of which requires cooperation of $t + 1$ nodes. Hence, this approach is preferable when it can be assumed that most rounds will require recovery due to faulty participants. RandShare~\cite{syta2017scalable} uses this technique alongside a Byzantine agreement protocol to reach consensus on $O(n)$ secrets to be reconstructed.

\subsubsection{Share-Aggregate-Reconstruct}
Another alternative is to harness the homomorphic property of PVSS where the sum of $n$ respective shares of $n$ secrets is a share of the sum of $n$ secrets (note that the sum of $n$ secrets is precisely $\drboutput_r$ in these protocols). Due to this homomorphism, only one, as opposed to $O(n)$, Lagrange interpolation can be used to reconstruct $\drboutput_r$ if nodes essentially perform the \textit{aggregate} phase before the \textit{reconstruct} phase, hence the name \textit{share-aggregate-reconstruct}. SecRand~\cite{guo2020secRand} uses this technique to reduce the communication complexity by a factor of $n$ during reconstruction as only $t + 1$ aggregated shares are exchanged to compute $\drboutput_r$.

\subsection{From Threshold Encryption}
While protocols based on threshold secret sharing can incur high communication cost of $O(n^4)$ due to $O(n)$ Lagrange interpolations, protocols relying on a different cryptographic primitive, namely threshold encryption~\cite{desmedt1990Threshold}, offer a variant where only one Lagrange interpolation suffices even in the worst case. Though reminiscent of share-aggregate-reconstruct, these protocols differ in that they do not necessarily assume a PKI (mandatory in PVSS) but rather a DKG, which may be run multiple times to refresh keys. In this section, we define threshold encryption and summarize how a protocol like HERB~\cite{cherniaeva2019homomorphic} uses it to construct a DRB.

\begin{definition}[$(t, n)$-threshold encryption]
A \textit{$(t, n)$-threshold encryption} scheme uses DKG among $n$ nodes as a subroutine and allows encryption of a message under the resulting group public key $pk$ such that the message can be decrypted by any $t + 1$ of the $n$ nodes, but not less. The scheme ($\mathsf{ThrEnc}$) is composed of the following algorithms.
\begin{itemize}
    \item $\mathsf{DKG}(1^\lambda, t, n) \rightarrow (sk_i, pk_i, pk)$ runs a typical DKG.
    \item $\mathsf{Enc}(pk, m) \rightarrow c$ encrypts message $m$ with group public key $pk$ and outputs ciphertext $c$.
    \item $\mathsf{DecShare}(sk_i, c) \rightarrow d_i$ generates decryption share $d_i$ for ciphertext $c$ using individual secret key $sk_i$.
    \item $\mathsf{Rec}(A, c, pk, \{pk_i\}_{i \in A}, \{d_i\}_{i \in A}) \rightarrow m$ takes ciphertext $c$, $pk$, and a set $A$ of $t + 1$ nodes with valid decryption shares along with their individual public keys and recovers the message $m$ via Lagrange interpolation.
\end{itemize}
\end{definition}

HERB uses threshold ElGamal encryption~\cite{desmedt1990Threshold, fouque2001threshold} (see Appendix \ref{appendix:thrElGamal} for details) though it can be replaced with any other threshold homomorphic encryption scheme. After an initial DKG ($\mathsf{ThrEnc.DKG}$), the protocol proceeds in two phases. In the first phase, nodes play the role of \textit{entropy providers} each offering some entropy contribution to generate a group ciphertext. In the second phase, nodes play the role of \textit{key holders} performing threshold decryption. While entropy providers and key holders could technically be different nodes, we assume they are the same below.

\begin{enumerate}
    \item \textbf{Publication.} Each entropy provider $P_j$ encrypts its entropy contribution $m_j$ using $\mathsf{ThrEnc.Enc}$ to generate a ciphertext share $c_j$, published along with a proof of correct encryption $\pi_{CE}^{(j)}$ (Appendix \ref{appendix:ce}) to account for malleability~\cite{dolev2003nonmalleable}. When $\committee_r$ (the agreed set of nodes with verified published $c_j$'s) reaches a certain size (based on system parameters), the included $c_j$'s are summed into group ciphertext $c$ corresponding to group plaintext $m$ (which is in turn a sum of $m_j$'s).
    \item \textbf{Disclosure.} Each key holder $P_i$ uses $\mathsf{ThrEnc.DecShare}$ to generate a decryption share $d_i$, published along with a proof of correct decryption $\pi_{DLEQ}^{(i)}$ (Appendix \ref{appendix:dleq}). When $t + 1$ decryption shares are published and verified, nodes use $\mathsf{ThrEnc.Rec}$ to output $\drboutput_r = m$.
\end{enumerate}

Similar to SecRand's share-aggregate-recover, HERB achieves a communication complexity of $O(n^2)$ and $O(n^3)$ in the optimistic and worst cases, respectively, due to one needed Lagrange interpolation per $\drboutput_r$. Its requirement of DKG in the setup presents a caveat however, as a new DKG must take place for any attempt to refresh keys of participants, e.g. in case of a suspected hack or a simple \textit{reconfiguration} in which the set of participants changes. This can incur additional cost per DKG. On the flip side, HERB provides the advantage that entropy providers need not be key holders (as noted before), meaning that the level of security and randomness quality can be adjusted independently if necessary.

\section{Committee-Based Protocols}
\label{section:committee-based}
While all aforementioned commit-reveal variants (Sections \ref{subsection:modifying-commit-reveal}, \ref{section:commit-reveal-punish}, and \ref{section:commit-reveal-recover}) include every node in each entropy-providing committee $\committee_r$, this introduces a scalability problem. Requiring communication of marginal entropy by all nodes is inefficient with large numbers of participants, and hence a natural optimization is to use a smaller subset of nodes $\committee_r$ in each round to contribute entropy (i.e. reduce $|\committee_r|$).

In this section, we consider DRBs that are committee-based, where a \emph{committee} refers to a non-empty proper subset of nodes. Committee-based protocols proceed in two steps: \textit{committee selection} and \textit{beacon output generation}. As the names suggest, $\committee_r$ is agreed upon during committee selection while the beacon output $\drboutput_r$ is generated and agreed upon during beacon output generation.
%Provided below is a summary of ten preexisting protocols, and we offer intuition (refer to corresponding citations for full details) on interpreting them under our simple framework.
We observe that committee selection and beacon output generation are, at least theoretically, modular such that subprotocols can be independently chosen for the two components. We visualize these two dimensions of committee-based DRBs in Table \ref{table:committee-based}. We also observe that the protocols introduced so far (e.g. commit-reveal-recover) can be used as a module in a larger committee-based protocol, with the chosen committee executing the chosen protocol in each round.

\subsection{Step 1. Committee Selection}
The first step of a committee-based DRB involves selecting $\committee_r$ in a way agreeable by all nodes. We classify committee selection mechanisms into two: public and private.

\subsubsection{Public Committee Selection}
\label{subsubsection:public-committee-selection}
In a \textit{public committee selection}, only public information is needed to derive $\committee_r$.\\

\noindent\textbf{Round-Robin (RR).} A first example is \textit{round-robin} (RR), in which nodes simply take turns being selected such that there is no notion of hierarchy among nodes. While RR can work with committees of any size, typically RR is used to select a committee of size one (i.e. a leader) corresponding to node $i \equiv r \pmod n$. Protocols like BRandPiper~\cite{bhat2020randpiper} (in which the round leader is the only active entropy provider) adopt RR as their leader selection mechanism due to its innate fairness property~\cite{azouvi2018winning} (also known as chain quality~\cite{garay2015bitcoin} in the blockchain context) where all nodes, by RR's definition, take equal leadership.\\
%Looking ahead, RR is vulnerable against an adaptive adversary, which can predict in advance which nodes to corrupt to control a committee in a given round. Thus, it is important that RR not assume any committee (or leader) is honest.\\

\noindent\textbf{Random Selection (RS).} A second example is \textit{random selection} (RS), which uses some public randomness (most commonly the last beacon output $\drboutput_{r - 1}$) to derive $\committee_r$.
%While RR is simple and deterministic, RS is randomized.
In HydRand~\cite{schindler2020hydrand} and GRandPiper~\cite{bhat2020randpiper}, for instance, $\committee_r$ consists of a node $i \equiv \drboutput_{r - 1} \pmod{\tilde{n}}$ where $\tilde{n}$ is the number of eligible nodes. Similar is the process in Ouroboros~\cite{kiayias2017ouroboros} called follow-the-satoshi~\cite{bentov2014proof,kiayias2017ouroboros}, which can output more than one node in $\committee_r$.

Randomized selection means that some nodes may, in theory, never be selected and therefore may never be able to provide entropy contribution. A more serious concern is that an adversary can attempt to bias, via grinding attack, $\drboutput_r$ in order to bias $\committee_{r + 1}$ (which can bias $\drboutput_{r + 1}$). In the worst case, this can lead to a vicious cycle in which an adversary controlling enough nodes on the current committee to manipulate the beacon output can ensure it will also control enough nodes on the next committee, and so on ad infinitum.

This is not an issue in RR, as its committee selection is deterministic and independent of the preceding beacon output. Nonetheless, a tradeoff of RR is that DoS attack becomes indefinitely possible (for all rounds $\tilde{r}$ for $\tilde{r} > r$ given $\drboutput_r$) since each committee is publicly known in advance. All in all, RR gains unbiasability (due to determinism) at the cost of indefinite DoS attack while RS benefits from less DoS attack, i.e. that only for round $r + 1$ (due to randomization given $\drboutput_r$), at the cost of grinding attack.\\

\noindent\textbf{Leader-Based Selection (LS).} A third example, \textit{leader-based selection} (LS) is a hybrid method that exhibits both determinism and randomization. It runs in two steps: the first step involves electing a round leader (either by RR or RS) while the second involves selection of $\committee_r$ by the elected leader. It is in this way that the mechanism is deterministic from the leader's perspective while randomized from that of others.

One approach to limit the power delegated to the leader is that $|\committee_r|$ needs to be greater than $t$ so that a malicious leader wouldn't be able to choose $\committee_r$ maliciously. RandHound~\cite{syta2017scalable} and SPURT~\cite{das2021spurt} demonstrate such LS.
\begin{itemize}
\item RandHound. As instantiated in RandHerd~\cite{syta2017scalable}, RandHound's leader election (i.e. via RS as the first step of LS) involves a public lottery where each node generates a lottery ticket $t_i = H(C \mathbin\Vert pk_i)$ given a public configuration parameter $C$ (assuming its randomness) such that the owner of $min(t_i)$ becomes the leader (originally called client). In the second step of LS, RandHound adopts a form of sharding (involving PVSS groups). The leader selects more than a threshold number of nodes in each shard (PVSS group), guaranteeing a threshold number of entropy providers across all shards.
\item SPURT. Unlike RandHound, SPURT adopts RR as its first part of LS such that nodes simply take turns being a round leader. Then the leader chooses $\committee_r$ based on received encrypted messages.
\end{itemize}

Given an underlying DRB that utilizes the concept of a leader as an orchestrator of communication among nodes, LS is a natural choice to committee selection, as a leader helps mitigate the protocol's communication cost overall.

\subsubsection{Private Committee Selection}
\label{subsubsection:private-committee-selection}
In a \textit{private committee selection}, also known as \textit{private lottery}, each node needs to input some private information (e.g. secret key) in order to check whether or not it has been selected into $\committee_r$ (i.e. has won the lottery). The general formulation of a private lottery can be given by
\[
f_{priv}(\cdot) < target
\]
where $f_{priv}(\cdot)$ is a lottery function (i.e. pseudorandom function) that takes some private input $priv$ and $target$ denotes the lottery's ``difficulty level'' (a la Proof of Work difficulty) such that $target$ can be adjusted to make the lottery arbitrarily easy or hard to win. Each node calculates $f_{priv}(\cdot)$ and checks if the above inequality is satisfied, in which case it ``wins'' the lottery and becomes an entropy provider.

As it is possible for an adversary to perform a grinding attack by trying many values of $priv$ until a desirable function output is achieved, one crucial requirement is that $priv$ should be provably committed in the past and thus be ungrindable at the time of computation of $f_{priv}(\cdot)$. Two examples of the above formulation exist in the landscape: a VRF-based lottery and Caucus'~\cite{azouvi2018winning} lottery involving a hash chain.\\

\noindent\textbf{VRF-based approach.} In Algorand~\cite{gilad2017algorand}, a VRF (verifiable random function)~\cite{micali1999verifiable,dodis2005verifiable} is used in each round to realize a lottery. (While there exist more than one version of Algorand's private lottery algorithm, we consider its first version, as the versions do not differ fundamentally.) Quite naturally, one's private input to $VRF_{sk}(\cdot)$ is its secret key such that the lottery is given by
\[
VRF_{sk}(\drboutput_{r - 1} \mathbin\Vert role) < target
\]
where $role$ is some parameter specific to Algorand. As both $\drboutput_{r - 1}$ and $role$ are already public and ungrindable at the time of computation, Algorand makes sure $sk$ is likewise ungrindable by requiring that $sk$ is committed a certain number of rounds in advance. Similar are private lotteries for protocols like Ouroboros Praos~\cite{david2018ouroboros} and NV (from Nguyen-Van et al.~\cite{nguyen2019scalable}). See Table \ref{table:committee-based} for details.\\

\noindent\textbf{Replacing VRF with $H(\cdot)$ and hash chain.} In Caucus, the VRF is replaced by a hash function and a hash chain, i.e. a list ($h_1, ..., h_m$) with $h_r = H(h_{r + 1})$ for all $r = 1, ..., m - 1$ where $h_m = s$ for some random seed. A hash chain provides the functionality of provably committing to private inputs as one can publicize one $h_r$ at a time (i.e. $h_r$ in round $r$) such that doing so commits to $h_{r + 1}$. Thus, each participant of Caucus independently generates a private hash chain comprising $m$ private inputs such that the lottery is given by
\[
H(h_r \oplus \drboutput_{r - 1}) < target
\]
which simply involves a hash function. One downside is that the hash chain needs to be periodically regenerated, as $m$ is finite while we desire our DRB to run indefinitely. Verifying a winning ticket in Caucus also requires work linear in the length of the hash chain (though a tree-based structure could make this cost logarithmic).\\

Private lotteries provide two notable benefits: resilience to DoS attack (due to its property of delayed unpredictability~\cite{azouvi2018winning} where one cannot predict the eligibility of honest nodes until they reveal) and \textit{independent participation} (i.e. nodes do not have to know other participants in advance to participate) allowing less communication cost as well as a more permissionless setting. Nonetheless, it can introduce the possibility of biasing via withholding (as discussed in Section \ref{subsection:withholding}).

\subsection{Step 2. Beacon Output Generation}
\label{subsection:beacon-output-generation}
Given a committee $\committee_r$, the issue then shifts to outputting $\drboutput_r$. While a typical commit-reveal-recover run among nodes in $\committee_r$ may be sufficient to realize a DRB, other approaches provide different tradeoffs. Largely, we classify these variations into two: one that requires \textit{fresh} (independently generated on the spot) per-node entropy (contribution) and one that combines previous beacon output with \textit{precommitted} (independently generated but precommitted, hence ungrindable) per-node entropy.

\subsubsection{Fresh Per-Node Entropy}
\label{subsubsection:fresh}
Beacon output generation process involving fresh (also referred to as true randomness~\cite{cascudomt, das2021spurt} as opposed to pseudorandomness) per-node entropy for committee-based protocols is typically a commit-reveal-recover variant from Section \ref{section:commit-reveal-recover}. Some protocols in this family include the following.\\

\noindent\textbf{Share-Reconstruct-Aggregate.} In Ouroboros, nodes in $\committee_r$ (i.e. slot leaders of epoch $r$) perform a RandShare-style share-reconstruct-aggregate using PVSS to output $\drboutput_r$. RandHound uses a similar approach, facilitated by a round leader.\\

\noindent\textbf{Share-Aggregate-Reconstruct.} In SPURT and BRandPiper, nodes in $\committee_r$ perform a SecRand-style share-aggregate-reconstruct to output $\drboutput_r$. BRandPiper has a twist, however: it utilizes the idea of buffering PVSS shares in advance. While there exists one entropy provider per round, $n$ secrets (one from each node) are combined such that it provides the ideal 1-unpredictability property as opposed to $t$-unpredictability (as in HydRand or GRandPiper). The trick is that each round leader generates $n$ fresh secrets that become combined with others' secrets in the next $n$ rounds, respectively. One node distributes $O(n^2)$ PVSS shares (buffered by other nodes) per round in BRandPiper whereas, in a typical share-aggregate-reconstruct like SPURT, each of $O(n)$ nodes distributes $O(n)$ PVSS shares per round (with no buffering).\\

\noindent\textbf{From Threshold Encryption.} Similar to HERB, entropy providers in NV~\cite{nguyen2019scalable} contribute their fresh entropy using ElGamal although they use its classical, non-threshold version due to NV's centralized model in which a third party called the Requester is the direct recipient of a beacon output. As a result, each entropy provider generates and encrypts its entropy and sends it to the Requester, which then decrypts all the messages received from entropy providers and outputs their sum as $\drboutput_r$. Naturally, this Requester version of NV can be modified into what we call \textit{NV++}, which differs from NV in two ways. First, nodes in $\committee_r$ (once finalized) can be made to perform HERB among themselves. This eliminates the existence of the centralized Requester. Second, entropy provision (i.e. broadcasting one's entropy) can be coupled with proof of membership to $\committee_r$ (i.e. broadcasting the fact that a node has won the VRF private lottery). In NV, these two are separate steps potentially incurring adaptive insecurity (a concept delineated in Section \ref{subsection:adaptive}). Thus, NV++ distributes the Requester and achieves adaptive security.

\subsubsection{Combining Previous Output and Precommitted Per-Node Entropy}
\label{subsubsection:precommitted}
To optimize and lower communication cost, we can require generally less input from entropy providers each round. The canonical optimization involves utilizing $\drboutput_{r - 1}$ as a source of entropy to produce $\drboutput_{r}$. Nonetheless, the caveat in doing so is that grinding attack may become a possibility once $\drboutput_{r - 1}$ becomes public, which is why it is necessary to require entropy providers' contribution for round $r$ to be precommitted before combining with $\drboutput_{r - 1}$ to output $\drboutput_r$. This prevents grindability while taking advantage of the convenience of $\drboutput_{r - 1}$. Such a requirement can be observed in many committee-based protocols, even though their details seem unrelated on the surface.
\begin{itemize}
\item HydRand and GRandPiper. Each round, an entropy provider (i.e. round leader) in HydRand commits its entropy that becomes opened in the next round it is selected as the leader again. In other words, the round leader's precommitted entropy $e_{\tilde{r}}$ from its last round $\tilde{r}$ of leadership is the one that becomes combined with $\drboutput_{r - 1}$ in the form of $h^{e_{\tilde{r}}}$ to generate
\[
\drboutput_r = H(\drboutput_{r - 1} \mathbin\Vert h^{e_{\tilde{r}}})
\]
while PVSS recovery is used in case the leader fails to open $e_{\tilde{r}}$ in round $r$. Notable in HydRand is the fact (achieving ungrindability of $h^{e_{\tilde{r}}}$) that one honest node must be present in any $t + 1$ consecutive rounds due to the requirement that a leader cannot gain another leadership in the next $t$ rounds. Similar overall is GRandPiper's beacon output generation (see Table \ref{table:committee-based}).
\item Algorand and Ouroboros Praos. These schemes use a VRF for beacon output generation (rather than only for committee selection as in NV++). The secret key $sk$ of the round leader often corresponds to precommitted per-node entropy as long as the assumption that nodes cannot switch their $sk$ at the time of VRF's computation holds. Algorand's beacon output is therefore given by
\[
\drboutput_r = VRF_{sk}(\drboutput_{r - 1} \mathbin\Vert r)
\]
combining the previous output $\drboutput_{r - 1}$ with the precommitted entropy $sk$. Note that the input to the VRF in beacon output generation is different from that in committee selection, as the VRF output in committee selection is always going to be less than $target$ by design. Ouroboros Praos' beacon output is generated similarly (see Table \ref{table:committee-based}).
\item Caucus. Each new reveal ($h_r$ in round $r$) from an entropy provider's private hash chain in Caucus corresponds to that node's precommitted entropy. The beacon output is given by
\[
\drboutput_r = h_r \oplus \drboutput_{r - 1}
\]
such that it naturally follows its committee selection mechanism $H(h_r \oplus \drboutput_{r - 1}) < target$.
\end{itemize}

\section{Protocols With No Marginal Entropy}
\label{section:dvrf}
While DRBs can have all nodes or some subset of nodes contribute entropy to the beacon output every round, it is possible to devise a protocol where no node contributes any marginal entropy as the beacon runs. The advantage of this approach is that no node needs to generate and communicate any fresh entropy (which alleviates communication cost) while the disadvantage is that the entire beacon is permanently predictable once compromised (perhaps undetectably).

\subsection{From Distributed Verifiable Random Function}
Guaranteeing randomness entirely via pseudorandomness, such DRB can be based on distributed VRF~\cite{hanke2018dfinity,galindo2020fully} (DVRF, also known as threshold VRF or TVRF~\cite{cascudomt}). The idea is that the VRF's $sk$ is distributed among $n$ nodes via DKG such that $t + 1$ nodes can cooperate to compute a per-round VRF output (as well as its proof), as if the computation involves one master node with access to $sk$.

\begin{definition}[Distributed verifiable random function]
A \textit{distributed verifiable random function} (DVRF) is a VRF where $n$ nodes cooperate to yield a pseudorandom output such that up to $t$ Byzantine nodes are tolerated while any $t + 1$ honest nodes are able to yield an honest output. It can be described by the following tuple of algorithms.
\begin{itemize}
\item $\mathsf{DKG}(1^\lambda, t, n) \rightarrow (sk_i, pk_i, pk)$ runs a typical DKG.
\item $\mathsf{PartialEval}(sk_i, x) \rightarrow (y_i, \pi_i)$ outputs the partial evaluation $y_i$ as well as its proof of correctness $\pi_i$ given an input $x$ and a node's secret key $sk_i$.
\item $\mathsf{PartialVerify}(pk_i, x, y_i, \pi_i) \rightarrow \{0, 1\}$ verifies the correctness of the partial evaluation $y_i$ given its proof $\pi_i$, an input $x$, and a node's public key $pk_i$.
\item $\mathsf{Combine}(A, \{(y_i, \pi_i)\}_{i \in A}) \rightarrow (y, \pi)$ outputs the DVRF evaluation $y$ as well as its proof of correctness $\pi$ given a set $A$ of $t + 1$ nodes and their outputs of $\mathsf{PartialEval}(sk_i, x)$, all of which pass $\mathsf{PartialVerify}$.
\item $\mathsf{Verify}(pk, \{pk_i\}, x, y, \pi) \rightarrow \{0, 1\}$ verifies the correctness of the DVRF evaluation $y$ given $\pi$, input $x$, and public keys.
\end{itemize}
% Naturally, it should satisfy VRF's properties of provability, uniqueness, and pseudorandomness. See Appendix \ref{appendix:dvrf}.
\end{definition}

\noindent\textbf{DVRF-based DRB.} Each beacon output of a DVRF-based DRB is then given by
\begingroup\makeatletter\def\f@size{8}\check@mathfonts
\[
\drboutput_r = \mathsf{DVRF.Combine}(A, \{\mathsf{DVRF.PartialEval}(sk_i, f(\drboutput_{r - 1}))\}_{i \in A})[0]
\]\endgroup
where $sk_i$ denotes each node's secret key after a DKG and $f$ denotes some deterministic function of $\drboutput_{r - 1}$.

The output is equivalent to one trustworthy master node with complete knowledge of $sk$ computing the output as:
\[
\drboutput_r = VRF_{sk}(f(\drboutput_{r - 1}))
\]
As $f$ typically takes a form resembling $f(\drboutput_{r - 1}) = H(r \mathbin\Vert \drboutput_{r - 1})$, there is no marginal entropy contributed by the participants. Unpredictability of the above DVRF formulation relies on the fact that no one node (or up to $t$ nodes) can gain knowledge of $sk$ to be able to compute and predict future beacon outputs.\\

\noindent\textbf{DVRF-based DRB from a chain of unique signatures.} Since taking the hash of a verifiable unpredictable function (VUF)~\cite{micali1999verifiable} is equivalent to a VRF, a unique digital signature (which is a VUF~\cite{dodis2005verifiable}) can be made into a DVRF by computing its threshold variant~\cite{boldyreva2003threshold} and hashing the output. Dfinity~\cite{hanke2018dfinity} and drand~\cite{drand} (while differing slightly in minor details) both use the BLS signature scheme~\cite{boneh2001short} to realize a DRB as
\[
\drboutput_r = H(\mathsf{Sign}_{sk}(r \mathbin\Vert \drboutput_{r - 1}))
\]
where $\mathsf{Sign}_{sk}(\cdot)$ is a threshold BLS signature computed by at least $t + 1$ nodes with $sk$ as the implied group secret key generated via DKG. The actual computation of $\drboutput_r$ involves combining of partial signatures computed using $sk_i$ (see Appendix \ref{appendix:bls}).\\

\noindent\textbf{Variations on a chain of unique signatures.} Besides a chain of BLS signatures, there exist several other variations.
\begin{itemize}
\item RandHerd~\cite{syta2017scalable}. Two modifications are made in RandHerd. First, a form of ``sharding'' is performed where nodes are randomly configured into groups (each of size $c$) via some initial configuration seed (e.g. derived from RandHound) such that each group emits a group leader while that of the first group is deemed a cothority (collective authority) leader. This results in the notion of hierarchy among nodes in a tree structure and thus has the effect of reducing the communication complexity from $O(n^2)$ to $O(c^2 \log n)$. Second, the underlying signature scheme used is Schnorr instead of BLS. Each beacon output in RandHerd is essentially a threshold Schnorr signature on message (as per the original protocol) $m = t_r$ where $t_r$ denotes the timestamp at the beginning of round $r$. As $m$ can technically be chosen (and thus biased) by the leader, one simple improvement can be setting $m = r \mathbin\Vert \drboutput_{r - 1}$ a la Dfinity or drand.
\item DDH-DRB~\cite{galindo2020fully}. Each round of DDH-DRB involves DDH-DVRF. As $\mathsf{PartialVerify}$ and $\mathsf{Verify}$ from Dfinity-DVRF (i.e. each round of Dfinity) rely on verifying pairing equations (see Appendix \ref{appendix:dfinity-dvrf}), the speed at which each beacon output is generated can be made faster if we replace each pairing equation with a DLEQ NIZK (Appendix \ref{appendix:dleq}) achieving the same effect. The tradeoff is space, as $\pi$ grows linearly in $n$. See Appendix \ref{appendix:ddh-dvrf} for details.
\item GLOW-DRB~\cite{galindo2020fully}. Each round involves GLOW-DVRF, which strikes a balance between Dfinity-DVRF and DDH-DVRF by involving a pairing equation in $\mathsf{Verify}$ (a la Dfinity-DVRF) but a DLEQ NIZK in $\mathsf{PartialVerify}$ (a la DDH-DVRF). This has the effect of generating a compact proof $\pi$ from $\mathsf{Verify}$ while enjoying less computational cost from $\mathsf{PartialVerify}$. See Appendix \ref{appendix:glow-dvrf} for details.
\end{itemize}

\section{Discussions}
\label{section:discussions}
\todo{better overall grouping in the intro of the section}
We summarize key properties of all protocols discussed in Table~\ref{table:comparison} and explore several practical issues with DRBs.

\subsection{Relation to Collective Coin Flipping Protocols}
Conceptually, distributed randomness is not a new line of research.
With its roots in Blum's classic work on coin flipping over telephone~\cite{blum1983coin}, distributed randomness has in fact been much researched albeit in a different context elaborated below.
Namely, Ben-Or and Linial in their seminal work~\cite{ben1985collective,ben1989collective} introduced the \textit{full information} model for the \textit{collective coin flipping} problem, in which $n$ participants with unbounded computational power communicate only via a single broadcast channel to generate a common random bit (such that honest majority is required~\cite{saks1989robust,boppana2000perfect} and thus assumed).
Numerous works exist in this setting, largely classifiable into different types of adversaries dealt with: static~\cite{ben1989collective,ajtai1993influence,kahn1989influence,saks1989robust,alon1993coin,boppana2000perfect,feige1999noncryptographic,russell1999lower}, adaptive~\cite{ben1989collective,lichtenstein1989some,goldwasser2015adaptively,dodis2000impossibility,kalai2021lower,haitner2020tight}, and variants of adaptive~\cite{mahloujifar2019can,etesami2020computational,cleve1993martingales,aspnes1998lower,goldwasser2015adaptively}.
See~\cite{kalai2021lower,haitner2020tight} for this line of research.

Overall, these works concern upper and lower bounds on corruption threshold, bias (deviation from coin flipping probability 1/2), and round complexity, all of which provide interesting theoretical insights.
Nonetheless, these bounds are often asymptotic (hence not practical) and are grounded in a more lax definition of security where it is sufficient that bias is bounded (but can still be nontrivial).
This is in contrast to the literature on DRBs considered in this paper, where we require each protocol to be as pseudorandom\todo{check with definition} as possible, outputting multi-bit, have explicit round complexity and fault tolerance, and assume computationally bounded adversaries in a cryptographic setting as well as point-to-point communication channels in the first place.
The goal is to achieve fully functional and practical DRBs.

Outside the full information model (such that cryptography is allowed) and thus the honest majority assumption, the well-known lower bound by Cleve~\cite{cleve1986limits} states that for any $r$-round coin flipping protocol there exists an efficient adversary that can bias the output of an honest node by $\Omega(1 / r)$.
In other words, it is impossible to have a pseudorandom\todo{check with definition} coin flipping protocol with a dishonest majority.

While this may seem to contradict the fault tolerance of delay-based DRBs from Section~\ref{section:vdf}, we note that delay functions help circumvent Cleve's impossibility result in the following two ways.
First, timed commitments allow recovery of a value that is withheld (either due to honest or Byzantine fault) and lost from an honest node's perspective.
In Cleve's proof, the notion of a ``default bit'' is used in such withholding situation whereas timed commitments effectively deprecate this default bit mechanism, sidestepping the proof logic.

Second, an implicit assumption in Cleve's model is that a Byzantine node is capable of grinding through possibilities to its liking and can arbitrarily choose which messages to output based on inputs from other nodes that are honest.
However, VDFs limit this capability such that it is not possible for even a dedicated attacker to grind through possibilities in an attempt to fix an output of some computation if a VDF is applied.
As a result of above, delay-based DRBs are able to enjoy both the highest fault tolerance and pseudorandomness\todo{check w def} without violating any classical lower bounds.

\subsection{Grinding Attack}
In a grinding attack, an adversary can search over many possible inputs to broadcast in a given round, with the possibility of influencing the outcome. While grinding attacks are not a threat in commit-reveal-recover variants or protocols with no marginal entropy, they are a valid concern in committee-based protocols involving random selection (RS), a private lottery, or a beacon output generated by combining precommitted per-node entropy with $\drboutput_{r - 1}$. The idea is that an adversary can grind to produce a biased $\committee_r$, $\drboutput_r$, or both (leading to a vicious cycle in the worst case).
% \joenote{What about the countermeasure of just making grinding statistically not effective for a subexponential adversary?}
% \kevinnote{can mention quantum/exponential adversary later?}

Two countermeasures are possible. First, inclusion of fresh marginal entropy from at least one honest node can be required, in which case grinding fails due to the adversary's inability to control such entropy. Second, precommitted entropy must indeed be precommitted, in which case grinding vacuously fails due to the lack of any grindable entropy.
\begin{enumerate}
\item \textbf{Requirement of fresh marginal entropy from at least one honest node.} Due to the $t$-limited adversary assumption, it is possible to force the inclusion of fresh marginal entropy from at least one honest node if we require more than $t$ entropy providers each round. Such a requirement is used in protocols like RandHound (where committee selection via LS has an explicit size requirement), Ouroboros (where the size of each epoch can be made large), and NV++ (where the VRF's target used for committee selection can be adjusted).
\item \textbf{Requirement of precommitted entropy.} No grindable entropy naturally means no possible grinding attack. In HydRand (and similarly GRandPiper), it is required that the precommitted entropy ($e_{\tilde{r}}$ from $\drboutput_r = H(\drboutput_{r - 1} \mathbin\Vert h^{e_{\tilde{r}}})$ as per Section \ref{subsubsection:precommitted}) used in round $r$ is precommitted in round $\tilde{r}$ where $r - \tilde{r} > t$ such that it is ungrindable due to the protocol's $t$-unpredictability property. In the protocols based on private lottery (i.e. Algorand, Ouroboros Praos, and Caucus), the private inputs to the lottery (VRF's $sk$ or each $h_r$ of a hash chain) are fixed in advance to make them ungrindable.
\end{enumerate}

\subsection{Withholding Attack}
\label{subsection:withholding}
In a withholding attack, an adversary can influence the outcome by not publishing some information in a given round. Any leader-based protocol is vulnerable to withholding due to the inherent reliance on a leader's availability, affecting the protocol's liveness (as well as potentially unpredictability and unbiasability). Any protocol with a private lottery is also vulnerable due to its nature where the lottery winner has to announce itself as a winner in the first place or can withhold this announcement if desirable.
\begin{enumerate}
\item \textbf{Protocols with a leader.} RandHound, RandHerd, and SPURT suffer from the leader unavailability issue in case the leader withholds its message such that their liveness is affected and a beacon output can be aborted (depending on implementation). In worse cases like RandHound and RandHerd, this can create a bias if the leader aborts after seeing $\drboutput_r$. In either case, it is desirable to have some fallback in case a leader withholds (e.g. HydRand's PVSS recovery).
\item \textbf{Protocols with a private lottery.} The issue of withholding is more fundamental with private lottery schemes like Algorand (where the leader can bias via withholding after privately computing $\drboutput_r$), as there is no way to conclusively detect if a winner withholds its leadership, i.e. there is no accountability. There are two possible remedies. First, we can require all participants to post their lottery outputs every single round even if they lose the lottery, in which case any lack of message would be indicative of withholding. However, this incurs communication cost, negating the advantages of a private lottery. Second, a technique called SSLE (single secret leader election)~\cite{boneh2020single} can be used to guarantee one winner per round, enabling detection of withholding. In a nutshell, SSLE ensures exactly one leader from a group is randomly chosen while the identity of the leader will only be known when the winner publicly reveals its identity. The guarantee of one winner as opposed to the expectation of one winner is what differentiates SSLE. While this guarantee makes withholding obvious, it does not prevent withholding by itself, nor does it enable detecting \emph{who} the withholding winner was in the case of withholding.
\end{enumerate}

\begin{table*}[h!]
% \footnotesize
\scriptsize
% \tiny
\begin{threeparttable}
\caption{DRB Comparison}
\label{table:comparison}
% \begin{tabularx}{\textwidth}{@{} l *{20}c}
% \begin{tabularx}{\textwidth}{@{} l *{20}{@{\phantom{x}}c@{\phantom{x}}}}
\begin{tabularx}{\textwidth}{@{} l *{20}{@{\phantom{w}}c@{\phantom{w}}}}
\toprule
\spheading{} & \spheading{Section\\(from paper)} & \spheading{Cryptographic Primitive} & \spheading{Fault Tolerance (less than)} & \spheading{Independent Participation} & \spheading{Per-Round Entropy Provider} & \spheading{Unpredictability} & \spheading{Immunity to Withholding} & \spheading{Adaptive Security} & \spheading{Verifier Complexity} & \multicolumn{2}{c}{\spheading{Communication Complexity}} & \spheading{Max Damage} & \spheading{Recovery Cost}\\
\cmidrule{11-12}
 & & & & & & & & & & Optimistic & Worst & & \\
\toprule
Commit-Reveal & \hyperref[subsection:commit-reveal]{II} & Commitment & 1 & \cmark & All & 1 & \xmark & \xmark & $O(n)$ & $O(n^2)$ & $O(n^3)$ & Bias & $O(1)$ \\
\midrule
Unicorn++ & \multirow{4}{*}{\ref{section:vdf}} & VDF & $n$ & \cmark & All & 1 & \cmark & \cmark & $O(n)$ & $O(n^2)$ & $O(n^3)$ & None & $O(1)$ \\
Ext. Beacon+VDF & & VDF & $n$ & \cmark & External & 1 & \cmark & \cmark & $O(1)$ & $O(n)$ & $O(n^2)$ & None & $O(1)$ \\
RandRunner & & Trapdoor VDF & $n$ & \xmark & None & $t$\tnote{§} & \cmark & \xmark & $O(\log T)$\tnote{‡} & $O(n)$ & $O(n^2)$ & Predict & $O(n^3)$ \\
Narwhal & & Timed commitment & $n$ & \cmark & All & 1 & \cmark & \cmark & $O(n)$ & $O(n^2)$ & $O(n^3)$ & None & $O(1)$ \\
\midrule
RANDAO & \multirow{2}{*}{\ref{section:commit-reveal-punish}} & Commitment & $n$ & \cmark & All & 1 & \cmark & \cmark & $O(n)$ & $O(n^2)$ & $O(n^2)$\tnote{†} & None & $O(n)$\tnote{†} \\
EVR & & Escrow-DKG & $n/3$ & \xmark & All & 1 & \cmark & \cmark & $O(n^3)$ & $O(n^3)$ & $O(n^4)$ & None & $O(n)$ \\
\midrule
Scrape & \multirow{5}{*}{\ref{section:commit-reveal-recover}} & PVSS & $n/2$ & \xmark & All & 1 & \cmark & \cmark & $O(n^2)$ & $O(n^3)$ & $O(n^4)$ & Bias\tnote{r} & $O(n^3)$ \\
Albatross & & PVSS & $n/2$ & \xmark & All & 1 & \cmark & \cmark & $O(1)$ & $O(n)$ & $O(n^2)$ & Bias\tnote{r} & $O(n^3)$ \\
RandShare & & (P)VSS & $n/3$ & \xmark & All & 1 & \cmark & \cmark & $O(n^3)$ & $O(n^3)$ & $O(n^4)$ & Bias\tnote{r} & $O(1)$ \\
SecRand & & PVSS & $n/2$ & \xmark & All & 1 & \cmark & \cmark & $O(n^2)$ & $O(n^3)$ & $O(n^4)$ & Bias\tnote{r} & $O(n^3)$ \\
HERB & & Thr. ElGamal & $n/3$ & \xmark & All & 1 & \cmark & \cmark & $O(n)$ & $O(n^2)$ & $O(n^3)$ & Bias\tnote{r} & $O(n^4)$ \\
\midrule
HydRand & \multirow{11}{*}{\ref{section:committee-based}} & PVSS & $n/3$ & \xmark & Committee\tnote{*} & $t$ & \cmark & \xmark & $O(n)$ & $O(n^2)$ & $O(n^3)$ & Bias & $O(n^3)$ \\
GRandPiper & & PVSS & $n/2$ & \xmark & Committee\tnote{*} & $t$ & \cmark & \xmark & $O(n^2)$ & $O(n^2)$ & $O(n^2)$ & Bias & $O(n^3)$ \\
BRandPiper & & (P)VSS & $n/2$ & \xmark & Committee\tnote{*} & 1 & \cmark & \cmark & $O(n^2)$ & $O(n^2)$ & $O(n^3)$ & Bias & $O(n^4)$ \\
Ouroboros & & PVSS & $n/2$ & \xmark & Committee & 1 & \cmark & \xmark & $O(n^2)$ & $O(n^3)$ & $O(n^3)$\tnote{†} & Bias & $O(n^2)$\tnote{†} \\
RandHound & & PVSS & $n/3$ & \xmark & Committee & 1 & \xmark & \xmark & $O(c n)$ & $O(c^2 n)$ & $O(c^2 n^2)$ & Bias & $O(n^3)$ \\
SPURT & & PVSS & $n/3$ & \xmark & Committee & 1 & \xmark & \xmark & $O(n)$ & $O(n^2)$ & $O(n^2)$ & Bias & $O(n^3)$ \\
OptRand & & PVSS & $n/2$ & \xmark & Committee & 1 & \cmark & \cmark & $O(n)$ & $O(n^2)$ & $O(n^2)$ & Bias & $O(n^3)$ \\
Algorand & & VRF & $n/3$ & \cmark & Committee\tnote{*} & 1 & \xmark & \cmark & $O(1)$ & $O(n)$ & $O(n)$\tnote{†} & Bias & $O(n^2)$\tnote{†} \\
Ouroboros Praos & & VRF & $n/2$ & \cmark & Committee & 1 & \xmark & \cmark & $O(n)$ & $O(n^2)$ & $O(n^2)$\tnote{†} & Bias & $O(n^2)$\tnote{†} \\
Caucus & & Hash chain & $n/3$ & \cmark & Committee\tnote{*} & 1 & \xmark & \cmark & $O(1)$ & $O(n)$ & $O(n^2)$ & Bias & $O(n^3)$ \\
NV++ & & VRF, thr. ElGamal & $n/3$ & \xmark & Committee & 1 & \xmark & \cmark & $O(n)$ & $O(n)$ & $O(n)$\tnote{†} & Bias & $O(n^2)$\tnote{†} \\
\midrule
drand & \multirow{5}{*}{\ref{section:dvrf}} & Thr. BLS & $n/2$ & \xmark & None & 1 & \cmark & \cmark & $O(1)$ & $O(n^2)$ & $O(n^3)$ & Predict & $O(n^4)$ \\
RandHerd & & Thr. Schnorr & $n/3$ & \xmark & None & 1 & \xmark & \xmark & $O(1)$ & $O(c^2 n)$ & $O(n^4)$ & Bias & $O(n^4)$ \\
DDH-DRB & & DDH-based DVRF & $n/2$ & \xmark & None & 1 & \cmark & \cmark & $O(n)$ & $O(n^2)$ & $O(n^3)$ & Predict & $O(n^4)$ \\
GLOW-DRB & & Pairing-based DVRF & $n/2$ & \xmark & None & 1 & \cmark & \cmark & $O(1)$ & $O(n^2)$ & $O(n^3)$ & Predict & $O(n^4)$ \\
STROBE & & RSA, VSS & $n/2$ & \xmark & None & 1 & \cmark & \cmark & $O(1)$ & $O(n^2)$ & $O(n^3)$ & Predict & $O(n)$ \\
\bottomrule
\end{tabularx}
\begin{tablenotes}[flushleft,para]
\item $c$ is the size of a shard in RandHerd and RandHound. We assume a leader can be Byzantine for both.
\item Albatross' verifier and communication complexities are per beacon output.
\item In Ouroboros and Ouroboros Praos, we assume the number of slot leaders in an epoch is denoted by $n$.
\item We assume Scrape's PVSS~\cite{cascudo2017scrape} is used as the default PVSS scheme.
\item[*] Each committee consists of a leader by default or by expectation.
\item[†] PBB (public bulletin board) is assumed.
\item[‡] Verification of Pietrzak's VDF is logarithmic in $T$ (VDF's delay parameter).
\item[§] $d = t$ for RandRunner's $d$-unpredictability assuming a dishonest minority without any computational advantage. See~\cite{schindler2021randrunner} for more scenarios.
\item[r] In a non-rushing adversary model, max damage would be predict rather than bias.
\end{tablenotes}
\end{threeparttable}
\end{table*}

\subsection{Adaptive Security}
\label{subsection:adaptive}
A DRB is \textit{adaptively secure} if its security properties remain unaffected against an adaptive adversary instead of a static one. Otherwise, it is \textit{adaptively insecure}. In this section, we discuss three ways in which adaptive security is achieved.

\begin{enumerate}
\item \textbf{$|\committee_r|$ is greater than $t$ or equal to 0.} Due to the $t$-limited adversary assumption, a large enough $\committee_r$ (or an empty one as per Section \ref{section:dvrf}) guarantees adaptive security. Otherwise, a protocol may be vulnerable. In HydRand and GRandPiper (where $|\committee_r| = 1$), an adaptive adversary can corrupt the next $t$ round leaders to predict $t + 1$ future rounds. In Ouroboros, it can adaptively corrupt the entire $\committee_r$ (which could probabilistically be less than or equal to $t$ in size) publicly known in advance.
\item \textbf{Protocols with private lotteries require lottery winners to broadcast marginal entropy and proof of selection into $\committee_r$ in the same message.} While some private lottery schemes (i.e. Algorand, Ouroboros Praos, and Caucus) may involve less than or equal to $t$ entropy providers per round, the fact that one message (per entropy provider) comprises both announcement of winning the lottery and provision of marginal entropy is what allows adaptive security. The idea is that by the time an adversary knows which nodes to corrupt adaptively in a round (after the nodes reveal their identity as entropy providers), there is no extra step left to be corrupted, as each entropy provider's contribution to $\drboutput_r$ has been broadcast already in the same message.
\item \textbf{There is no central point of dependency in any step of the protocol.} In leader-based protocols where a leader functions more as an orchestrator than an entropy provider, participating nodes may still need to depend on the leader to make progress on the beacon such that an adversary can adaptively corrupt such leaders to its benefit. In RandRunner, corrupting the next $t$ leaders allows predictability. In RandHound and RandHerd, corrupting the round leader allows biasability if the leader aborts after seeing $\drboutput_r$ as aforementioned. In SPURT, corrupting the next $t$ leaders to withhold endangers liveness.
\end{enumerate}

\subsection{Comparison of DRBs}
Table~\ref{table:comparison} provides an overall comparison of DRBs. \textit{Fault Tolerance} indicates the minimum number of faulty nodes that can abort a protocol (after the initial setup). Protocols with \textit{Independent Participation} allow a node to contribute to beacon output without the knowledge of other nodes in advance. However, it differs from a permissionless setting in the sense that a node may still have to register in advance to allow verification of its contribution.

\textit{Verifier Complexity} refers to the computational cost for a passive node (third party) to verify a beacon output. We exclude the cost associated with the initial setup for both verifier and communication complexities. We assume a verifier complexity of $O(n)$ per Lagrange interpolation or Scrape's PVSS~\cite{cascudo2017scrape} run. \textit{Communication Complexity} concerns bitwise point-to-point communication among nodes by default. Alternatively, we consider a \textit{public bulletin board} (PBB) as a reliable information exchange medium in protocols where it is intrinsic (e.g. in blockchains). In a PBB model, we assume both the bitwise writing cost (amount of data posted to PBB) and the reading cost (by all nodes where each node only reads data relevant to it) contribute to the total cost. In the absence of PBB, Byzantine consensus~\cite{castro1999practical} incurs a cost of $O(n^2)$ per decision by default.

\textit{Max Damage} refers to the maximum damage possible when $n - 1$ rushing~\cite{gennaro1999secure} (where an adversary can delay sending messages until \textit{after} reading messages sent by the honest nodes in a given round of communication) adversarial nodes cooperate to predict or bias. In escrow-based protocols, we assume the adversaries are rational. \textit{Recovery Cost} refers to the communication cost associated with recovering from an adversarial corruption. Regenerating keys (e.g. $\mathsf{PVSS.KeyGen}$ or for private lottery schemes) and $\mathsf{VDF.Setup}$ incur $O(n^3)$ recovery cost without PBB (and $O(n^2)$ with PBB) while we assume each DKG incurs $O(n^4)$ recovery cost.
% \iffalse
% \subsection{Quality vs Efficiency}
% % Mt. Random's Tier 1 (fresh randomness per node) > 2 (one VRF, not biasable) > 3 (many VRFs, biasable via withholding) -- from quality of randomness perspective
% The protocols that we have seen so far provide a range of efficiency and quality tradeoffs under different setups, assumptions and adversarial models. PVSS/VSS based protocols offers uniform randomness, but comes at quartic communication complexity.
% VRF based protocols require very little communication and computation but the output is biasable by withholding. DVRF based protocols get rid of the bias by allowing a set of participants greater than a threshold to recover the output. VDF based protocols require high computational cost (sequential squarings) but generates uniform pseudorandom outputs with quadratic communication cost. While these protocols can be used on their own, they can also be combined in a modular way to build a distributed randomness beacon. Mt. Random~\cite{cascudomt}, a multi-tiered randomness beacon is one such example.

% \joenote{should there be a separate section on protocols that combine other protocols?}
% Mt. Random has three independent tiers, each based on a different technique and providing different tradeoff between complexity and quality of randomness. Tier 1 provides uniform randomness via PVSS based protocols. Mt. Random reduces the amortized cost per beacon output for PVSS by using an extension of Albatross called GULL (Gradually UnLeashed aLbatross)~\cite{cascudomt}, but could be substituted with any of the Commit-Reveal-Recover variants from Section \ref{section:commit-reveal-recover}. Tier 2 provides uniform pseudorandomness via DVRF based protocols. Mt. Random uses DDH based version of drand, but any of the DVRF based protocols from Section \ref{section:dvrf} or RandRunner from Section \ref{subsection:randrunner} could be used instead. Tier 3 provides biased pseudorandomness using VRF based protocols. Mt. Random uses a variation of Ouroboros Praos where every participant computes and broadcasts their VRF outputs (and requires no committee selection via private lottery). Though this makes detecting malicious participants (and maybe punishing them) easier, the beacon output for the round would still remain biased. Randomness from earlier tiers are used to periodically refresh seeds for Tier 2 and Tier 3 protocols, making them more secure than their stand-alone versions.

% Mt. Random illustrates a framework in which PVSS and (D)VRF protocols can be combined in a multi-tiered fashion where higher tiers generate random outputs faster than lower tiers albeit with losses in randomness quality. It is possible to extend the framework to other primitives/building blocks or use an altogether different framework to combine different protocols. This remains to be explored further.
% \fi

\section{Concluding Remarks}
\label{section:conclusion}
In this paper, we systematize distributed randomness beacons.
%and describe a modular framework comprising two components: selection of entropy providers and beacon output generation, which can be used to analyze a DRB's design.
Our systematization highlights important insights both for practitioners and researchers. Based on practical considerations such as scalability (in $n$), flexibility (reconfiguration and independent participation), robustness (fault tolerance and max damage), and randomness quality (true randomness versus pseudorandomness), we would advise practitioners planning to deploy a DRB as follows:
\begin{itemize}
    \item VDF-based protocols stand above the competition in terms of scalability, flexibility, and robustness, enabling an efficient DRB with unlimited, open participation and security given any honest participant. In theory, VDFs appear to be a silver bullet for DRBs, though they have yet to be widely used in practice and assumptions about VDF security and hardware speeds remain relatively new. They also invoke a unique practical cost in that \emph{somebody} must compute a VDF (preferably by running specialized hardware), which also induces latency into the DRB.
    \item If not using VDFs, practitioners need to think critically about two design dimensions: how large is the set of participants, and how frequently will it change? Given a small, static set of participants, DKG-based protocols, e.g. HERB (from threshold encryption) and drand (from DVRF), scale better than PVSS-based protocols. HERB and drand are both competitive in this setting, differing in randomness quality and max damage.
    \item For a small but dynamic set of participants, PVSS-based protocols offer better flexibility (by avoiding a costly DKG setup per reconfiguration) and randomness quality. Committees may be needed to scale to more participants.
    \item Given a large, dynamic set of participants, protocols with private lotteries like Algorand offer better scalability and flexibility simultaneously although the randomness quality is potentially affected by withholding.
    \item Finally, escrow-based protocols are suitable against purely financially-motivated adversaries in applications such as lotteries or finance, at the cost of locking up some amount of capital during the protocol.
\end{itemize}

We conclude by identifying the following areas which we consider most promising for further research.
\begin{itemize}
    \item While VDFs are a promising tool, practical deployment requires good estimates of the lower bound of wall-clock VDF evaluation time. More research is needed to gain confidence in the security of underlying VDF primitives (such as repeated modular squaring), and hardware implementations must be built to provide practical assurance against attacks.
    \item VDFs might be useful as a modular layer in strengthening other DRBs in a ``belt-and-suspenders'' approach, though this does not appear to have been explored yet.
    \item To avoid the need for VDF evaluation (and latency) in the optimistic case, timed commitments (a related primitive to VDFs) might be used instead as yet another mechanism to recover from aborts in commit-reveal.
    \item Vulnerable to withholding, protocols based on private lotteries can generate biased outputs. Though the guarantee of a single lottery winner every round via SSLE makes withholding detectable, extending these protocols to enable tracing of which node withheld is a promising direction for further research.
    \item With the exception of VDF-based protocols like Unicorn++, all other DRBs assume a permissioned setting requiring some initial setup (e.g. PKI or DKG) to establish participants' identities. It is an open question which non-VDF-based protocols can be extended to enable ad hoc, permissionless participation.
    \item Existing DRBs assume synchronous communication, which may fail in practice. Extending protocols to handle fully asynchronous communication is an area for future research.
    %\item Key subroutines such as DKG or Byzantine consensus can be studied and optimized further for better communication and computational efficiency, flexibility, and robustness.
    \item Finally, there is a gap between the systems-based literature on DRBs and the traditional cryptographic literature on randomness extractors~\cite{trevisan2000extracting,trevisan2001extractors}, with DRBs simply assuming cryptographic primitives such as hash functions work as extractors in practice. Utilizing the existing theory of extractors could prove useful in scenarios where high-quality DRB outputs are required directly.
    % proactively detecting corruption and automatic recovery
    % \item Multiple independent protocols might be combined in a modular way to build a heterogeneous beacon. Mt. Random~\cite{cascudomt} explores this idea by building a multi-tiered beacon with PVSS-based (Scrape variant), DVRF-based (drand variant), and VRF-based (Ouroboros Praos variant) protocols, with each tier providing different tradeoffs between cost and randomness quality. Extending this framework of juxtaposition to combine other primitives can be explored further.
\end{itemize}