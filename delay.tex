%!TEX root = main.tex

\section{Delay-Based Protocols}
\label{section:delay}
One way to prevent the last-revealer attack is to compute $\drboutput_\epochv$ using a \emph{delay function} after combining each node's entropy contribution. If the delay is suitably long, no participant can predict what effect a potential contribution will have on the output before its share must be published. Typically, a \emph{verifiable delay function} (VDF)~\cite{boneh2018verifiable,boneh2018survey} is used to accomplish this while maintaining efficient verifiability of the result.

\begin{definition}[Verifiable delay function]
A \textit{verifiable delay function} (VDF) is a function that takes a specified number of sequential steps to compute (even with a large amount of parallelism available) but takes exponentially less time to verify once computed. It can be described by the following algorithms:
\begin{itemize}
\item $\mathsf{Setup}(\lambda, T) \rightarrow pp$ is a randomized algorithm that outputs public parameters $pp$ given security parameter $\lambda$ and delay parameter $T$.
\item $\mathsf{Eval}(pp, x) \rightarrow (y, \pi)$ computes $y$ in $T$ sequential steps and a proof $\pi$ given $pp$ and an input $x$.
\item $\mathsf{Verify}(pp, x, y, \pi) \rightarrow \{0, 1\}$ outputs 1 if $y$ is the unique correct evaluation of the VDF on input $x$ and 0 otherwise.
\end{itemize}
\end{definition}

Two well-known VDF proposals, due to Pietrzak~\cite{pietrzak2018simple} and Wesolowski~\cite{wesolowski2019efficient}, make use of the (believed) inherently sequential nature of repeated squaring in a group of unknown order.
VDFs can also be constructed from incrementally verifiable computation~\cite{boneh2018verifiable,khovratovich2022minroot} or isogenies~\cite{de2019verifiable}.
VDFs can be used to derive unbiasable randomness either from existing, biasable protocols (e.g. commit-reveal or public implicit beacons) or as the building block for an entirely new protocol (like RandRunner~\cite{schindler2021randrunner}).

\subsection{Modifying Commit-Reveal}
\label{subsection:modifying-commit-reveal}
The Unicorn protocol~\cite{lenstra2015random} uses the Sloth function (a VDF precursor based on computing square roots modulo a prime) in a manner similar to commit-reveal. In fact, commitments are no longer needed; participants simply publish their entropy contributions directly. Unicorn can be improved using a modern VDF in place of Sloth to achieve faster (constant time) verification time for a given delay parameter. We refer to VDF-enhanced Unicorn as \textit{Unicorn++}. It runs as follows:
\begin{enumerate}
    \item \textbf{Collect.} Every participant $P_i$ broadcasts its entropy contribution $e_i$ between time $t_1$ and $t_2$ (assuming synchronized clocks). At $t_2$, they are combined into $seed_\epochv = H(e_1,\ldots, e_n)$.
    \item \textbf{Evaluate.} Some party evaluates the VDF with $seed_\epochv$ and a chosen delay parameter $T$ (part of $pp$) via
    $$y_\epochv, \pi_\epochv = \mathsf{VDF.Eval}(pp, seed_\epochv)$$
    such that $\drboutput_\epochv = H(y_\epochv)$, which is posted and can be efficiently verified by any observer using $\pi_\epochv$ via $\mathsf{VDF.Verify}$.
\end{enumerate}
\todo{lower case $t$ used here for time?}
As long as $T$ is longer than the duration of $t_2 - t_1$, Unicorn++ successfully defends against any attack possible by the last entropy provider. Also desirably, it is unbiasable by an adversary that controls $n - 1$ of the participants, as even one honest entropy contribution requires computation of $\mathsf{VDF.Eval}$ from scratch. The downside of the protocol is that \emph{somebody} must evaluate the VDF, which is slow by design. It is possible to outsource this computation, even in a decentralized manner~\cite{thyagarajan2021opensquare}, as it does not matter for security who evaluates since VDFs are deterministic and verifiable. %) though it is possible to outsource VDF evaluation in a decentralized manner~\cite{thyagarajan2021opensquare}.

We note a variation of above~\cite{bunz2017proofs, bonneau2015bitcoin}, replacing or bolstering the participant entropy contributions with  stock prices~\cite{clark2010use} or PoW blockchain headers~\cite{nakamoto2008bitcoin, bentov2016bitcoin, han2020randchain} (which are otherwise susceptible to manipulation) can be used to supply $seed_\epochv$ in Collect. Such schemes are collectively denoted by \textit{Ext. Beacon+VDF} in Table~\ref{table:comparison}.
Unfortunately, they do not easily compare to other DRBs, as the security model depends on the cost of manipulating the external beacon, which has not yet been formally analyzed.

\subsection{Adding Recovery to Commit-Reveal}
Another way to modify commit-reveal is to leverage a different class of delay functions called timed commitments~\cite{boneh2000timed} in place of regular commitments used in commit-reveal.
The idea is simple: timed commitments are commitments with an additional slow recovery process (the committed value can be recovered in $T$ sequential steps but not before) in case the committer withholds.

\begin{definition}[Timed commitment]
A \textit{timed commitment} is a commitment with the following additional recovery process (also known as forced opening) where the committed value can be recovered in $T$ sequential steps but not before.
\begin{itemize}
\item $\mathsf{ForceOpen}(\com) \rightarrow (x, r_0)$ outputs the committed value $(x, r_0)$ in $T$ sequential steps given a commitment $\com = \mathsf{Com}(x, r_0)$.
\end{itemize}
\end{definition}

This recovery process avoids the last-revealer attack as a withholding participant's contribution can be recovered. Thus the resulting distributed randomness protocol can be seen as a ``commit-reveal-recover'' protocol (see Section~\ref{section:commit-reveal-recover}).
This approach was suggested by Boneh and Naor~\cite{boneh2000timed} though not specified in detail.
Thyagarajan et al.~\cite{thyagarajan2021efficient} proposed that by leveraging homomorphic timed commitments, it is possible to combine contributions and only compute one delay function even if \emph{all} participants refuse to open (rather than one computation per withholder).
Bicorn~\cite{choi2022bicorn} realizes the above logic in a simple, efficient DRB with comparable overhead to basic commit-reveal.
An improvement of Bicorn over Unicorn++ is that there is an optimistic case (which the latter does not have) when everyone reveals as expected, making the protocol analogous to a simple commit-reveal.
At the same time, context may be important to consider if the optimistic case is unlikely to occur (e.g. due to poor network conditions or too many participants), in which case Unicorn++ is even simpler and also requires only one delay function computation.

All of the protocols in this family\todo{have what properties?}

\subsection{Chain of VDFs}
\label{subsection:randrunner}
The disadvantage of above is that each \epoch may require consensus~\cite{castro1999practical} on inputs to the delay function, incurring communication cost.
Also, the rate at which beacon outputs are generated is limited by $T$ (by default in Unicorn++ and in Bicorn's $\mathsf{ForceOpen}$ case).
RandRunner~\cite{schindler2021randrunner} tackles these issues by leveraging a VDF design that builds a deterministic chain of outputs (more precisely, a chain of $n$ interleaved VDFs each set up by a node) to bypass per-\epoch consensus while allowing each \epoch's duration to be independent of $T$ in the optimistic case.
As a result, the protocol achieves lower communication complexity as well as more beacon outputs generated per time frame.
Trapdoor VDFs~\cite{wesolowski2019efficient} with the strong uniqueness property~\cite{schindler2021randrunner} serve as its key building block.

\begin{definition}[Strongly unique trapdoor VDF]
A \textit{strongly unique trapdoor VDF} ($\mathsf{TVDF}$) is a VDF with an additional functionality as follows.
It allows one who knows the \textit{trapdoor} (e.g. $p, q$ for RSA's $N = p q$) to efficiently evaluate the VDF without $T$ sequential steps, while providing \textit{strong uniqueness} (uniqueness even with the knowledge of such trapdoor).
\begin{itemize}
    \item $\mathsf{TrapdoorEval}(pp, x, sk) \rightarrow (y, \pi)$ outputs $y$ in steps less than $T$ (unlike $\mathsf{Eval}$) and a proof $\pi$ given $pp$, an input $x$, and the trapdoor $sk$.
\end{itemize}
\end{definition}

Wesolowski's VDF~\cite{wesolowski2019efficient} is not strongly unique, as knowing the trapdoor allows an adversary to forge proofs accepted by $\mathsf{VDF.Verify}$. As a result, RandRunner uses Pietrzak's VDF~\cite{pietrzak2018simple} in its setup, in which $pp_i$ (each corresponding to a different VDF) is broadcast by each $P_i$. Then the idea is that, in each \epoch, the value $H(\drboutput_{\epochv - 1})$ is input to the VDF of the \epoch leader selected via either \textit{round-robin} (i.e. taking turns in some permuted order) or \textit{random selection} (i.e. using $\drboutput_{\epochv - 1}$ as seed), the implications of which are discussed in Section~\ref{subsubsection:public-committee-selection}.

In the optimistic case, the leader evaluates and publishes the VDF output as the beacon output via $\mathsf{TVDF.TrapdoorEval}$ while in the faulty case (if the leader withholds), others can evaluate the same value via $\mathsf{TVDF.Eval}$ albeit more slowly.

% After an initial Setup phase, RandRunner reiterates its Execution phase as follows.
% \begin{enumerate}
%     \item \textbf{Setup.} Each participant $P_i$ executes $\mathsf{TVDF.Setup}$ to compute its public parameters $pp_i$ and the corresponding secret trapdoor $sk_i$ and broadcasts $pp_i$. At the end, all participants should have the same set of public parameters $\{pp_i\}_{i = 1, ..., n}$. The initial value $\drboutput_0$ used to bootstrap the protocol is also agreed upon.
%     \item \textbf{Execution.} A unique leader for \epoch $\epochv$, $l_\epochv$ is selected via either \textit{round-robin} (i.e. taking turns in some permuted order) or \textit{random selection} (i.e. using $\drboutput_{\epochv - 1}$ as seed, originally called randomized sampling). The implications of each are discussed in Section~\ref{subsubsection:public-committee-selection}. Each \epoch can proceed in two ways depending on $l_\epochv$'s status.
%     \begin{itemize}
%         \item \textbf{Honest Leader.} The leader broadcasts
%         $$y_\epochv, \pi_\epochv = \mathsf{TVDF.TrapdoorEval}(pp_{l_\epochv}, H_1(\drboutput_{\epochv - 1}), sk_{l_\epochv})$$
%         in which case other nodes verify the received values via $\mathsf{TVDF.Verify}$. Then the beacon output is
%         $$\drboutput_\epochv = H_2(y_\epochv)$$
%         where $H_1$ and $H_2$ map values from the beacon output space to the VDF space and vice versa.
%         \item \textbf{Dishonest Leader.} Given a dishonest leader that withholds or broadcasts an invalid message, every non-leader computes and broadcasts
%         $$y_\epochv, \pi_\epochv = \mathsf{TVDF.Eval}(pp_{l_\epochv}, H_1(\drboutput_{\epochv - 1}))$$
%         in $T$ sequential steps, and then $\drboutput_\epochv = H_2(y_\epochv)$.
%     \end{itemize}
% \end{enumerate}

Thus, RandRunner optimistically generates each beacon output rapidly with only $O(n)$ communication complexity. Adversarial leaders can increase the \epoch duration to $T$ (or more with network delay $\Delta$) and the communication complexity to $O(n^2)$. Due to its pseudorandom nature, the protocol exhibits two other beneficial properties. First, liveness is retained even with a dishonest majority and when network connectivity breaks down completely, as a node can simply compute the beacon outputs over time via $\mathsf{TVDF.Eval}$. Second, it is impossible to bias the beacon once bootstrapped such that even the strongest adversary can only predict but not bias. The trade-off is that RandRunner can never achieve the ideal 1-\interunpredictability property due to the existence of leaders that can withhold and adversaries with higher compute power. In other words, the parameter $\beta$ as in RandRunner's $\beta$-\interunpredictability must be greater than one but can be calculated and bounded~\cite{schindler2021randrunner} depending on assumptions.
