51. Stake-Bleeding Attacks on Proof-of-Stake Blockchains
52. Global, Unpredictable Bit Generation Without Broadcast
53. STROBE: Stake-based Threshold Random Beacons
54. Efficient Random Beacons with Adaptive Security for Ungrindable Blockchains
55. On the Notion of Pseudo-Free Groups
56. The Algebraic Group Model and its Applications
57. On the Security of Time-Lock Puzzles and Timed Commitments
58. Attribute-Hiding Predicate Encryption With Equality Test in Cloud Computing
59. Public Randomness Extraction with Ephemeral Roles and Worst-Case Corruptions

51. Stake-Bleeding Attacks on Proof-of-Stake Blockchains
https://eprint.iacr.org/2018/248.pdf
```
â€¢ We describe a general attack on proof-of-stake (PoS) blockchains without checkpointing. Our attack leverages transaction fees, the ability to treat transactions â€œout of context,â€ and the standard longest chain rule to completely dominate a blockchain
â€¢ More broadly, our attack must be reflected and countered in any future PoS design that avoids checkpointing, as well as any effort to remove checkpointing from existing protocols. We describe several mechanisms for protecting against the attack that include context-sensitivity of transactions and chain density statistics
â€¢ problem of â€œlong-range attacksâ€ (also related to the concept of â€œcostless-simulationâ€ in, e.g., [Poe15]). This refers to the ability of a minority set of stakeholders to execute the blockchain protocol starting from the genesis block (or any sufficiently old state) and produce a valid alternative history of the system
â€¢ In the same blog post [But14], however, a glimmer of hope was also provided: it was observed that the blockchains produced by such a minority set of stakeholders may have characteristics that could be used to distinguish them from the actual blockchain maintained by the honest majority. In particular, if timestamps are included in each block, it would be the case that a simple simulation of the protocol by a minority set of stakeholders would result in a blockchain that is more sparse in the time domain
â€¢ 1) Eventual-consensus protocols that apply some form of a longest-chain rule to the blockchain. In this setting the immutability of a block increases gradually with the number of blocks created on top of it.; 2) Blockwise-BA protocols that achieve the immutability of every single block via a full execution of a Byzantine Agreement (BA) protocol before moving on to production of any subsequent block
â€¢ Of the above-listed PoS protocols, Algorand is a blockwise- BA protocol, while all the other protocols aim for eventual consensus
â€¢ All of these protocols had to confront the problem of long- range attacks, which was eventually understood to be even more serious than originally thought. The additional complicationâ€” aptly named â€œposterior corruptionâ€ in [BPS16]â€”observes that simply examining time stamps will not be sufficient for dealing with long-range attacks. In fact, an attacker can attempt to corrupt the secret keys corresponding to accounts that possessed substantial stake at some past moment in the history of the system. Assuming that such accounts have small (or even zero) stake at the present time, they are highly susceptible to bribery (or simple carelessness) which would expose their secret keys to an attacker. Armed with such a set of (currently low-stake) keys, the attacker can mount the long-range attack and in this case the density of the resulting blockchain in the time domain could be indistinguishable from the honestly generated public blockchain
â€¢ To address the posterior corruption and other long range attacks, a number of mitigating approaches have been employed (sometimes in conjunction) and can be organised into three types: (i) Introduce some type of frequent checkpointing mechanism, that enables nodes to be introduced to the system by providing them a relatively recent block.; (ii) Employ key-evolving cryptography [Fra06] that calls for users to evolve their secret keys so that past signatures cannot be forged, even when a complete exposure of their current secret state takes place.; (iii) Enforce strict chain density statistics, where the expected number of participating players at any step of the protocol is known; thus alternative protocol execution histories that exhibit significantly smaller participation can be immediately dismissed as adversarial
â€¢ Out of the above-mentioned PoS schemes, all eventual- consensus protocols (i.e., NXT, PPCoin, Ouroboros, Snow White, and Ouroboros Praos) employ the first mitigation strategy and assume some form of checkpointing. Ouroboros Praos employs the first and the second approach (key-evolving signatures) to additionally handle adaptive corruptions, while Algorand adopts the second and the third approach (strict chain density statistics) to the same end
â€¢ Stake-bleeding is an effective strategy for mounting a long-range attack that does not rely on posterior corruption; thus it cannot be prevented by key-evolving cryptographic techniques. The only requirement for the attack is that the underlying blockchain protocol allows transaction fees to be used as rewards for running the protocol
â€¢ The adversary checks in every time slot whether it is allowed to extend the chain C or Ë†C according to the rules of the protocol Î . It skips all opportunities to extend C, hence not contributing to its growth at all. On the other hand, whenever an opportunity to extend Ë†C arises, A extends Ë†C with a new block, and inserts into this new block all the transactions from the honest chain C that are not yet included in Ë†C and are valid in the context of Ë†C (or as many of them as allowed by the rules of Î ). This entitles A to receive (on Ë†C) any block-creation reward and any transaction fees coming from the included transactions
```
â€¢ Checkpointing (but "weak subjectivity") vs strict chain density statistics (but can be complicated/inaccurate) vs key-evolving crypto (preferable b/c algorithmic BUT still vulnerable to stake bleeding)
â€¢ "Density" means in the time domain
â€¢ 2 mitigations to stake bleeding: minimum chain density in the time domain & context sensitive transactions
â€¢ Figure 2: landscape of long-range attacks
â€¢ Figure 3: stake bleeding in a nutshell
â€¢ Idea (stake bleeding): stall on C (honest chain); mine/collect all fees & rewards on C' (private chain); stake grows on C' -> C' can progress faster than C
â€¢ Key?: relative stake of adversary on C' > relative stake of honest on C (eventually b/c honest on C loses fees also)
â€¢ Extra notes: https://archive.vn/MizCd (can grind in the time domain?), https://archive.vn/kD1Lx, https://archive.vn/BzeqV
â€¢ Higher stake => can progress faster
â€¢ Stake grinding: grinding (or withholding) to change the randomness itself / is a bit different?
â€¢ Also see: long-range attack from Ouroboros pg 59

52. Global, Unpredictable Bit Generation Without Broadcast
https://www.researchgate.net/profile/Donald-Beaver-2/publication/221348192_Global_Unpredictable_Bit_Generation_Without_Broadcast/links/5db90290a6fdcc2128eba5d9/Global-Unpredictable-Bit-Generation-Without-Broadcast.pdf
```
â€¢ A fast, efficient solution is of fundamental importance to distributed protocols, especially those that rely on  broadcast  channels. We present two unpre- dictable bit generators, based on the Blum-Blum-Shub generator, that can be evaluated non-interactively; that is, each bit (or group of bits)  requires each processor merely to send one message to the other processors, without  requiring a broadcast or Byzantine Agreement
â€¢ In this paper, we show how to generate  unpredictable bits efficiently and in  one round of communication. In fact, this  one  round of communication is very simple: it requires each processor to send the same message to all the other processors, but it does not require the system to check whether  each  processor did so. We call this weak form of broadcast "dissemination," and we show how to achieve an unpredictable coin using one round of dissemination
â€¢ We present two solutions, one based on the QRA' and one based  on the intractability of factoring. (The first  solution is more efficient, but basing it on the weaker assumption (factoring) is not an obvious  task.) Each solution uses a homomorphic technique for secret sharing in the style of Feldman [9]. (Caution is required, however; applying Feldman's VSS scheme as a "subroutinen leads to an easily predictable generator.) In a nutshell, it applies a generalized form of the Blum-Blum-Shub  (BBS)  pseudorandom number generator (71 to a hidden seed. and reveals the bits  in a coordinated  manner: no bit is revealed until some n - t processors decide it is time to do so, according to their programs
â€¢ The key property that we intend to capture is  that the bits are unpredictable - namely, an adversary has little better than a 50-50 chance to predict the next bit, although once it is generated, the sequence may be clearly distinguishable from uniformly random bits because other (useless) information is present; The Blum-Blum-Shub [7] generator provides a nice example
â€¢ For simplicity, let us assume the initialization is taken care of either by a trusted party or an initial multiparty protocol requiring broadcast. Thereafter, neither trust nor broadcast is needed
â€¢ After initialization,  each party holds a "share" y; of a secret value X = gN!' = zN!, similar to Feldman's VSS scheme [9]. Any other piece y, can be "checked" by raising it to an  appropriate power and comparing the result to tj, thus avoiding the need to share the shares for verification purposes. More to the point, because this scheme is homomorphic, each player i can generate a share of A' raised to any desired  power, simply by raisin y to that power. Thus, with- out interaction, each  player can generate shares of X2' , . . . , zZo, simply by computing Y, At each phase, each  player disseminates its share of the current power of X to be revealed. Unfortunately, it is not  clear how to interpolate X (or a power of it) directly from the pieces, since we do not know how to take arbitrary roots. Instead, X2"!) (and its various powers) are computed. The N! arises from making sure that a unique interpolation can be done over the integers without taking roots (ie. division in the exponents)
```
â€¢ Section 2.1: formula
â€¢ Section 4: exact construction
â€¢ Non-interactive: means disseminating once
â€¢ RSA group instead of mod p
â€¢ Idea: pregenerate all shares -> "threshold inversion" a la reverse(!) BBS
â€¢ Trusted setup
â€¢ N! (factorial) b/c of Lagrange interpolation

53. STROBE: Stake-based Threshold Random Beacons
https://eprint.iacr.org/2021/1643.pdf
```
â€¢ Existing beacon constructions are highly inefficient in practical settings whereprotocol parties need to rejoin after crashes or disconnections, and more significantlywhere  smart  contracts  may  rely  on  arbitrary  index  points  in  high-volume  streams.For this, we introduce a new notion ofhistory-generating decentralized randombeacons(HGDRBs)
â€¢ Roughly, thehistory-generationproperty of HGDRBs allows for previous beaconoutputs to be efficiently generated knowing only the current value and the public key.At application layers, history-generation supports registering a sparser set of on-chainvalues if desired, so that apps like lotteries can utilize on-chain values without incurringhigh-frequency costs, enjoying all the benefits of DRBs implemented off-chain or withdecoupled, special-purpose chains.  Unlike rollups, HG is tailored specifically to recov-ering and verifying pseudorandom bit sequences and thus enjoys unique optimizationsinvestigated in this work
â€¢ We  introduce  STROBE:  an  efficient  HGDRB  construction  which  generalizesthe original squaring-based RSA approach of Beaver and So.  STROBE enjoys severaluseful properties that make it suited for practical applications that use beacons: 1.history-generating: it can regenerate and verify high-throughput beacon streams,supporting sparse (thus cost-effective) ledger entries; 2.concisely self-verifying:   NIZK-free,  with  state  and  validation  employing  asingle ring element; 3.eco-friendly:  stake-based rather than work based; 4.unbounded:  refresh-free, addressing limitations of Beaver and So; 5.delay-free:  results are immediately available
â€¢ Our  starting  point  is  to  view  RSA  decryption  as  a  trapdoor  one-way  function  in  reverse,which  can  be  efficiently  verified.   The  beacon  output  of  an  epoch  is  essentially  the  RSAdecryption of the previous epochâ€™s output, and this carries on perpetually.  The verificationof an output is to just RSA encrypt it with the public key and see that if it equals to theprevious epochâ€™s output.  In this sense, the beacon isself-certifying
â€¢ To parties that just know aboutNas a public parameter, this provides some attractiveproperties:  (1) The next value in the beacon is hard to predict given the earlier values.  (2)Itâ€™s  easy  to  verify  a  beacon  value  against  the  last  value.   In  fact,  we  can  check  the  valueagainst any historical value, except that it gets progressively harder with the gap.  (3) Anespecially tantalizing property is that any historical beacon value, can in fact begeneratedby just knowing the current value
â€¢ Essentially, Shamir secret sharing involves fractionalLagrange interpolation coefficients which are efficient to compute to group elements if weknow the order.  However, this is not possible to do in the exponent of RSA group elements,asÏ†(N) is not public.  We adapt and extend the techniques pioneered by [7] and also usedby [52] to address this challenge.  The core trick is to lift the Lagrange coefficients by a factorofn!, so that they are not fractional anymore
â€¢ Since currently there is no knownway to sample a bi-prime (using only public randomness) for which nobody knows the factors,the only way to alleviate the trusted setup is to distribute the generation of the bi-primemodulus  via  a  dedicated  multi-party  computation  protocol
â€¢ We leave it as an open problem toconstruct an adaptively secure protocol which retains the efficiency standard of our selectiveone.  A generic (complexity-leveraging) approach can be used to get an adaptively securescheme from a selectively secure one: the reduction simply needs to guess the set of corruptedparties and then run the selective reduction aborting if the selection of corrupted parties doesnot match the one requested by the adversary.  This, unfortunately, leads to a loss in securitythat is exponential in the number of parties,n, thus limiting the number of parties to beat most logarithmic in the security parameterÎ».  There are other promising approaches inthe works for threshold RSA cryptosystems.  Canetti et al. [21] proposed a methodology fortransforming a selectively-secure threshold scheme into an adaptively-secure one, where theprotocol needs to be modified to carefully erase secrets and to use simple zero-knowledgeproofs, the adversary is rewinded in the proof which also incurs a security loss although notas large as with the complexity-leveraging approach.  A follow-up work of Almansa et al. [4]simplified this result for RSA, but at the cost of the secretâ€™s re-sharing after every round,with an emergent benefit of making the scheme proactively secure.  In a proactively securescheme  the  adversary  can  corrupt  at  mosttplayers  in  a  time  period  determined  by  theprotocol.  Since the set of corrupted parties changes, each party can become corrupt at somepoint (i.e.  leak its secrets), but if the party recovers from a compromise then a subsequentsecretâ€™s re-sharing will enable the party to be honest again
â€¢ In earlier sections we observed that it is possible to check the beacon valuexTat epochTagainst the seed valuex0by checkingx0=xsTT.  However, this takes sequential timeT.  Oneway to speed up verification is to exploit the RSA repeated powering structure of this checkand use existing techniques like [47, 55] to add a proof in addition to the beacon value.In particular, we can just apply Wesolowskiâ€™s [55] proof technique
â€¢ A better approach is to use a continuous VDF [33].  In a continuous VDF, it is efficient topublish and use intermediate proofs at every time epoch.  The Ephraim et al [33] continuousVDF  makes  use  of  the  recursive  structure  of  Pietzakâ€™s  VDF
```
â€¢ Idea: Strobe = Beaver/So - pregenerated shares (s.t. each share is indeed dependent on the past beacon output) + could be any "decryption key" s (not just 2)
â€¢ Unclear what "stake-based" means
â€¢ Section 2: summary of RSA group without trusted setup
â€¢ Trusted setup: no DKG -> one secret sharing poly with secret = s^{-1}

54. Efficient Random Beacons with Adaptive Security for Ungrindable Blockchains
https://eprint.iacr.org/2021/1698.pdf
```
â€¢ randomness beacon: a sequenceof high entropy values, continuously emitted at regular intervals, with sub-linear communication per value
â€¢ The algorithm can tolerate a(1 âˆ’ðœ–)âˆ•2fraction of theð‘›players to be controlled by anadaptiveadversary thatmay deviate arbitrarily from the protocol
â€¢ (i) with overwhelming probability inð‘˜â€”the security parameterâ€”each beacon value has highmin-entropy conditioned on the full history of the algorithm, and (ii) the total work and communication requiredper value isð‘‚(ð‘˜)cryptographic operations
â€¢ More broadly, we considerthe question of generating randomness for a long-lived distributed protocol that proceeds inepochs: Each epochof the protocol requires clean randomness, is responsible for carrying out a distributed computation of interest,and must furthermore generate the randomness to carry out the next epoch
â€¢ Our principal contribution is a simple protocolðthat achievesð¶ >1. The protocol isone-round, calling for each player to generate and broadcast a â€œnonceâ€ð‘¤ð‘–âˆˆ {0,1}ðœ†
â€¢ 1. With the seedð‘ , each player evaluatesð¹ð‘–(ð‘ ) =ð‘¤ð‘–. These values,ð‘¤ð‘–, along with proofs thatð¹ð‘–(ð‘ ) =ð‘¤ð‘–arebroadcast to all players.; 2. All valuesð‘¤ð‘–received (with correct proofs) are sorted lexicographically. The firstð‘˜values are hashed to-gether to produce the new seed ð‘ â€²
â€¢ Reducing broadcasts.The algorithm admits a simple optimization that yields a significant improvement in mes-sage efficiency; we call thisthe optimized version ofð. As written, the protocolðcalls forð‘›broadcast messages,one per party. However, as only thoseð‘¤ð‘–appearing among the firstð‘˜positions in the lexicographically sortedlist ofð‘¤ð‘–will contribute to the final value, playerð‘ƒð‘–can safely remain silent ifð‘¤ð‘–â‰¥ð“2ðœ†âˆ•ð‘›, for an appropriatelychosen thresholdð“> ð‘˜
â€¢ Many proof-of-stake blockchain protocols,such as Ouroboros Praos [10], Genesis [2], and Snow White [5], use VRFs in their coin-flipping protocols. (VRFsare formally defined in Definition 1.) This is a multi-round protocol where each â€œblockâ€ contains a nonce. Thecoin-flipping output is a cryptographic hash of the XOR of the nonces recorded in the â€œcommon prefixâ€ of allblockchains held by the honest players at the end of the epoch. (Thus, these protocols do not use a broadcastchannel.) We can call these beacon protocols â€œhash the blockchainâ€ beacons. It was shown in the Ph.D. the-sis [22] that the min-entropy loss for this beacon in a single epoch (in the synchronous communication setting)grows linearly in the security parameter if the adversarial stake is9.5%or higher
â€¢ Our simple beacon protocol can be directly incorporated into these blockchain protocols by the standard de-vice: the broadcast channel is implemented using blockchain consensus mechanism itself
â€¢ Indeed, protocols based on publicly-verifiable secret sharing schemes (e.g., Ouroboros [18]) can achieve perfectrandomness with two rounds. The emphasis on one-round solutions arises because of adaptive security and thefact that the length of the randomness generation algorithm is an important design parameter
â€¢ Our contribution.Recall that our objective is anð‘›-player beacon protocol with the following properties: (i) itis an iterated single-round coin-flipping protocol; (ii) it is secure against an adaptive adversary who may controlless than half the players (or, equivalently, in the proof-of-stake setting, control less than a50%stake); (iii) it isallowed to use a broadcast channel and cryptography; (iv) the setup and communication complexity is sublinearinð‘›; (v) for some parameterð‘˜(which is independent ofð‘›), the loss in the output min-entropy isð‘‚(ð‘˜)except withprobabilityð‘’âˆ’â„¦(ð‘˜)
â€¢ The optimized version of our beacon protocolðhas all these properties. To our best knowledge, no otherbeacon does the same: 1. Algorand [9]â€”one of the main inspirations for this paperâ€”provides single-round coin-flipping but guar-antees high min-entropy with only a constant probability. Our approach can be viewed as a kind of paral-lelization of the Algorand technique; see below.; 2. The coin-flipping in Ouroboros and RandHound [25] are multi-round and insecure against an adaptiveadversary who controls a minority stake or a minority coalition, respectively. DFINITY [16] uses one-roundcoin-flipping but, like Ouroboros, it is secure only against a static adversary
â€¢ We leave the combination of VDF techniques with our randomnessgeneration algorithm as an interesting future research direction
â€¢ As mentioned above, our protocol can be viewed as a parallelization of the Al-goRand technique; indeed, a single-round of AlgoRand coin-flipping is equivalent to settingð‘˜= 1in our protocol.In contrast, our one-round protocol guarantees a â€œsmallâ€ loss in min-entropy except with a negligible probability
â€¢ Finally, consider the behavior of the protocol in the iterated setting. As discussed in theintroduction,ðð‘˜is used to generate a sequence of beaconsð‘ 0,ð‘ 1,...,ð‘ ð‘‡; We conclude that except with probabilityð‘‡ð‘âˆ’ð‘˜, each beacon value has min entropyðœ†âˆ’ð‘˜logð‘Ž, as desired
```
â€¢ Some error probability & min entropy discussion
â€¢ ("epoch", "nonce") = (round, entropy contribution)
â€¢ Idea: VRF lottery -> everyone broadcasts each VRF output ("optimized" version if not all need to) -> hash the k lowest outputs

55. On the Notion of Pseudo-Free Groups
https://people.csail.mit.edu/rivest/Rivest-OnTheNotionOfPseudo-FreeGroups.pdf
â€¢ Their formulation: pseudo-free <=> no adversary can find an equation E that doesn't have a solution in the free group F(A) but has one in G
â€¢ My formulation: pseudo-free <=> all equations that don't have a solution in F(A) shouldn't have a solution in G
â€¢ RSA group being pseudo-free <=> Strong RSA assumption
â€¢ Example (for understanding): x^2 = a doesn't have a solution in the free group -> also shouldn't in (mod N) assuming RSA group being pseudo-free

56. The Algebraic Group Model and its Applications
https://eprint.iacr.org/2017/620.pdf
```
â€¢ To overcome this limitation, we propose the Algebraic Group Model (AGM), a modelthat lies in between the Standard Model and the GGM. It is the first restricted model ofcomputation covering group-specific algorithms yet allowing to derive simple and meaningfulsecurity statements. To prove its usefulness, we show that several important assumptions,among them the Computational Diffie-Hellman, the Strong Diffie-Hellman, and the interactiveLRSW assumptions, are equivalent to the Discrete Logarithm (DLog) assumption in theAGM. On the more practical side, we prove tight security reductions for two importantschemes in the AGM to DLog or a variant thereof: the BLS signature scheme and Grothâ€™szero-knowledge SNARK (EUROCRYPT 2016), which is the most efficient SNARK for whichonly a proof in the GGM was known
â€¢ LetGbe a cyclic group of prime orderp. Informally, we call an algorithmAalgalgebraicif itfulfills the following requirement: wheneverAalgoutputs a group elementZâˆˆG, it also outputsa â€œrepresentationâ€~z= (z1,...,zt)âˆˆZtpsuch thatZ=âˆiLzii, where~L= (L1,...,Lt)is the listof all group elements that were given toAalgduring its execution so far
â€¢ We propose thealgebraic group model(AGM) â€” a computational model in which all adversariesare modeled as algebraic.  In contrast to the GGM, the AGM does not allow for provinginformation-theoretic lower bounds on the complexity of an algebraic adversary. Similar tothe Standard Model, in the AGM one proves security implications via reductions
â€¢ The AGM is stronger (in the sense that it putsmore restrictions on the attackers) than the Standard Model, but weaker than the GGM. Inspite of this, all of our reductions are purely generic algorithms. As mentioned above, anygeneric algorithm can be modeled within the AGM. In particular, combining arbitrary genericoperations with algebraic ones will yield an algebraic algorithm. This suggests the followingidea. LetHandGbe two computational problems and letAalgbe an algebraic algorithm thatsolves problemG. If we can convertAalgby means of a generic reduction algorithmRgenintoan algorithmBalgfor problemH, then clearly,Balgis also an algebraic algorithm. However, weobtain an even stronger statement for free: Namely, ifAgenis a generic algorithm solvingG,thenBgenis a generic algorithm solvingH. This means that results in the AGM directly carryover to the GGM
â€¢ For this reason, we believe that our model offers an alternative, perhaps simpler method ofproving the hardness of computational problems within the GGM. This applies in particularto interactive assumptions, which can be rather difficult to analyze in the GGM. For example,we prove that the discrete logarithm assumption implies the LRSW assumption in the AGM.As the discrete logarithm assumption holds in the GGM, we instantly obtain that the LRSWassumption holds in the GGM
â€¢ As already noted, one of the main benefits of our model overthe GGM is the ability to reason about algorithms that arbitrarily exploit the structure of the group
```
â€¢ AGM: uses actual bitstrings (not allowed in GGM)?
â€¢ Lemma: all generic algorithms are algebraic
â€¢ Idea (can show GGM via AGM): breaking A via algebraic (or generic) + reduction is generic => breaking B via algebraic (or generic)
â€¢ Std model < AGM < SAGM (Katz) < GGM -- in terms of restrictions on adversary
â€¢ Example: DLP reduces to CDH (can break CDH to break DLP under AGM)

57. On the Security of Time-Lock Puzzles and Timed Commitments
https://eprint.iacr.org/2020/730.pdf
```
â€¢ We give the first hardness result about the sequential-squaring con-jecture in a non-generic model. Namely, in a quantitative version ofthe algebraic group model (AGM) that we call thestrongAGM, weshow that speeding up sequential squaring is as hard as factoring N
â€¢ We extendexisting  security  definitions  to  settings  that  may  arise  when  usingtimed commitments in higher-level protocols, and give the first con-struction ofnon-malleabletimed commitments
â€¢ We  studythis  assumption  in  a  new,  strengthened  version  of  the  algebraic  group  model(AGM) [16] that we call thestrong AGM (SAGM), which lies between the genericgroup  model  (GGM)  [24, 32]  and  the  AGM.  Roughly,  an  algorithmAin  theAGM is allowed to utilize theactual  bitstringsrepresenting group elements inthe course of its computation (something that is not allowed in the GGM), butis  constrained  in  the  sense  that  for  any  group  elemenththatAoutputs,Amust also output coefficients showing howhwas computed from group elementspreviously  given  toAas  input.  The  SAGM  imposes  the  stronger  constraintthatAoutput  theentire  path  of  its  computation(i.e.,  all  intermediate  groupoperations) that resulted in h
â€¢ We also show that it is not possible to reduce the hardness ofsequential squaring to factoring in the AGM (assuming factoring is hard in thefirst place). Our result is the first formal argument for the sequential hardnessof  squaring  in  a  non-generic  model,  and  immediately  implies  the  security  ofPietrzakâ€™s VDF [28] in the SAGM (assuming the hardness of factoring)
â€¢ In  the  SAGM  westrengthen this and require an algorithm to express any group element as either(1) aproductof two previous group elements that it has either received as inputor already computed in some intermediate step, or (2) aninverseof a previousgroup element that it has either received as input or already computed in someintermediate step
```
â€¢ Idea: std model < AGM < SAGM < GGM -- in terms of restrictions on adversary
â€¢ Computational RSW is proven (breaking it implies breaking factoring), but decisional RSW is assumed?
â€¢ Simulation-sound NIZK
â€¢ Running time in SAGM = number of algebraic steps taken (allowing parallelism)
â€¢ Construction 1: CPA timed encryption (Diffie-Hellman style) + decisional RSW assumption + Naor-Yung -> CCA scheme
â€¢ Construction 2: their non-malleable TC is based on Construction 1

58. Attribute-Hiding Predicate Encryption With Equality Test in Cloud Computing
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8379425
```
â€¢ Public key encryption with equality test (PKE-ET) enables anyone to perform equivalencetest between two messages encrypted under distinct public keys. Attribute-hiding predicate encryptionis a paradigm for public key encryption that supports both attribute-hiding and fine-grained access con-trol. In this paper, we first initialize the concept of attribute-hiding predicate encryption with equalitytest (AH-PE-ET) by incorporating the notions of PKE-ET and PE, and then propose a concreteAH-PE-ET scheme
â€¢ In the AH-PE-ET scheme, onedata receiver can calculate a trapdoor using his/her private key and delivers this trapdoor to an untrusted cloudserver, who in turn compares the ciphertexts from this receiver with other receiversâ€™ ciphertexts. During thecomparison, the information about the trapdoor as well as the attributes associated with the ciphertexts willnot be disclosed to this cloud server
```
â€¢ Heavily reliant on pairings
â€¢ Idea: âˆƒ"trapdoor" (< individual secret key) that enables "equality test on ciphertexts" (i.e. check if messages are equal given ciphertexts)
â€¢ Use case: IoT sensor encrypts (to its pk?) data and keywords + user requests keyword search by sending encrypted (to its pk?) keywords to untrusted cloud server => cloud is able to perform equality test on ciphertexts using trapdoors only (such that can't fully decrypt)

59. Public Randomness Extraction with Ephemeral Roles and Worst-Case Corruptions
https://eprint.iacr.org/2022/237.pdf
```
â€¢ We distill a simple information-theoretic model for random-ness  extraction  motivated  by  the  task  of  generating  publicly  verifiablerandomness in blockchain settings and which is closely related toYou-Only-Speak-Once (YOSO)protocols (CRYPTO 2021)
â€¢ With the goal ofavoiding  denial-of-service  attacks,  parties  speak  only  once  and  in  se-quence by broadcasting a public value and forwarding secret values tofuture  parties.  Additionally,  an  unbounded  adversary  can  corrupt  anychosen  subset  of  at  mosttparties.  In  contrast,  existing  YOSO  proto-cols only handle random corruptions
â€¢ With respect to feasibility, we give protocols fortcorruptions andn= 6t+ 1 orn= 5tparties depending on whether the adversarylearns secret values forwarded to corrupted parties immediately oncethey are sent or only once the corrupted party is executed, respec-tively
â€¢ To complement our protocols, we show that low-error randomnessextraction is impossible with corruption thresholdtandnâ‰¤4tpar-ties in both settings above. This also provides a separation betweenchosen and random corruptions, since the latter allows for random-ness extraction with close ton/2 random corruptions
â€¢ Our model is in particular motivated by the notions ofplayer-replacableprotocols  as  introduced  by  Micali  [Mic16]  andYou-Only-Speak-Once(YOSO)protocols  as  introduced  by  Gentry,  Halevi,  Krawczyk,  Magri,  Nielsen,  Rabin,and Yakoubov [GHK+21]. In these classes of protocols, each party only sendsmessages once
â€¢ More precisely, we consider a multiparty computation model wherenpartiesP1,...,Pnare activated sequentially, with each party having access to an internalsource of randomness. To begin with,P1is executed and it outputs a public valuex1which  we  think  of  as  being  shown  to  all  parties,  including  the  adversary.Moreover,P1also gets to send secret valuess1,jto each future partyPj
â€¢ Information may be revealed to the adversary in different ways. We considertwo  scenarios,  which  we  term  thesending-leaksandexecution-leakssettings.In  the  sending-leaks  setting,  if  partyPiis  honest  and  sends  the  secret  valuesi,jto  a  corrupted  partyPjduring  its  execution,  then  the  adversary  learnssi,jimmediately. In contrast, in the execution-leaks setting the secret valuesi,jwould only be revealed to the adversary later when the corrupted partyPjisexecuted. The motivation behind these settings is related to how the forwardingof the secret values is implemented in practice
â€¢ In particular, one can generate unbiased randomness using this approach byhaving  all  parties  run  a  verifiable  secret  sharing  protocol  of  a  random  value,and then reconstruct all values and XOR them. Using, for instance, the protocolfrom  [CGG+21]  with  2-round  sharing  and  1-round  reconstruction  procedurestoleratingt < m/3  corruptions,  we  immediately  obtain  a  randomness  extrac-tion protocol in our model toleratingt < n/9 corruptions. However, this is notvery satisfactory
â€¢ Can  we  improve  the  lower  and  upper  bounds  on  the  exact  maximumcorruption threshold that allows for public randomness generation in ourmodel?
â€¢ The main difference between player-replaceable and YOSO proto-cols is that player-replaceable protocols only allow public messages and YOSOprotocols allow secret messages
â€¢ However, there are twoadditional issues to keep in mind when performing MPC in this model:First,how does a party send a secret value to an unknown future speaker? Second, howimpartial is the selection of speakers?
â€¢ The YOSO paper [GHK+21] studiesmainlyrandomcorruptions  (i.e.,  each  party  is  independently  corrupted  withsome constant probability). The motivation behind this is that, since rolesRareassumed to be mapped uniformly to partiesPby some perfectly random roleassignment mechanism; However, there are natural motivations for considering worst-case corruptionsin this model, as opposed to random corruptions
â€¢ Other  works  have  considered  related  models  where  parties  publish  publicvalues in sequence but future secret values are not permitted, such as Santha-Vazirani sources [SV84], Bitcoin beacons [BGZ16], and SHELA sources [AOR+20].Crucially, in such versions it is not possible to deterministically extract uniformlyrandom bits
â€¢ Theorem 1  (Feasibility  in  the  sending-leaks  model).There  is  a  zero-errorn-party  randomness  extraction  protocol  secure  against  any  sending-leaksadversary with corruption threshold t whenever nâ‰¥6t+ 1
â€¢ Theorem 2  (Feasibility in the execution-leaks model).There  is  a  zero-errorn-party randomness extraction protocol secure against any execution-leaksadversary with corruption threshold t whenever nâ‰¥5t
â€¢ Theorem 3  (Impossibility result).There is no randomness extraction pro-tocol  secure  againsttcorruptions  withnâ‰¤4tparties  and  bias  less  than1/100in both the sending-leaks or execution-leaks models
â€¢ Extracting multiple random bits.Observe that in order to extract aÎ»-bitstring of unbiased random bits, we can just run our protocolsÎ»times in parallel.This incurs an extra factor ofÎ»in the total communication complexity. We leaveit as an interesting open problem to improve on this approach
â€¢ Impossibility result.We now discuss the approach behind our impossibilityresult  in  Theorem  3.  For  the  sake  of  simplicity,  consider  a  protocol  with  fourpartiesP1,...,P4and one corruption, and assume that a (close to) final out-put  bit  is  produced  if  all  parties  behave  honestly.  Our  proof  follows  a  carefulsequential argument where we analyze what would happen if we corrupted par-tiesP4throughP1. At a high level, we show that either the behavior of partiesP1,...,Piâˆ’1already fully determines the final output of the protocol with highprobability, or corruptingPiallows an adversary to locally control and bias thefinal output
```
â€¢ Chosen vs random corruptions (in YOSO?)
â€¢ 2 "role assignment protocols" ("role" ~= code to be executed): ephemeral key method (~= sending-leaks model) & threshold IBE method (~= execution-leaks model)
â€¢ Committee-based methodology: could be bad if entire committee could be corrupted => worse bounds
â€¢ Section 1.3: technical overview
â€¢ Final output = take the majority twice + XOR across sets S

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Universal
Blum-Micali & BBS
Chameleon sig?
Min-entropy
OWF => PRG (BM) => PRF (GGM) => PRP (LR = Feistel) -- converse is also true?!
OWF, OWP, TDP (trapdoor permutation)
BG (Blum-Goldwasser): asymmetric encryption a la BBS
Non-uniform PPT & advice string
IND-CPA (game-based) vs semantic security (simulation-based)

Semantic security => not deterministic
Hardcore bit/predicate
Goldreich-Levin construction
Hybrid argument & poly-many distributions
Left-or-right indistinguishability ~= IND-CPA