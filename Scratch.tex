\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix-2020-09}
\usepackage[backend=bibtex,sortcites]{biblatex}
\addbibresource{bib.bib}
% Language and font encodings
% \usepackage[english]{babel}
% \usepackage[utf8]{inputenc}

% Sets page size and margins
% \usepackage[letterpaper,margin=1.5in]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
% \usepackage{hyperref}
\usepackage{seqsplit}
\usepackage{indentfirst}
\usepackage{tabu}
\usepackage{lipsum}
\usepackage{array}
\usepackage{tocloft}
\usepackage{float}
\usepackage[font=small,labelfont=bf]{caption}
\usepackage{etoolbox}
\usepackage{setspace}
\usepackage{braket}
% start table
\usepackage{tabularx,booktabs,multirow}
\usepackage{diagbox}
\newcolumntype{C}{>{\centering\arraybackslash}X} % centered version of "X" type
\setlength{\extrarowheight}{1pt}
\newcommand{\spheading}[2][7em]{ % \spheading[<width>]{<stuff>}
    \rotatebox{90}{\parbox{#1}{\raggedright #2}}}
\usepackage{pifont} % http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}
\usepackage{threeparttable}
\DeclareMathOperator*{\argmin}{argmin}
% end table
\AtBeginEnvironment{quote}{\singlespace\vspace{1em}\small}
\AtEndEnvironment{quote}{\vspace{1em}\endsinglespace}
\renewcommand{\arraystretch}{1.5}
\tabulinesep = 2mm

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{notes}{Notes}
\renewcommand\qedsymbol{$\blacksquare$}

\newcommand{\todo}[1]{\textcolor{red}{\textbf{TODO:} #1}}
\newcommand{\joenote}[1]{\textcolor{blue}{\textbf{JOE:} #1}}
\newcommand{\kevinnote}[1]{\textcolor{green}{\textbf{JOE:} #1}}
\newcommand{\aathiranote}[1]{\textcolor{purple}{\textbf{JOE:} #1}}

\title{\Large \bf A Survey on Distributed Randomness}
\author{
{\rm Kevin Choi}\\
New York University
\and
{\rm Aathira Manoj}\\
New York University
}
% \date{Spring 2021}

\begin{document}

\maketitle
\tableofcontents

\section{Introduction}
Generating periodic trustworthy randomness is crucial to applications ranging from sampling ballots for recounts in electronic voting \cite{adida2008helios} and choosing winning numbers in gambling and lottery services \cite{bonneau2015bitcoin} to leader election in proof-of-stake blockchains \cite{gilad2017algorand, kiayias2017ouroboros}, blockchain sharding \cite{al2017chainspace, kokoris2018omniledger, luu2016secure}, and selecting parameters for cryptographic protocols \cite{baigneres2015trap, lenstra2015random}. The process of generating reliable randomness is nontrivial, as obtaining access to good sources of randomness, even in terms of entropy alone, can be difficult and prone to errors.
% Randomness beacon
\todo{This needs re-writing to cast beacons as an ideal concept first, then describe some approximations. Beacons are not necessarily third-party}
\todo{Mention that this paper is not focusing on other beacons e.g. stock market}
\todo{Need a clearer transition of what a distributed randomness beacon is} \joenote{beacon or protocol? I would argue it's a distributed randomness protocol that is used as a beacon.}

\textbf{Randomness Beacons.} The concept of randomness beacon was first formalized by Rabin \cite{rabin1983Rabin} to describe an ideal service that emits fresh random numbers at regular intervals that no party can manipulate. Because no such ideal beacon exists, various solutions ranging from centralized approaches, relying on a single source or organization to distributed approaches, decentralizing the randomness generation among a set of nodes, are used to approximate it.

\textbf{Centralized Beacons.} While centralized approaches like relying on a trusted third party like NIST \cite{fischer2011public} or random.org \cite{haahr2010random} might be the simplest way to realize a beacon, it carries drawbacks typically associated with centralized services, in particular, risk of tampering, risk of benefit from prior knowledge of randomness and inability of the end-user to verify that the numbers they are getting from beacon are random. Users have to trust that the system is providing genuinely random numbers. For these reasons, it is strongly desirable to construct a beacon with no trusted parties or central point of failure.

\textbf{Biasable External Beacons.} The other alternative is to construct a beacon using publicly available external sources of entropy such as stock-market data \cite{clark2010use} or PoW blockchains like Bitcoin \cite{nakamoto2019bitcoin, han2020randchain} as formalized in \cite{bonneau2015bitcoin}. However, such beacons are vulnerable to malicious insiders.

Beacons realized using stock-market data are susceptible to manipulation from high-frequency traders through unnatural sales or purchases, particularly near the closing time of the market. To add to this, the extent to which the financial exchanges are in fact trusted parties that could manipulate or halt the beacon output also remains unclear.

Even though the decentralized nature and the large amount of computational work expended on maintaining a PoW blockchain makes them good sources of entropy, the security of such beacons are heavily dependent on the extent to which the miners can be bribed to withhold blocks to create a bias. The issue aggravates when the miners themselves are stakeholders in the output of the beacon.

\textbf{Distributed Randomness Beacons.}
A natural approach to further distribute and decentralize trust is to rely on a set of mutually-distrustful nodes and use distributed protocols to generate randomness. The distributed randomness protocol can publish verifiable and unbiased random numbers periodically and be used as a beacon. We call such a beacon a Distributed Randomness Beacon (DRB). In this paper, we focus on distributed randomness protocols that can be used to realize a DRB.

\textbf{Contribution.} The goal of the paper is to systematize the current progress on the problem of generating reliable distributed randomness and devise a theoretical framework and generalization encompassing all distributed randomness protocols in the landscape. To aid comparison and discussion of properties and potential drawbacks and benefits, we provide an overview of these protocols along with the various cryptographic building blocks used to construct them. Drawing from a scattered body of knowledge, we identify two key components of a practical DRB's design --- selection of entropy providers and beacon output generation, which can be decoupled from each other. This enables a more insightful analysis of existing protocols which can also be extended to future protocols with similar design. Finally, we provide new insights and discussion on various techniques which can be used to improve existing protocols.

\textbf{Paper organization.} We organize the paper as follows. Preliminaries including our system model, a strawman DRB leveraging perfect synchrony (an ideal assumption), commit-reveal, and the definition of an ideal DRB are described in Section \ref{section:preliminaries}. Then from Section \ref{section:vdf} to \ref{section:dvrf}, protocols in the landscape are introduced in decreasing order of number of nodes providing \textit{marginal entropy} (i.e. randomness that is independently generated at a node level and is broadcast during the newest round of a DRB) with the exception of those that are based on verifiable delay functions (which merit a separate section, namely Section \ref{section:vdf}). Accordingly, Section \ref{section:commit-reveal-punish} and \ref{section:commit-reveal-recover} review protocols in which all nodes must provide marginal entropy while erroneous behaviors by some nodes are successfully counteracted by financial punishment and threshold secret sharing or threshold encryption, respectively. Section \ref{section:subset-based} illustrates protocols that include in the beginning of each round an extra step of subset selection, enabling only a subset (non-empty and proper) of nodes to provide marginal entropy for the sake of efficiency (overall computational and communication complexity). In Section \ref{section:dvrf}, we furthermore have protocols that do not require any marginal entropy to generate a beacon output.

\section{Preliminaries}
\label{section:preliminaries}
We delineate the necessary preliminaries in this section, starting with the introduction of a strawman ``rock-paper-scissors'' DRB protocol assuming a perfectly synchronous network (with zero latency in message delivery between the message sender and the receiver) as well as that of the classical commit-reveal. Identifying problems in both, we define the security of an ideal DRB. First, we describe our system model (including threat model) relevant in all protocols portrayed in this paper (unless stated otherwise).

\subsection{System Model}
We consider a system model with $\mathcal{P} = \{P_1, P_2, ..., P_n\}$ comprising $n$ participants (called nodes), also often denoted by $\mathcal{P} = \{1, 2, ..., n\}$ for the purpose of algebraic formulations without loss of generality. Out of $n$, up to $t$ faulty nodes (deemed \textit{Byzantine}) engage in incorrect behaviors during a protocol run, and an adversary $\mathcal{A}$ that controls such $t$ nodes is called \textit{$t$-limited}. Otherwise, nodes that are \textit{honest} abide by the specified protocol.

Given a standard public key infrastructure such that all nodes know each others' public keys, we assume the nodes are connected via point-to-point secure (providing authenticity) communication channels. All messages exchanged by honest nodes are digitally signed by the sender, and the recipient always validates each message before proceeding. By default, we assume a \textit{synchronous} network, in which there exists some known finite message delay bound $\Delta$. This means that an adversary can delay a message by at most $\Delta$.

Moreover, we assume a computationally bounded adversary $\mathcal{A}$ runs in PPT (probabilistic polynomial time) and that $\mathcal{A}$ cannot break standard cryptographic constructions such as a hash function, digital signatures, the discrete log problem, etc. The three ways in which $\mathcal{A}$ can deviate from a protocol are omitting a message (i.e. \textit{withholding attack}), sending invalid messages, and colluding to coordinate an attack based on private information shared among Byzantine nodes. Additionally, $\mathcal{A}$ has the power to perform a \textit{grinding attack}, in which $\mathcal{A}$ privately precomputes and iterates through as many combinations of inputs to an algorithm as possible in order to derive a desirable output. By default, we assume a \textit{static} adversary that chooses nodes to be corrupted before a protocol run whereas an \textit{adaptive} adversary can choose nodes to be corrupted at any time during a protocol run (although we assume a model where nodes remain corrupted once corrupted).

Our computational model is parametrized by a security parameter $\lambda$. We call a function $negl(\lambda)$ \textit{negligible} if for all $c > 0$ there exists a $\lambda_0$ such that $negl(\lambda) < \frac{1}{\lambda^c}$ for all $\lambda > \lambda_0$. The group elements $g, h \in \mathbb{G}$ are generators of $\mathbb{G}$ while $p, q$ denote primes such that $q \mid p - 1$ (unless stated explicitly). The notation $tuple[0]$ denotes the first element of $tuple$. Furthermore, we model any hash function $H(\cdot)$ as a random oracle. In the context of a distributed randomness beacon, we use $r$ to denote round number and $\mathcal{O}_r$ to denote the \textit{beacon output} (i.e. the distributed randomness output) in round $r$. The \textit{entropy-providing subset} refers to a subset of nodes (hereafter called \textit{entropy providers}) that proactively generate and provide marginal entropy in the newest round $r$. Subject to change every round, this subset can include all nodes, some but not all nodes, one node (i.e. a leader), or no node.

\subsection{Strawman Protocol Assuming Perfect Synchrony}
Sourcing a joint random number from $n$ participants assuming perfect synchrony is straightforward. Consider the following ``rock-paper-scissors'' protocol where each participant $i$ for $i = 1, ..., n$ broadcasts its entropy share (i.e. independently generated randomness) $e_i \in \mathbb{N}$ to every other participant at the same time as per simultaneity observed in real life (say) in rock-paper-scissors. Naturally, its protocol output $\mathcal{O}$ can be given by
\[
\mathcal{O} = \sum_{i = 1}^n e_i
\]
where applying this mechanism $\tilde{r}$ times at $\tilde{r}$ chronological timestamps would yield a DRB in the form of $\{\mathcal{O}_r\}_{r = 1, ..., \tilde{r}}$.

While simple and agreeable, such rock-paper-scissors DRB is indeed a strawman solution in a non-ideal setting where the perfect synchrony assumption is never true. In fact, situations can change dramatically in a practical setting where participants can go offline (perhaps temporarily) due to network failure, messages can be delayed either non-significantly or significantly, and Byzantine attackers can try to predict or bias the randomness to their benefit.

Consider the following simple scenario without perfect synchrony: three participants $\{P_1, P_2, P_3\}$ coordinate to produce $\mathcal{O} = e_1 + e_2 + e_3$ where each $P_i$ sends $e_i$, and suppose $P_3$ already obtains the knowledge of $e_1$ and $e_2$ (due to non-zero message latency) before sending $e_3$ to $P_1$ and $P_2$ as the last step of the protocol. Then $P_3$ is able to set the output $\mathcal{O}$ to be whichever desirable value $\tilde{\mathcal{O}}$, as it can choose $e_3 = \tilde{\mathcal{O}} - e_1 - e_2$. Effectively, this protocol becomes centralized by $P_3$.

\subsection{Commit-Reveal}
\label{subsection:commit-reveal}
A classical improvement to the above issue, commit-reveal provides an intuitive way to source a joint random number from a group of participating nodes by introducing a cryptographic commit step before revealing. It runs as follows.
\begin{enumerate}
\item \underline{Commit}. Each participant $P_i$ broadcasts its cryptographic commitment $C_i = \mathsf{Com}(e_i, r_i)$ (with fresh randomness $r_i$) to its entropy share $e_i$ rather than $e_i$ itself. Note that $\mathsf{Com}(x, r)$ denotes a cryptographic commitment to $x$ with hiding and binding properties (see Appendix \ref{appendix:commitment}).
\item \underline{Reveal}. Once all participants have shared their corresponding commitments, each participant $P_i$ then opens the commitment by revealing the pair $(e_i, r_i) = \mathsf{Open}(e_i, r_i)$. In turn, $P_i$ verifies the received pair $(e_j, r_j)$ for $j \neq i$ by checking the equality $C_j = \mathsf{Com}(e_j, r_j)$. Given that these checks pass, the final output $\mathcal{O}$ can canonically be given by
\[
\mathcal{O} = \sum_{i = 1}^n e_i
\]
all of which can be repeated to prolong a DRB. If any of the preceding checks does not pass, however, the protocol aborts.
\end{enumerate}

Note that due to the additional commit step, it becomes impossible for one participant to centralize the process and set the final randomness to be whichever desirable value. Nonetheless, the problem of biasing still exists, as the last participant $P_k$ to reveal its share can in fact compute and check $\mathcal{O}$ earlier than others and hence can decide not to reveal $(e_k, r_k)$ if $\mathcal{O}$ is not to its liking. This is called the \textit{last revealer attack}.

\subsection{Ideal Distributed Randomness Beacon}
Clearly, we should prevent anyone from tampering with (e.g. predicting, biasing, or delaying) each beacon output of a DRB in any way. Apart from this, the randomness should be verifiable by any third party. Based on these requirements, the overall security properties of an ideal DRB are given by the following.

\begin{definition}[Ideal distributed randomness beacon]
A distributed randomness beacon is \textit{ideal} or \textit{secure} if it satisfies the following four properties.
\begin{enumerate}
\item Bias Resistance (or Unbiasability). No PPT adversary $\mathcal{A}$ can bias any $c$ bits of $\mathcal{O}_r$. In other words, $\mathcal{A}$ cannot force $c$ bits of $\mathcal{O}_r$ to be some arbitrarily chosen bits with probability greater than $\frac{1}{2^c} + negl(\lambda)$.
\item Unpredictability. Similarly, $\mathcal{A}$ cannot predict any $c$ bits of $\mathcal{O}_r$ with probability greater than $\frac{1}{2^c} + negl(\lambda)$. The protocol satisfies \textit{$d$-unpredictability} \cite{bhat2020randpiper} for $d \in \mathbb{N}$ if this is true for any round greater than or equal to $r + d$ (where $r$ denotes the current round).
\item Liveness. A la game-based security, we can define the liveness property \cite{guo2020secRand} by requiring that the advantage of $\mathcal{A}$ in attacking liveness denoted by $Pr[\mathcal{O}_r = \text{$\perp$}]$ (i.e. the probability that the honest beacon output at the end of round $r$ is null) is negligible, given a DRB that runs among honest participants and $\mathcal{A}$.
\item Public Verifiability. Any third party should be able to verify the beacon outputs based on public information. In other words, suppose the advantage of $\mathcal{A}$ in attacking public verifiability is given by
\[
\left\lvert 1 - Pr\left[b = b' \middle\vert \begin{array}{l}
y_0 = \mathcal{O}_r;\\
y_1 \leftarrow \mathcal{A}(priv_r, pub_r);\\
b \leftarrow \{0, 1\};\\
b' \leftarrow V(y_b, pub_r)
\end{array}\right]
\right\rvert
\]
where the protocol runs among honest participants and $\mathcal{A}$ (which has access to private information $priv_r$ in round $r$ as a $t$-limited participant), $pub_r$ denotes public information emitted in round $r$, and $V$ is a third party verifier. Then this advantage is negligible such that $\mathcal{A}$ cannot fool a verifier into accepting $\tilde{\mathcal{O}_r} \neq \mathcal{O}_r$ as a DRB output.
\end{enumerate}
\end{definition}

We next begin our discussion of various approaches to realizing an ideal DRB generally in decreasing order of number of nodes providing marginal entropy. The reasoning behind this is that while it is the most intuitive to require every node's marginal entropy (a la commit-reveal) for the sake of distributed randomness, the narrative is often that a novel dose of cryptography can help eliminate the need for everyone's role as an entropy provider while maintaining the security of a DRB and therefore lead to better efficiency and scalability. We start with protocols based on verifiable delay functions.

\section{VDF-Based Protocols}
\label{section:vdf}
One way to prevent the last revealer attack is to add a delay function after collecting entropy, making it slow to compute the final beacon output. As long as the delay is suitably long, none of the participants would be able to determine the final beacon output and manipulate or withhold their shares to bias it. A verifiable delay function (VDF) \cite{boneh2018verifiable} can be used to accomplish this.
\begin{definition}[Verifiable Delay Function]
A Verifiable Delay Function (VDF) is a function that takes a specified number of sequential steps to compute which cannot be parallelized. However the output can be quickly verified by anyone such that for every input $x$, there exists a unique output $y$ only which will be verified successfully. In other words, one cannot come up with an accepting proof for a wrong output.
A VDF can be described via a set of three algorithms:
\begin{itemize}
\item $\mathsf{Setup}(\lambda, T) \rightarrow pp$ is a randomized algorithm that takes a security parameter $\lambda$ and a time bound $T$  and outputs public parameters $pp$ sampled from some parameter space $PP$.
\item $\mathsf{Eval}(pp, x) \rightarrow (y, \pi)$ takes public parameters $pp\in PP$, an input $x$ and outputs $y$ and a proof $\pi$.
\item $\mathsf{Verify}(pp, x, y, \pi) \rightarrow \{Accept, Reject\}$ outputs $Accept$ if $y$ is the correct evaluation of the VDF on input $(pp, x)$ and $Reject$ otherwise.
\end{itemize}
\end{definition}
 The two well-regarded VDF proposals, one due to Pietrzak \cite{pietrzak2018simple} and the other due to Wesolowski \cite{wesolowski2019efficient}, make use of the serial nature of exponentiation in a group of unknown order to implement a VDF. 

A VDF can be used to generate unbiasable randomness from biasable sources of entropy such as naive commit-reveal scheme or public sources of randomness such as stock prices or proof-of-work blockchains (e.g. Bitcoin \cite{nakamoto2019bitcoin}, Ethereum \cite{wood2014ethereum}). Or it can be used to construct an entirely new protocol (like RandRunner \cite{schindler2021randrunner}) altogether. These three approaches are summarized in the following sections.

\subsection{Extending Commit-Reveal}
\label{subsection:extending-commit-reveal}
The work of \cite{lenstra2015random} extends commit-reveal using the Sloth function (a VDF precursor involving modular square roots in modulo prime) via Unicorn. The Sloth function in Unicorn can be replaced with a VDF, desirably achieving an exponential gap between computation and verification times. We refer to this VDF-based Unicorn as Unicorn++. In Unicorn++ (as well as Unicorn), participants can skip the commit step and send their shares directly. It runs as follows.
\begin{enumerate}
    \item \textbf{Collect entropy.} Every participant $P_i$ broadcasts its share of randomness $r_i$. Once a consensus has been achieved on the shares, they are combined such that  $seed_r = H(r_1,\ldots, r_n)$.
    \item \textbf{Evaluate.} Every participant computes the output of VDF $y_r$ and the corresponding proof $\pi_r$ with a chosen delay parameter $T$ (part of $pp$) as follows:
    $$y_r, \pi_r = \mathsf{VDF.Eval}(pp, seed_r)$$
    The final beacon output is calculated as $\mathcal{O}_r = H(y_r) $, which is then posted and can be efficiently verified using $\pi_r$ through $\mathsf{VDF.Verify}$.
\end{enumerate}
As long as $T$ is longer than the time period during which the values may be submitted including the bounded network delay (for synchronous communication model), even the last participant to submit their $r_i$ cannot bias the final beacon output because by the time a participant computes $\mathsf{VDF.Eval}$, the Share phase would be over and would no longer be able to manipulate their shares. Such a beacon is unbiasable (and unpredictable) by an adversary that controls $n-1$ of the participants because the entropy from even a single honest participant would require an adversary to compute  $\mathsf{VDF.Eval}$. 

\subsection{Extending Public Randomness}
As proposed in \cite{bunz2017proofs, bonneau2015bitcoin}, beacons using stock prices \cite{clark2010use} or PoW blockchains \cite{bonneau2015bitcoin} which are otherwise susceptible to manipulation from insiders (high frequency traders and miners respectively) can be used as the $seed_r$ which is fed into $\mathsf{VDF.Eval}$ to generate beacon output as follows:
$$y_r, \pi_r = \mathsf{VDF.Eval}(pp, seed_r)$$
where $seed_r = H(e_r)$, and $e_r$ denotes the output of a biasable external beacon.

Adding a VDF prevents miners (or any other party) from determining the beacon output (and deciding whether to withhold/manipulate) before $T$, at which point it is already too late to attack as the beacon would have moved on to the next round with another $seed_r$. For PoW blockchains, this results in the miner to lose the block reward as well as any influence on the beacon. A sufficiently long $T$ also increases the attack cost significantly as changing the block at that point would require a deeper fork of the network. 

\subsection{RandRunner}
\label{subsection:randrunner}
In the VDF-based schemes discussed so far require consensus on the inputs to VDF every round and the rate at which random numbers are generated is limited by $T$. RandRunner \cite{schindler2021randrunner} tackles these issues by building a deterministic chain of outputs (no consensus on ordering required) using a VDF design that allows the participant that sets up the VDF to quickly compute it using a secret trapdoor and broadcast the output. Only if the participant fails to do when required do other participants need to evaluate the VDF without the trapdoor. This results in much lower communication overhead and shorter intervals between random outputs when the network is not under attack. Trapdoor VDFs, initially described in \cite{wesolowski2019efficient} can be used to realize this. RandRunner uses \emph{strongly unique trapdoor VDFs}, which ensures that the result obtained via the trapdoor and by evaluation are always equal.
\begin{definition}[Strongly Unique Trapdoor VDF]
A Strongly Unique Trapdoor VDF extends VDF by allowing any participant who knows the trapdoor to efficiently evaluate the VDF without $T$ sequential steps. Moreover, it provides uniqueness even when the public parameters for the VDF are generated by the adversary. This is called strong uniqueness. A Strongly Unique Trapdoor VDF can be described by the algorithms $\mathsf{TVDF = (Setup,VerifySetup, TrapdoorEval, Eval, Verify)}$. It extends the algorithms of a traditional VDF with:
\begin{itemize}
    \item $\mathsf{VerifySetup}(\lambda, pp) \rightarrow (Accept, Reject)$ is used to verify the validity of the public parameters $pp$.
    \item $\mathsf{TrapdoorEval}(pp,x,sk) \rightarrow (y, \pi)$ takes an input $x$  along with trapdoor $sk$ and outputs $y$ and a proof $\pi$ in less than time $T$ unlike $\mathsf{Eval}$.
\end{itemize}
See Appendix \ref{appendix:tvdf} for details.
\end{definition}
Wesolowski’s VDF \cite{wesolowski2019efficient} does not achieve strong uniqueness because knowing the trapdoor allows an adversary to forge ``valid'' proofs for different invalid outputs. As a result, RandRunner uses Pietrzak's VDF \cite{pietrzak2018simple}. RandRunner starts with a one-time Setup and Bootstrapping phase. It is followed by Execution phase which generates random outputs every round. The phases proceed as follows.
\begin{enumerate}
    \item \textbf{Setup and Bootstrapping Phase.} Each participant $P_i$ executes $\mathsf{TVDF.Setup}$ to compute its public parameters $pp_i$ and the corresponding secret trapdoor $sk_i$ and broadcasts $pp_i$, which is verified by other participants using $\mathsf{TVDF.VerifySetup}$. This ensures that the assumptions for uniqueness property of Pietrzak’s VDF \cite{pietrzak2018simple} are fulfilled. At the end, every participant should have the same set of public parameters $\mathcal{P} = \{ pp_1, pp_2, \ldots pp_n \}$. The initial value $\mathcal{O}_0$ used to bootstrap the protocol selects the first round's leader and also serves as input to the first (leader’s) VDF  being evaluated.
    
    \item \textbf{Execution Phase.} Every round $r$ has a unique leader $l_r$ whose duty is to advance the protocol into the next round. $l_r$ can be selected either via round-robin (i.e. taking turns in some permuted order based on $\mathcal{O}_0$) or using randomized sampling (i.e. using $\mathcal{O}_{r-1}$ as seed). The implications of each will be discussed in Section \ref{subsubsection:public-subset-selection}. The execution can proceed in two ways depending on the honesty of the leader.
    \begin{itemize}
        \item \textbf{Honest Leader (Common Case).} The leader advances the protocol into next round by using $sk_{l_r}$ to compute the VDF and broadcasting the result as,
        $$y_r, \pi_r = \mathsf{TVDF.TrapdoorEval}(pp_{l_r}, H_1(y_{r-1}), sk_{l_r})$$
        The other participants checks the correctness of the received values using $\mathsf{TVDF.Verify}$. If verified successfully, the beacon output for the round is computed as 
        $$\mathcal{O}_r = H_2(y_r)$$
        $H_1$ and $H_2$ are cryptographic hash functions to map the beacon output to input space of VDF and vice versa.
        \item \textbf{Dishonest Leader.} To deal with dishonest leaders, every non leader computes and shares the round's VDF output in $T$ sequential steps using $pp_{l_r}$ as
        $$y_r, \pi_r = \mathsf{TVDF.Eval}(pp_{l_r}, H_1(y_{r-1}))$$
    \end{itemize}
\end{enumerate}
When the network is in good shape and the leaders are not malicious, RandRunner generates fresh randomness rapidly with only $O(n)$ communication complexity. Adversarial leaders and network delay ($\Delta$) increases the round duration to $T$ and the communication complexity to $O(n^2)$. Since the output of each round can be computed independently (with delay $T$), RandRunner retains liveness even with dishonest majority and when network connectivity breaks down completely. Assuming an unbiased initial seed, the deterministic nature of RandRunner prevents an adversary from manipulating the beacon outputs. 

However, RandRunner produces pseudorandom numbers (and not uniform random numbers) and trails in terms of the quality of randomness. The leader based nature of RandRunner allows an adversary (if leader) to predict future outputs up to some extent and its advantage increases as long as a continuous sequence of adversarial nodes are selected as leaders. Assuming a $t$-limited adversary with relative computational advantage of $\alpha$ with respect to honest nodes, RandRunner provides $d$-unpredictability where $d = t \cdot \alpha$ if honest nodes make progress faster than adversarial nodes. This is reduced to standard majority assumption $n > 2t$ only when $\alpha = 1$ and $T \gg \Delta$. Otherwise, the fraction of honest nodes compared to adversarial nodes must also increase.
% secure against covert adversary
\section{Commit-Reveal-Punish}
\label{section:commit-reveal-punish}
Representing an entirely different bucket of protocols, commit-reveal-punish schemes assume that all participants are rational, profit-maximizing entities willing to collude or withhold based on incentive. To motivate such a participant into joining the service that realizes a DRB, we assume an intrinsic value associated with it (called the jackpot) derived from the required deposits needed to join such a service. Namely, an escrow is used to collect initial deposits from the participants as part of their commitment, which can be slashed and redistributed if undesired behavior is detected. In this setting, commit-reveal-punish schemes achieve unpredictability and unbiasability either by forcing every participant to reveal \cite{youcai2017randao, andrychowicz2014secure, bentov2014use} or by tolerating some number of withholding participants via threshold secret sharing \cite{david2020economically}. These two approaches are summarized in the following.

\subsection{Enforcing Every Reveal}
RANDAO \cite{youcai2017randao} extends a basic commit-reveal using an escrow realized using a smart contract on Ethereum. It proceeds in three phases---Commit, Reveal, and Aggregate. During Commit phase, in addition to committing to their selected secrets, the participants are also required to send $m$ coins as deposit to the escrow contract. Failure to reveal the secret during Reveal phase by a participant results in the corresponding deposit of $m$ coins being taken away and redistributed among the rest of the participants. Finally, if none of the participants withhold, all the revealed secrets are aggregated and broadcast.

To ensure that honest participants are fully compensated when a participant fails to reveal, protocols like RANDAO require a high initial deposit of $O(n^2)$ coins per participant, where the jackpot and the number of participants are both $O(n)$ \cite{andrychowicz2014secure, bentov2014use}. This makes withholding highly unprofitable, as the $O(n^2)$ initial deposit of the withholder is redistributed among the remaining honest participants each receiving $O(n)$ coins as compensation.

Note that it is possible to optimize in a lottery setting (i.e. where we choose a random winner not a number) such that constant or no deposits are required \cite{bartoletti2017constant, miller2017zero}. The idea is to construct a binary-tree tournament consisting of $n - 1$ two-player lottery instances (which can be realized as per \cite{andrychowicz2014fair, andrychowicz2014secure}) in $O(\log n)$ rounds where a participant automatically loses by not revealing. While this mechanism allows the protocol to tolerate withholding, it is unclear as to how to extend a random winner into a random number for the purpose of a DRB.

\subsection{Rational Threshold Randomness}
Economically Viable Randomness (EVR) \cite{david2020economically}, on the other hand, does provide an alternative requiring constant deposits to output a random number while tolerating withholding to some extent. The escrow used in EVR ensures unpredictability and unbiasability of the protocol in the following ways:
\begin{itemize}
    \item \textbf{Unpredictability.} It introduces a informing mechanism to prevent collusion among participants. If the escrow is notified of collusion, it rewards the informer and slashes the deposits of all other participants (``collective punishment''). This makes informing more profitable than colluding. Realizing this, entities are discouraged to collude, fearing another entity would frame.
    \item \textbf{Unbiasability/Robustness.} Any withholding of shares or failure to reconstruct the final random output is disincentivized by the escrow collectively punishing everybody by slashing all the deposits.
\end{itemize}

Collective punishment is inevitable in EVR when informing happens as it is impossible to detect who colluded. Even though collective punishment is not necessary when participants fail to recover the final output, EVR enforces it to allow reconstruction to be done off-chain, without the involvement of escrow. 

EVR uses Escrow-DKG \cite{david2019rational}, which is an extension of Distributed Key Generation (DKG) protocol \cite{gennaro1999secure, gennaro3revisiting}. DKG allows a set of $n$ participants to collectively generate a pair of private and public keys, $(x,X = g^x )$, in such a way that $X$ is publicly known while $x$ is shared by $n$ servers via a verifiable $(t, n)$-secret sharing scheme.
\begin{definition}[$(t, n)$-secret sharing]
A $(t, n)$-secret sharing scheme \cite{shamir1979share, blakley1979safeguarding} allows a dealer to share a secret $s = p(0)$ for some $p \in \mathbb{Z}_q[X]$ among a set of $n$ participants each holding $p(i)$ for $i = 1, ..., n$ in such a way that in the reconstruction phase any subset of $t+1$ or more honest participants can compute the secret $s$ via \textit{Lagrange interpolation} (Appendix \ref{appendix:lagrange}), but subsets of size $t$ or fewer cannot.
\end{definition}
\begin{definition}[Verifiable Secret Sharing]
Verifiable Secret Sharing (VSS) \cite{feldman1987practical, pedersen1991non} protects a $(t, n)$-secret sharing scheme against a malicious dealer providing incorrect shares by allowing every participant to verify the share they've received from the dealer is a valid piece of the secret without revealing the secret. VSS can be described by the following algorithms.
\begin{itemize}
    \item $\mathsf{Setup}(\lambda) \rightarrow pp$ generates the public parameters $pp$ and is an implicit input to all other algorithms.
    \item $\mathsf{ShareGen}(s) \rightarrow (\{s_i\}, C)$ is executed by the dealer with secret $s$ to generate secret shares $\{s_i\}$ (each of which is sent to node $i$ correspondingly) as well as commitment $C$ to the secret sharing polynomial of degree $t$.
    \item $\mathsf{ShareVerify}(s_i, C) \rightarrow \{0, 1\}$ verifies the correctness of the share $s_i$ using $C$.
    \item $\mathsf{Recon}(A, \{s_i\}_{i \in A}) \rightarrow s$ reconstructs the shared secret $s$ via Lagrange interpolation from a set $A$ of $t + 1$ valid shares.
\end{itemize}
Feldman-VSS and Pedersen-VSS are two of the most popular VSS protocols. See Appendix \ref{appendix:vss} for details.
\end{definition}
\begin{definition}[Distributed Key Generation]
A Distributed Key Generation (DKG) \cite{gennaro1999secure, gennaro3revisiting} protocol allows $n$ participants to collectively generate a group public key, the individual secret keys, and the corresponding public keys without the help of a trusted third party. It does so by running multiple instances of VSS, with each participant acting as a dealer for its corresponding share of secret. However, unlike secret sharing schemes, DKG shares can be used repeatedly for an unlimited number of time without ever recovering the group secret explicitly. A DKG is described by the following algorithm.
\begin{itemize}
    \item $\mathsf{DKG}(1^{\lambda}, t, n) \rightarrow (\vec{SK}, \vec{PK}, pk)$ is a distributed key generation algorithm that takes a input security parameter $1^\lambda$, the number of participants $n$ and the threshold parameter $t$ and outputs a group public key $pk$, the individual secret keys $\vec{SK} = \{sk_1, sk_1, \ldots, sk_n\}$, and the corresponding public keys $\vec{PK} = \{pk_1, pk_2, \ldots, pk_n\}$
\end{itemize}
Joint-Feldman and Joint-Pedersen are two of the most popular DKG protocols. See Appendix \ref{appendix:dkg} for details.
\end{definition}

\begin{definition}[Escrow-DKG]
Escrow-DKG \cite{david2019rational} is a rational variant of DKG with the following variations.
\begin{itemize}
    \item Unlike traditional DKG, Escrow-DKG does not a priori assume a $t$-limited adversary. However, it assumes the participants are rational in a setting where collusion of more than $t$ nodes would be financially punished such that, effectively, we have a $t$-limited adversary.
    \item It assumes a trusted escrow service $\mathcal{G}$ that substitutes and enhances the broadcast channel usually assumed in traditional protocols.
    \item Escrow-DKG considers how a DKG may fail and associates a financial penalty to each failure case.
\end{itemize}
\end{definition}

While Escrow-DKG is usually used to generate keys for secret sharing, EVR adapts it to realize a DRB (see Appendix \ref{appendix:edkg} for details). With $\mathcal{G}$ implemented using a smart contract, EVR proceeds in five phases---Register, Setup, Commit, Inform, and Reveal.
\begin{enumerate}
    \item \textbf{Register.} Every participant registers themselves with $\mathcal{G}$ by depositing 1 coin per secret share.
    \item \textbf{Setup.}  Based on the number of coins collected, $\mathcal{G}$ sets the total count of participants registered $n$ and threshold parameter $t = \frac{2n}{3}$ required for DKG. It also sets a bound on the illicit profit that EVR can sustain $P= n-t = \frac{n}{3}$ and the informing reward $\ell = n$.
    \item \textbf{Commit.} Each registered participant execute $\mathsf{VSS.ShareGen}$ to share their secrets. Detection of any misbehavior during Commit results in $\mathcal{G}$ aborting the protocol and returning the deposits.
     \item \textbf{Inform.} If Commit completes successfully, it enters the Inform phase where any participant who knows the group secret $x$ by colluding can inform $\mathcal{G}$ and get high informing reward ($\ell$) for it. The reward comes from the participants’ deposits, which are all confiscated in this case. Otherwise, it enters into the Reveal phase.
    \item \textbf{Reveal.} The participants distribute their shares and reconstruct $x$ off-chain. The consistency of reconstructed secret with the published shares is verified by $\mathcal{G}$. Participants get their deposits back if successfully verified. In case the participants fail to reconstruct and publish $x$ in a timely manner, $\mathcal{G}$ confiscates the deposits of all the participants.
\end{enumerate}
With $n$ total coins deposited during Register, EVR assumes that no participant owns more than $n/3$ of the coins, either deposited to escrow or externally and sets a bound on the maximum illicit profit that EVR can sustain (denoted by $P$). With these limits in place, EVR makes any malicious behavior unprofitable. 

Since nothing can be gained from failing Commit, the malicious behavior of participants is limited to withholding shares to abort the protocol during Reveal or colluding to learn the secret before Reveal. Setting $P$ to $n-t$ makes withholding unprofitable to $n-t$ or more participants that can collectively withhold to abort the protocol as any profit they would make would not be greater than what they would lose by $\mathcal{G}$ slashing all the deposits. Setting the informing reward $\ell$ to $n$ makes informing more profitable than any illicit profit. However, the collective punishment as a consequence of informing prevents participants from colluding fearing another would inform. The high informing reward and limited coins owned by participants also makes coalitions enforced via external contracts unprofitable.

\section{Commit-Reveal-Recover Variants}
\label{section:commit-reveal-recover}
Instead of using an escrow to enforce desired behavior, commit-reveal-recover variants extend commit-reveal and defend against the last revealer attack by providing a mechanism to recover or reconstruct the secret in case some participants refuse to reveal. This is achieved by using techniques based on threshold secret sharing or threshold encryption. These protocols assume $t$-limited adversary and require the cooperation of at least $t + 1$ nodes to reconstruct the secret such that two desirable properties are achieved simultaneously: there is no need for all $n$ nodes to reveal while $t$ Byzantine nodes cannot collude to preemptively reconstruct the secret to their benefit. Guaranteeing availability as a result, the protocols allow the honest participants to reconstruct the secret by themselves even if all the corrupted participants decide to withhold.

\subsection{Threshold Secret Sharing based}
Threshold Secret Sharing based schemes are based on $(t, n)$-secret sharing. To allow not only the participants but any external party to verify the correctness of the sharing and reconstruction, most threshold secret sharing schemes use Publicly Verifiable Secret Sharing (PVSS)  \cite{schoenmakers1999simple, cascudo2017scrape} instead of VSS as a subprotocol. Scrape \cite{cascudo2017scrape}, Albatross \cite{cascudo2020albatross}, and SecRand \cite{guo2020secRand} use PVSS whereas RandShare \cite{syta2017scalable} uses VSS (although it could be adapted to use PVSS as well).
\begin{definition}[Publicly Verifiable Secret Sharing]
A Publicly Verifiable Secret Sharing (PVSS) scheme extends VSS by allowing any external party, along with each participant themselves, to verify the correctness of sharing and reconstruction of a secret via zero knowledge proofs posted by the dealer and the reconstructing participants respectively.\\
A PVSS scheme can be realized by the algorithms $\mathsf{PVSS = (Setup, KeyGen, Enc, Dec, ShareGen, ShareVerify,}$  $\mathsf{Recon)}$.
To provide public verifiability, PVSS extends VSS by using keys generated by $\mathsf{PVSS.KeyGen}$ for encryption and decryption of shares using the algorithms $\mathsf{PVSS.Enc}$ and $\mathsf{PVSS.Dec}$ respectively. Unlike VSS, $\mathsf{PVSS.ShareGen}$ generates encrypted shares along with auxiliary proofs needed to verify correctness of sharing. $\mathsf{PVSS.ShareVerify}$ verifies the overall correctness (including the consistency of encrypted and decrypted shares) using these proofs. $\mathsf{PVSS.Recon}$ recovers the shared secret. See Appendix \ref{appendix:pvss} for further details.
\end{definition}
Commit-reveal-recover variants based on threshold secret sharing starts with $n$ participants distributing  PVSS/VSS shares of a randomly chosen secret to all the other participants resulting in every participant ending up with a share of each of the $n$ secrets. In an ideal scenario, all the participants reveal their committed secrets, which are aggregated to compute the final randomness for the round, without ever needing to use the shares. However, to deal with withholding participants, protocols either proactively or reactively use the shares to reconstruct the final secret. The reconstruction is done using Lagrange interpolation, which recovers the unique secret given any subset of $t+1$ valid shares of it with $O(t^2)$ computations. Based on this, we can further divide the schemes into the following subcategories.

\subsubsection{Commit-Reveal-Recover}
It extends the  commit-reveal by an additional recovery phase for force-opening and reconstructing only those secrets that were withheld during the reveal phase. Given that, optimistically, no force-open will be required. However, recovering withheld shares during force-opens requires  further data sharing between the participants, expanding the duration of each round. Scrape adopts this technique by having every dealer publish a commitment to the secret, which is opened in the Reveal phase, in addition to the encrypted shares and the verification information needed for PVSS scheme.\\\\
\textbf{Scrape}\\
\joenote{is this a one-round protocol? General note-need a framework for one round vs. two round protocols?}
The main building block of Scrape is its PVSS scheme (see Appendix \ref{appendix:scrapePVSS} for details). The initial setup for Scrape requires generating public keys $pk_i$ for each of the $n$ participants using $\mathsf{PVSS.KeyGen}$. The protocol then proceeds as follows.
\begin{enumerate}
\item \textbf{Commit.} Every participant $P_j$ executes $\mathsf{PVSS.ShareGen}(s^{(j)})$ as dealer D and publishes the encrypted shares $\mathsf{Enc}(pk_i, s^{(j)}_i)$ for $1 \le i \le n$ and verification information $\pi_D^{(j)}$, also learning the random secret $h^{s^{(j)}}$. $P_j$ also publishes a commitment to the secret exponent $\mathsf{Com}(s^{(j)}, r_j)$ (with fresh randomness $r_j$).
\item \textbf{Verify.} For every set of published encrypted shares and the verification information, all participants run $\mathsf{PVSS.ShareVerify}$ corresponding to verification of correct encryption. Let $\mathcal{C}$ be the set of all participants who published commitments and valid shares.
\item \textbf{Reveal.} Once $t+1$ participants have distributed their commitments and valid shares, every participant $P_j$, $j \in \mathcal{C}$ opens its commitment, and shares $\mathsf{Open}(s^{(j)}, r_j)$.
\item \textbf{Recover.} For every participant $P_a \in \mathcal{C}$ that does not publish $\mathsf{Open}(s^{(a)}, r_a)$ in Reveal phase, other participants $P_j$ for $1 \leq j \leq n$ reconstructs $h^{s^{(a)}}$ by running $\mathsf{PVSS.Recon}$, which requires each participant to publish their decrypted shares $s_j^{(a)}$ and the corresponding proof of correct decryption $\pi_j^{(a)}$ that pass $\mathsf{PVSS.ShareVerify}$.

\item \textbf{Aggregate.} The final randomness is $\mathcal{O}_r = \prod_{j \in \mathcal{C}} h^{s^{(j)}}$.
\end{enumerate}
Note that what a participant $j$ can decrypt during the Recover phase is not really the share $s^{(j)}$, but rather $h^{s^{(j)}}$ . However these values are enough to reconstruct $h^s$ which acts as a uniformly random choice in the group by the participant who chose $s$. \\\\
\textbf{Albatross}\\
Albatross extends Scrape and provides an improved amortized communication complexity of $O(n)$ per beacon output by generating a batch of $O(n^2)$ beacon outputs at the end of each round (as opposed to Scrape's one). This is achieved by usage of two techniques: packed Shamir secret sharing and linear $t$-resilient functions, each of which contributes a multiplicative factor of $O(n)$ to the number of beacon outputs produced per round. See Appendix \ref{appendix:albatross} for details.

\subsubsection{Share-Reconstruct-Aggregate}
The other alternative is to skip the reveal phase altogether and proactively reconstruct each secret from the shares distributed during the sharing phase. Reconstructing each secret would require the cooperation of $t+1$ participants to gather the shares, after which Lagrange interpolation can be used to reconstruct the polynomial and recover the secret. However, this increases the communication complexity, as $n (t + 1)$ shares need to be broadcast due to $n$ Lagrange interpolations every round, irrespective of adversarial corruption. RandShare \cite{syta2017scalable} uses this technique.\\\\
\textbf{RandShare}\\
RandShare uses VSS as a subprotocol, extended by adopting the concept of barrier, a specific point in the protocol execution after which the output is fixed and guaranteed to complete successfully. In RandShare, the barrier is reached when the first honest node reveals his shares.
RandShare proceeds as follows.

\begin{enumerate}
    \item \textbf{Share Distribution.} Each participant $P_j$ executes the distribution phase $\mathsf{VSS.ShareGen}(s^{(j)})$ as the dealer, publishing the polynomial commitments and securely sending the shares $s_i^{(j)}$ to all other participants $P_i$, $1\le i\le n$.
    \item \textbf{Share Verification and Consensus.} To ensure that all honest participants have a consistent view of the secrets that will be recovered after the barrier or if the protocol run has already failed , a Byzantine agreement protocol is run in combination with $\mathsf{VSS.ShareVerify}$. This ensures that at least $t+1$ honest participants have verified the secret and will be able to recover it. Let $\mathcal{C}$ be the set of secrets that have been agreed upon by the participants.
    \item \textbf{Share Reconstruction.} If $\lvert \mathcal{C} \rvert \ge t+1$, each of these secrets $s^{(j)}$ where $j \in \mathcal{C}$ is recovered by collecting at least $t+1$ shares of the secret and reconstructing it using $\mathsf{VSS.Recon}$. Otherwise, the protocol fails.
    \item \textbf{Aggregation.} Final randomness is $\mathcal{O}_r = \sum_{j \in C}s^{(j)}$.
    
\end{enumerate}

\subsubsection{Share-Aggregate-Reconstruct}
Instead of Scrape's process of revealing, reconstructing, and adding up all the secrets, or RandShare's process of reconstructing each secret and adding them up, SecRand directly computes the final output through a single Lagrange interpolation of aggregated decrypted shares from $t + 1$ participants. This provides SecRand with a higher and more stable performance than Scrape and RandShare against an adversary's malicious behavior of withholding its secret and also reduces the communication complexity as only $t + 1$ aggregated decrypted shares are exchanged to compute the final random output.\\\\
\textbf{SecRand}\\
SecRand uses Scrape PVSS (see Appendix \ref{appendix:scrapePVSS} for details) as a subprotocol. After intial setup using $\mathsf{PVSS.KeyGen}$, SecRand proceeds in four phases---Share Distribution, Share Verification, Aggregation, and Reconstruction. The Share Distribution and Share Verification phases proceed in a similar way as Commit and Verify phases of Scrape. However, since SecRand does not have a Reveal phase like Scrape, the participants are not required to publish commitments to their secret $\mathsf{Com}(s, r)$ during Share Distribution phase. The other two phases proceed as follows.
\begin{enumerate}
    \setcounter{enumi}{2}
    \item \textbf{Aggregation.} After the Share Distribution and Share Verification phases, every participant $P_i$ would have a valid encrypted share of each of the $n$ secrets, $\mathsf{Enc}(pk_i, s_i^{(j)})$ for $1 \le j \le n$. $P_i$ decrypts these shares to recover $\tilde{s}_i^{(j)}$ (need not be $s_i^{(j)}$) and calculates its group secret share as follows: 
    $$ gs_i = \prod_{j=1}^{n}\tilde{s}_i^{(j)} $$
    $P_i$ then broadcasts its group secret share $gs_i$ along with a proof of correct decryption $\pi_i$.
    \item \textbf{Reconstruction.} Every participant verifies the correctness of decryption using $\mathsf{PVSS.ShareVerify}$. Once $t+1$ valid group secret shares are distributed, the complete group secret $gs$ is reconstructed through $\mathsf{PVSS.Recon}$. The final random output is $\mathcal{O}_r = H(gs)$.
\end{enumerate}

\subsection{Threshold Encryption based}
Threshold secret sharing schemes comes at a high communication cost ($O(n^4)$ when $t$ secrets needs to be reconstructed) and requires each participant to share $O(n)$ data every round. A threshold encryption scheme brings down the reconstruction cost and the data to be shared each round by establishing a global public key to encrypt the shared secret.
\begin{definition}[$(t, n)$-threshold encryption] 
A $(t, n)$-threshold encryption scheme allows to encrypt a message towards a group of $n$ participants such that the message can be decrypted by any $t+1$ of them, but not less. The global public key $pk$ generated by a DKG protocol is used by any sender to encrypt the message. The individual public keys $pk_i$ and the corresponding secret keys $sk_i$ will later enable any set of $t + 1$ participants to non-interactively decrypt ciphertexts computed under $pk$. A $(t, n)$-threshold encryption scheme is composed of the following algorithms:
\begin{itemize}
    \item $\mathsf{DKG}(1^\lambda, t, n) \rightarrow (\vec{SK}, \vec{PK}, pk)$ runs a typical DKG with threshold $t$.
    \item $\mathsf{Enc}(pk, m) \rightarrow C$ encrypts the message $m$ with global public key $pk$ and outputs the ciphertext $C$.
    \item $\mathsf{ShareDec}(pk, sk_i, pk_i, C) \rightarrow \mu_i$ generates the decryption share $\mu_i$ for ciphertext $C$ using the individual keys $(sk_i, pk_i)$ and $pk$.
    \item $\mathsf{Rec}(pk, \vec{PK}, C, \vec{\mu} )\rightarrow \{m, Reject\}$ is a recovery algorithm that takes $pk$, a ciphertext $C$ and a subset of $t+1$ valid decryption shares $\vec{\mu} = \{\mu_1, \mu_2,\ldots, \mu_{t+1}\}$ together with the public keys $\vec{PK} = \{pk_1, pk_2,\ldots, pk_{t+1}\}$ and outputs the message $m$ or $Reject$.
\end{itemize}
See Appendix \ref{appendix:thresholdEnc} for more details.
\end{definition}
HERB \cite{cherniaeva2019homomorphic} uses threshold ElGamal encryption \cite{desmedt1990Threshold}, though it can be replaced with any other threshold homomorphic encryption scheme. See Appendix \ref{appendix:thrElGamal} for details on threshold ElGamal Encryption.\\\\
\textbf{HERB}\\
In HERB, each participant can play two roles: entropy providers and key holders. Entropy providers are active only for ciphertext generation whereas key holders participate in all protocol stages. After the initial Setup where all key holders together run $\mathsf{ThrEnc.DKG}(1^\lambda, t, n)$ to generate keys for threshold encryption, the protocol proceeds as follows.
\begin{enumerate}
    \item \textbf{Publication.} Each entropy provider $e_j$ generates a random share $M_j$ and encrypts it using $\mathsf{ThrEnc.Enc}$ to generate the ciphertext share $C_j$, which is published along with a proof of correct encryption $\pi_{CE_{j}}$ needed to ensure non-malleability of encrypted shares. The shares are then verified and agreed upon by the participants. Let $QUAL$ denote a set of valid $C_j$'s. When enough $C_j$'s are published (based on system parameters), they are homomorphically combined into a common ciphertext $C$ corresponding to the plaintext $M$.
    
    \item \textbf{Disclosure.} The key holders $k_i$ use $\mathsf{ThrEnc.ShareDec}$ to generate their decryption share $D_i$ and publish it along with a proof of correct decryption $\pi_{DLEQ_{i}}$, which is then verified by other participants. When $t+1$ decryption shares are published and verified, participants use $\mathsf{ThrEnc.Rec}$ to reconstruct the final random number $M$ for the round.
\end{enumerate}
HERB achieves a communication complexity of $O(n^3)$ with only constant amount of data shared each round by the key holders. The communication complexity can be further optimized to $O(n^2)$ by using Avalanche \cite{rocket2018snowflake} to achieve consensus on $QUAL$, leading to an overall better performance than threshold secret sharing schemes. However, the dependence of HERB on DKG leads to high setup cost, as every new key holder would require a rerun of DKG to establish the keys. When compared to threshold VRF based schemes (Section \ref{section:dvrf}) which also uses DKG for setup, HERB trails in terms of communication complexity as it collects fresh entropy each round. This however results in HERB producing uniform random numbers (vs pseudorandom numbers). Also, HERB allows the entropy providers to be independent of key holders making it possible to collect entropy from a large and flexible set of sources while allowing the key holders set to be much smaller and sampled to contain at most $t$ malicious nodes.

\section{Subset-Based Protocols}
\label{section:subset-based}
While all aforementioned commit-reveal variants (i.e. from Sections \ref{subsection:extending-commit-reveal}, \ref{section:commit-reveal-punish}, and \ref{section:commit-reveal-recover}) include every node as an entropy provider such that all participants must comprise each entropy-providing subset in round $r$, the issue with this approach is one of scalability. In other words, requiring communication of marginal entropy by all nodes is unsurprisingly not the most efficient, and hence a natural optimization is to reduce the size of each entropy-providing subset.

In this section, we consider DRB protocols that are \textit{subset-based}, where a subset (for the purpose of this paper) refers to a non-empty proper subset. Subset-based protocols proceed in two steps: \textit{subset selection} and \textit{beacon output generation}. As the names suggest, the per-round entropy-providing subset is agreed upon during subset selection while the beacon output $\mathcal{O}_r$ is generated and agreed upon during beacon output generation. A summary of subclassification of each of these steps is provided below before we examine 11 preexisting protocols and provide intuition (refer to corresponding citations for full details) on interpreting them under our simple framework.

The key insight is that subset selection and beacon output generation are indeed modular in theory such that (cryptographic) tools used in the first step can be independent of those used in the second step. It is in this way that these two steps can be seen as two ``dimensions'' explaining any subset-based DRB in the landscape. Refer to Table \ref{table:subset-based} to interpret the protocols broached in this section accordingly in a nutshell.

\subsection{Step 1. Subset Selection}
The first step of a subset-based DRB protocol involves selecting an entropy-providing subset of participating nodes every round in a way that is agreeable by all nodes. We classify subset selection mechanisms in the landscape into two: public and private.

\subsubsection{Public Subset Selection}
\label{subsubsection:public-subset-selection}
In a public subset selection, only public information is needed to derive an agreeable subset that provides entropy every round.\\

\noindent\textbf{Round-Robin (RR).} A first example is \textit{round-robin} (RR), in which nodes simply take turns being selected such that there is no notion of hierarchy among nodes. While RR can work with subsets of any size in theory as long as the exact mechanism is clearly defined by the protocol in advance, it is canonical that RR usually refers to the selection of subset of size one (i.e. a leader) corresponding to node $i \equiv r \pmod n$ given round $r$ and $n$ number of nodes. Hence, protocols like BRandPiper \cite{bhat2020randpiper} (in which the round leader is the only active entropy provider) adopt RR as their leader selection mechanism. In the case of BRandPiper, it is in fact imperative that the leader is selected via RR due to its innate fairness property \cite{azouvi2018winning} (also known as chain quality \cite{garay2015bitcoin} in the blockchain context) where all nodes, by RR's definition, take equal leadership across any $n$ rounds.\\

\noindent\textbf{Random Selection (RS).} A second example is \textit{random selection} (RS), which uses a public source of randomness (e.g. most commonly the previous round's beacon value) to derive the entropy-providing subset. While RR is a simple deterministic algorithm, RS is a randomized one and thus allows for more protocol-level variations, some of which are exemplified in the following examples.
\begin{itemize}
\item HydRand \cite{schindler2020hydrand} and GRandPiper \cite{bhat2020randpiper}. Given the previous beacon value $\mathcal{O}_{r - 1}$, the subset (of size one, i.e. the leader) for round $r$ corresponds to node $i \equiv \mathcal{O}_{r - 1} \pmod{\tilde{n}}$ where $\tilde{n}$ denotes the number of nodes eligible for leadership.
\item Ouroboros \cite{kiayias2017ouroboros}. The follow-the-satoshi algorithm \cite{bentov2014proof,kiayias2017ouroboros}\joenote{I would omit this from the paper or reduce to one sentence. It's just another variant of random selection, the satoshi details don't matter} outputs the next slot leaders of an epoch (i.e. predefined collection of consecutive slots) given the previous beacon value as input by tracking the owners of specific ``satoshis'' or units of currency in order to derive a subset for the subsequent round. Note that we regard Ouroboros' epoch as one round in the context of DRB although Ouroboros' concept of a slot corresponds to a round in the blockchain context.
\end{itemize}

That RS is randomized incurs a side effect where some nodes may, in theory, never be selected and therefore may never be able to contribute their entropy to the beacon output even if actively participating in the protocol. A more realistic concern is that an adversary can attempt to bias, via grinding attack, the beacon output in order to bias the next entropy-providing subset to its benefit (which may in turn help the adversary bias the next beacon output again and so on). This is a notable tradeoff given RS, and thus protocols adopting RS need to take this facet into consideration.

On the other hand, this is not an issue in RR, as its subset selection is naturally deterministic in a way that is independent of the preceding beacon output. Nonetheless, a tradeoff of RR is that DoS attack becomes a possibility since each subset is known in advance for every round publicly. To be noted is this interplay where we either, when choosing between RR and RS, gain unbiasability (due to determinism) at the cost of DoS attack or gain DoS attack defense (due to randomization) at the cost of grinding attack.\\\todo{this section should talk about adaptive corruption}

\noindent\textbf{Leader-Based Selection (LS).} A third example, \textit{leader-based selection} (LS) is a hybrid method that in fact exhibits both determinism and randomization. It runs in two steps: the first step involves electing a leader (either by RR or RS) while the second step involves a manual selection\joenote{why manual?} of the entropy-providing subset by the leader from the first step. It is precisely in this way that the mechanism is deterministic from the leader's perspective while randomized from the perspective of others.

One requirement, due to the power delegated to the per-round leader, is that the size of the chosen subset needs to be greater than $t$ (assuming a network with at most $t$ Byzantine nodes) so that a malicious leader wouldn't be able to game the system by choosing a malicious subset. Some examples of LS include the following.
\begin{itemize}
\item RandHound \cite{syta2017scalable}. As instantiated in RandHerd \cite{syta2017scalable}, RandHound's leader election (i.e. the first step of LS) involves a lottery where each node generates a lottery ticket $t_i = H(C \mathbin\Vert pk_i)$ given a public configuration parameter $C$ (assuming its randomness) such that the owner of $min(t_i)$ becomes the leader (originally called client). Note that this lottery is a public one such that it only involves public parameters $C$ and $pk_i$, in which case anyone can derive the leader without any private input. Essentially, this first step of LS is an instance of RS. While the second step of LS for RandHound involves a manual subset selection by the leader as expected, one protocol-level caveat is that RandHound adopts a form of sharding (involving PVSS groups) such that the leader is required to select more than a threshold number of nodes in each shard (PVSS group), which in turn guarantees more than a threshold number of chosen entropy providers across all shards.
\item SPURT \cite{das2021spurt}. Unlike RandHound, SPURT adopts RR as its first part of LS such that nodes simply take turns being a round leader. Then the round leader chooses the subset of entropy providers manually.
\end{itemize}

The motivation for LS (as opposed to RR or RS) is clear\joenote{It's not clear ot me, you need to spell out what the advantage is} only if the underlying DRB protocol is already a leader-based one utilizing the concept of a leader as a facilitator of communication among nodes in order to lower the overall communication complexity. Otherwise, it naturally suffers from the same attacks impacting RR and RS (i.e. DoS attack and grinding attack, respectively) during the leader election step of LS while also potentially suffering from liveness issues related to leader failure (non-Byzantine or Byzantine). Hence, LS is generally less commonly used in practice.\joenote{Practice? are any of these used in practice?}

\subsubsection{Private Subset Selection}
\label{subsubsection:private-subset-selection}
In a private subset selection, also known as private lottery, each node needs to input some private information (e.g. secret key) in order to check whether or not it has been selected into the entropy-providing subset (i.e. has won the lottery). The general formulation of a private lottery can be given by
\[
f_{priv}(\cdot) < target
\]
where $f_{priv}(\cdot)$ is a lottery function (i.e. pseudorandom function) that takes some private input $priv$ and $target$ is indicative of the lottery's ``difficulty level'' (a la Proof of Work difficulty) such that a protocol can tinker with $target$ to make the lottery arbitrarily easy or hard to win. The idea is that each node calculates $f_{priv}(\cdot)$ as per its private input and checks if the above inequality is satisfied, in which case it is considered to have won the lottery and becomes an entropy provider.

As it may be possible for an adversary to perform a grinding attack by brute-forcing many values of $priv$ until a desirable function output is achieved (i.e. desirable both in terms of satisfying the lottery inequality and also the actual beacon output generation step that follows the lottery step, to be discussed later, given $priv_1$ and $priv_2$ that both satisfy the lottery), one crucial requirement is that the private input should be provably committed in the past and thus be ungrindable at the time of computation of the lottery function. Two examples of the above private lottery formulation exist in the landscape: a VRF-based lottery and Caucus' \cite{azouvi2018winning} lottery involving a hash chain.\\

\noindent\textbf{VRF-based approach.} In Algorand \cite{gilad2017algorand} (as well as Ouroboros Praos \cite{david2018ouroboros} and NV denoting a protocol by Nguyen-Van et al. \cite{nguyen2019scalable}), a VRF (see Appendix \ref{appendix:vrf}) is used each round to process a lottery. (While there exist more than one version of Algorand's private lottery algorithm, we consider its first version, as the versions don't differ fundamentally.) Quite naturally, one's private input to $VRF_{sk}(\cdot)$ is its secret key such that the lottery is given by
\[
VRF_{sk}(\mathcal{O}_{r - 1} \mathbin\Vert role) < target
\]
where $role$ is some parameter specific to Algorand. As both $\mathcal{O}_{r - 1}$ and $role$ are already public and ungrindable at the time of computation, Algorand makes sure $sk$ is likewise ungrindable by requiring that $sk$ is in fact the node's secret key from some threshold number of rounds ago. While the size of the entropy-providing subset is expected to be one in Algorand (such that there is 1 expected winner per lottery and 1 lottery per round), that in Ouroboros Praos is expected to be $K$ where each epoch consists of $K$ consecutive slots (such that there is 1 expected winner per lottery but $K$ per-slot lotteries per round, which is an epoch), as the protocol provides an epoch-based variant of Algorand. Fundamentally the same as that of Algorand, the per-slot lottery of Ouroboros Praos is given by
\[
VRF_{sk}(\mathcal{O}_{r - 1} \mathbin\Vert slot \mathbin\Vert \mathsf{TEST}) < target
\]
where $slot$ denotes the slot number and $\mathsf{TEST}$ is a string such that there would be $K$ expected entropy providers (each corresponding to a slot) in a round.\\\joenote{this is so similar, I would merge the two into one desciption}

\noindent\textbf{Replacing VRF with $H(\cdot)$ and hash chain.} In Caucus, a VRF is replaced by a hash function combined with a hash chain, i.e. a list ($h_1, ..., h_m$) with $h_r = H(h_{r + 1})$ for all $r = 1, ..., m - 1$ where $h_m = s$ for some random seed. Effectively, a hash chain provides the functionality of provable commitment to some private input as one can publicize one $h_r$ at a time (i.e. $h_r$ in round $r$) such that doing so is equivalent to committing to $h_{r + 1}$ (and $h_{r + 1}$ would be publicized later to commit to $h_{r + 2}$ and so on). Consequently, each participant of Caucus independently generates a private hash chain comprising its $m$ private inputs such that the lottery is given by
\[
H(h_r \oplus \mathcal{O}_{r - 1}) < target
\]
which simply involves a hash function. One downside is that the hash chain needs to be periodically regenerated, as $m$ is finite while we desire our DRB to be prolonged indefinitely.

\subsection{Step 2. Beacon Output Generation}
\label{subsection:beacon-output-generation}
Once given a subset of entropy providers, the issue then shifts to one dealing with the actual beacon output generation. While a typical commit-reveal-recover run among the subset of entropy providers may be sufficient to realize a DRB, there can be other variations coupled with different tradeoffs as well. Largely, we classify these variations into two: one that requires \textit{fresh} (independently generated on the spot) per-node entropy and one that combines previous randomness (i.e. beacon output) with \textit{precommitted} (independently generated but precommitted, hence ungrindable) per-node entropy.

\subsubsection{Fresh Per-Node Entropy}
\label{subsubsection:fresh}
The beacon output generation process involving fresh (also referred to as true randomness \cite{cascudomt, das2021spurt} as opposed to pseudorandomness) per-node entropy for subset-based protocols is essentially a commit-reveal-recover variant. Some protocols in this bucket and their implementation details are portrayed in the following examples.
\begin{itemize}
\item Ouroboros and RandHound. As each slot leader is a participant in the entropy-providing subset, all slot leaders of an epoch in Ouroboros perform a RandShare-style share-reconstruct-aggregate using PVSS. Similar is the chosen subset in RandHound while facilitated by a round leader.
\item SPURT and BRandPiper. The entropy providers of SPURT and BRandPiper, on the other hand, perform a SecRand-style share-aggregate-reconstruct. BRandPiper's beacon output generation process is quite idiosyncratic, however. While there exists one entropy provider per round, it allows $n$ secrets (one from each node) to be combined each round such that it provides the ideal 1-unpredictability property as opposed to $t$-unpredictability (as in HydRand or GRandPiper). The trick is that every time a node becomes the round leader, it generates $n$ fresh secrets that are to be combined with others' secrets in the next $n$ rounds, respectively, and it distributes them to other participants via PVSS in advance. Effectively, each beacon output is a result of share-aggregate-reconstruct.
\item NV++. Similar to HERB, the entropy providers of NV \cite{nguyen2019scalable} contribute their fresh entropy using ElGamal although they use its classical, non-threshold version due to the protocol's centralized Requester model in which a third party called Requester is the direct recipient of a beacon output. As a result, each entropy provider generates and encrypts its entropy and sends it to the Requester, which then decrypts all the messages received from entropy providers and outputs their sum as $\mathcal{O}_r$. Naturally, this Requester version of NV can be modified into what we call NV++, which differs in two ways. First, the entropy providers (once finalized) can be made to essentially perform HERB among themselves. This eliminates the existence of the Requester and its centralized nature. Second, entropy provision (i.e. actually broadcasting one's entropy) is coupled with revelation of membership to the entropy-providing subset (i.e. broadcasting the fact that a node has won the VRF private lottery). In the original NV, these two are separate steps potentially incurring adaptive insecurity (a concept of which is delineated in Section \ref{subsection:adaptive}). As a result, NV++ distributes the Requester and achieves adaptive security.
\end{itemize}

\subsubsection{Combining Previous Output and Precommitted Per-Node Entropy}
\label{subsubsection:precommitted}
There is room to optimize and lower a protocol's communication complexity if it's not a requirement that entropy providers need to generate fresh per-node entropy every single round. The canonical optimization involves utilizing $\mathcal{O}_{r - 1}$ as a source of entropy to produce $\mathcal{O}_{r}$. Nonetheless, the caveat in doing so is that grinding attack may become a possibility once $\mathcal{O}_{r - 1}$ becomes public, which is why we need to require per-node entropy to be precommitted before combining it with $\mathcal{O}_{r - 1}$ to output $\mathcal{O}_r$. Preventing grindability while taking advantage of the convenience of $\mathcal{O}_{r - 1}$, such requirement can be observed in many subset-based protocols in the landscape and is indeed a commonality among them even if their implementation details may seem unrelated on the surface. We provide some examples as follows.
\begin{itemize}
\item HydRand and GRandPiper. Each round, an entropy provider (which is the round leader for both HydRand and GRandPiper) commits its entropy that becomes opened in the next round the same node is selected as the leader again. In other words, the round leader's precommitted entropy $e_{\tilde{r}}$ from the last round $\tilde{r}$ it was a leader is the one that becomes combined with $\mathcal{O}_{r - 1}$ in the form of $h^{e_{\tilde{r}}}$ (due to details related to PVSS recovery) to generate
\[
\mathcal{O}_r = H(\mathcal{O}_{r - 1} \mathbin\Vert h^{e_{\tilde{r}}})
\]
where $h$ is a generator of $\mathbb{G}_q$ of prime order $q$. While GRandPiper's beacon output is technically
\[
\mathcal{O}_r = H(h^{e_{\tilde{r}}}, \mathcal{O}_{r - 1}, ..., \mathcal{O}_{r - t})
\]
for a system parameter $t$ up to which the protocol tolerates a number of Byzantine nodes, it is fundamentally the same as HydRand's. Common in both is the fact (due to which the ungrindability of $h^{e_{\tilde{r}}}$ is achieved) that one honest node must be present in any $t + 1$ consecutive rounds due to the requirement that a leader cannot gain another leadership in the next $t$ rounds. Also notably common is the use of PVSS recovery in case a round leader fails to open its precommitted entropy.
\item Algorand and Ouroboros Praos. In VRF-based schemes that use a VRF for beacon output generation (e.g. recall that NV++ uses a VRF for subset selection but not for beacon output generation), the secret key $sk$ of the round leader often corresponds to precommitted per-node entropy as long as the assumption that nodes cannot switch their $sk$ at the time of VRF's computation holds. Algorand's beacon output is therefore given by
\[
\mathcal{O}_r = VRF_{sk}(\mathcal{O}_{r - 1} \mathbin\Vert r)
\]
combining the previous output $\mathcal{O}_{r - 1}$ with the precommitted entropy $sk$. Note that the input to the VRF in beacon output generation is different from that in subset selection, as the VRF output in subset selection is always going to be less than $target$ by design. Ouroboros Praos (we take its epoch as a round for DRB similar to Ouroboros) provides an epoch-based variant where each slot leader is construed to be one entropy provider out of $K$ (denoting the number of slots in an epoch). Hence, the beacon output given by
\[
\mathcal{O}_r = H(\mathcal{O}_{r - 1} \mathbin\Vert epoch \mathbin\Vert \rho_1 \mathbin\Vert ... \mathbin\Vert \rho_K)
\]
involves all VRF outputs from all respective slot leaders, where $epoch$ denotes the epoch number and $\rho_i = VRF_{sk_i}(\mathcal{O}_{r - 1} \mathbin\Vert slot_i \mathbin\Vert \mathsf{NONCE})$ is returned by the slot leader of $slot_i$. Note the presence of the string $\mathsf{NONCE}$, which is different from $\mathsf{TEST}$ used in the private lottery.
\item Caucus. Each new reveal ($h_r$ in round $r$) of one's precommitted hash chain in Caucus corresponds to an entropy provider's precommitted entropy. The beacon output is given by
\[
\mathcal{O}_r = h_r \oplus \mathcal{O}_{r - 1}
\]
such that it naturally follows its subset selection mechanism $H(h_r \oplus \mathcal{O}_{r - 1}) < target$.
\end{itemize}

\section{Protocols With No Marginal Entropy}
\label{section:dvrf}
While DRB protocols can have all nodes or some subset of nodes contribute entropy to the beacon output every round, it is possible to devise a protocol where no node produces any marginal entropy to prolong a beacon. The advantage of this approach is that no node needs to generate and communicate any fresh entropy (which alleviates communication overhead) while the disadvantage is that the entire beacon can be predictable once compromised (perhaps undetectably).

\subsection{DRB Based On Distributed Verifiable Random Function}
Guaranteeing randomness entirely via pseudorandomness, such DRB can be based on the concept of distributed VRF \cite{hanke2018dfinity,galindo2020fully} (DVRF, also known as threshold VRF or TVRF \cite{cascudomt}), which is a distributed version of VRF. The idea is that the usual VRF's $sk$ is distributed among $n$ nodes via DKG such that $t + 1$ nodes can cooperate to compute a VRF output (as well as its proof) as if the computation involves one node with the knowledge of $sk$.

\begin{definition}[Distributed verifiable random function]
A distributed verifiable random function (DVRF) is a VRF where $n$ nodes cooperate to yield a pseudorandom output such that up to $t$ Byzantine nodes are tolerated while any $t + 1$ honest nodes are able to yield an honest output. It can be described by the following tuple of algorithms.
\begin{itemize}
\item $\mathsf{DKG}(1^\lambda, t, n) \rightarrow (sk_i, pk_i, pk)$ outputs the $i$-th node's secret key, its public key (e.g. $pk_i = g^{sk_i}$), and a global public key $pk$ (e.g. $pk = g^{sk}$) given security parameter $1^\lambda$, total number of nodes $n$, and threshold parameter $t$.
\item $\mathsf{PartialEval}(sk_i, x) \rightarrow (y_i, \pi_i)$ outputs the partial evaluation $y_i$ as well as its proof of correctness $\pi_i$ given an input $x$ and a node's secret key $sk_i$.
\item $\mathsf{PartialVerify}(pk_i, x, y_i, \pi_i) \rightarrow \{0, 1\}$ verifies the correctness of the partial evaluation $y_i$ given its proof $\pi_i$, an input $x$, and a node's public key $pk_i$.
\item $\mathsf{Combine}(A, \{(y_i, \pi_i)\}_{i \in A}) \rightarrow (y, \pi)$ outputs the DVRF evaluation $y$ as well as its proof of correctness $\pi$ given a set $A$ of $t + 1$ nodes and their outputs of $\mathsf{PartialEval}(sk_i, x)$, all of which pass $\mathsf{PartialVerify}$.
\item $\mathsf{Verify}(pk, \{pk_i\}, x, y, \pi) \rightarrow \{0, 1\}$ verifies the correctness of the DVRF evaluation $y$ given $\pi$, input $x$, and public keys.
\end{itemize}
Naturally, it should satisfy VRF's properties of provability, uniqueness, and pseudorandomness. See Appendix \ref{appendix:dvrf}.
\end{definition}

\noindent\textbf{Beacon output of a DVRF-based DRB.} Each beacon output of a DVRF-based DRB is then given by
\begingroup\makeatletter\def\f@size{8}\check@mathfonts
\[
\mathcal{O}_r = \mathsf{DVRF.Combine}(A, \{\mathsf{DVRF.PartialEval}(sk_i, f(\mathcal{O}_{r - 1}))\}_{i \in A})[0]
\]\endgroup
where $sk_i$ denotes each node's secret key after a DKG, $A$ denotes the set of $t + 1$ nodes whose outputs of $\mathsf{DVRF.PartialEval}(\cdot)$ pass the $\mathsf{DVRF.PartialVerify}(\cdot)$ test, and $f$ denotes some premeditated (mostly uncomplicated) function of $\mathcal{O}_{r - 1}$ on which nodes compute a DVRF.

Equivalently, suppose there exists one imaginary node with the knowledge of $sk$ (which should not happen in a typical DVRF or a DKG to begin with) computing a VRF. Then
\[
\mathcal{O}_r = VRF_{sk}(f(\mathcal{O}_{r - 1}))
\]
yields a computationally equivalent output to when a DVRF is computed among $n$ nodes. As $f$ typically takes a form resembling $f(\mathcal{O}_{r - 1}) = H(r \mathbin\Vert \mathcal{O}_{r - 1})$, it can be seen that there is no marginal entropy generated by the participants. The precise reason for the security of the above DVRF formulation is that no one node (or up to $t$ nodes) can gain knowledge of $sk$ to be able to compute and predict future beacon outputs.\\

\noindent\textbf{DVRF-based DRB from a chain of unique signatures.}
Due to the known fact that the hash of a verifiable unpredictable function (VUF, see Appendix \ref{appendix:vuf}) equals a VRF, a unique digital signature (which is a VUF \cite{dodis2005verifiable}) can be made into a DVRF by taking its threshold signature variant and hashing the output. Adopting the BLS signature scheme \cite{boneh2001short}, protocols like Dfinity \cite{hanke2018dfinity} and drand \cite{drand} (though with slightly different trivial details) offer a DRB given by
\[
\mathcal{O}_r = H(\mathsf{Sign}_{sk}(r \mathbin\Vert \mathcal{O}_{r - 1}))
\]
where $\mathsf{Sign}_{sk}(\cdot)$ is part of the BLS signature scheme (see Appendix \ref{appendix:bls}) and $sk$ is the implied global secret key derived from a DKG among participants such that the actual computation of $\mathcal{O}_r$ involves combining of partial signatures (which use $sk_i$), reminiscent of how a DVRF is computed via combining of partial evaluations.

In fact, note that $H(\mathsf{Sign}_{sk}(\cdot))$ is equivalent to $VRF_{sk}(\cdot)$, which is equivalent to
\[
\mathsf{DVRF.Combine}(A, \{\mathsf{DVRF.PartialEval}(sk_i, \cdot)\}_{i \in A})[0]
\]
combining $t + 1$ partial evaluations. Hence, hashing of a threshold signature is indeed a DVRF, in which case the threshold signature rather becomes the DVRF's proof $\pi$.\\

\noindent\textbf{Variations on a chain of unique signatures.} Besides a chain of BLS signatures, there exist other variations in the landscape, such as RandHerd \cite{syta2017scalable}, DDH-DRB, and GLOW-DRB \cite{galindo2020fully}.
\begin{itemize}
\item RandHerd. Two modifications are made in RandHerd. First, a form of ``sharding'' is performed where nodes are randomly configured into groups (each of size $c$) via some initial configuration seed (derived from a one-time run of RandHound in the original paper) such that each group emits a group leader while that of the first group is deemed a cothority (collective authority) leader. This results in the notion of hierarchy among nodes and thus has the effect of reducing the communication overhead from $O(n^2)$ to $O(c^2 \log n)$, as there is no need for nodes to broadcast every relevant message to every other node. Second, the underlying signature scheme used is Schnorr instead of BLS. Each beacon output in RandHerd is essentially a threshold Schnorr signature on message (as per the original protocol) $m = t_r$ where $t_r$ denotes the timestamp at the beginning of round $r$. As $m$ can technically be chosen (and thus biased) by the leader, one simple modification can involve setting $m = r \mathbin\Vert \mathcal{O}_{r - 1}$ a la Dfinity or drand in order to remove any potential bias. Otherwise, we assume $t_r$ is not a source of entropy but rather a system parameter.
\item DDH-DRB. Each round of DDH-DRB involves DDH-DVRF. As $\mathsf{PartialVerify}$ and $\mathsf{Verify}$ from Dfinity-DVRF (i.e. each round of Dfinity) rely on verifying pairing equations (see Appendix \ref{appendix:dfinity-dvrf}), the speed at which each beacon output is generated can be made faster if we replace each pairing equation with a DLEQ NIZK (see Appendix \ref{appendix:dleq}) achieving the same effect. The tradeoff is space, as $\pi$ of DDH-DVRF grows linearly in the size of $A$ and is not a compact proof. See Appendix \ref{appendix:ddh-dvrf} for details.
\item GLOW-DRB. Each round of GLOW-DRB involves GLOW-DVRF, which strikes a balance between Dfinity-DVRF and DDH-DVRF by involving a pairing equation in $\mathsf{Verify}$ (a la Dfinity-DVRF) but a DLEQ NIZK in $\mathsf{PartialVerify}$ (a la DDH-DVRF). This has the effect of generating a compact proof $\pi$ from $\mathsf{Verify}$ while enjoying less computational overhead from $\mathsf{PartialVerify}$. See Appendix \ref{appendix:glow-dvrf} for details.
\end{itemize}

\section{Discussions}
In this section, we broach points worth discussing. Namely, possible attack vectors are discussed as well as the phenomenon of adaptive security (or the lack thereof) and a tradeoff involving fresh randomness (versus pseudorandomness) and communication overhead.

\subsection{Grinding Attack}
While grinding attack is not a threat in commit-reveal-recover variants (like Scrape and HERB) or protocols with no marginal entropy (like drand and RandHerd), it is indeed a valid concern in a class of subset-based protocols involving either random selection (RS) and private lottery in terms of subset selection mechanism or combining of precommitted per-node entropy with $\mathcal{O}_{r - 1}$ in terms of beacon output generation mechanism. The idea is that an adversary can grind to produce a biased entropy-providing subset, a biased beacon output, or both. In the worst case, $\mathcal{O}_r$ can be adversarially generated via grinding such that the entropy-providing subset for the next round would likewise be adversarially selected, resulting in a vicious cycle.

Two countermeasures (depending on the protocol) are given by the following examples. First, inclusion of fresh marginal entropy from at least one honest node can be required, in which case grinding fails due to the adversary's inability to control such entropy. Second, precommitted entropy must indeed be precommitted, in which case grinding vacuously fails due to the lack of a grindable piece of entropy.
\begin{enumerate}
\item \textbf{Requirement of fresh marginal entropy from at least one honest node.} Due to the $t$-limited adversary assumption, it is possible to force the inclusion of fresh marginal entropy from at least one honest node if we require more than $t$ entropy providers each round. Such requirement is relevant in protocols like RandHound (where subset selection via LS has an explicit size requirement), Ouroboros (where the size of each epoch can be controlled to be large), and NV++ (where the VRF's target used for subset selection can be adjusted).
\item \textbf{Requirement of precommitted entropy.} No grindable entropy naturally means no possible grinding attack. Ensuring that precommitted entropy is indeed precommitted, protocols that counteract grinding in this manner include HydRand, GRandPiper, Algorand, Ouroboros Praos, and Caucus. In HydRand (and similarly GRandPiper), it is required that the precommitted entropy ($e_{\tilde{r}}$ from $\mathcal{O}_r = H(\mathcal{O}_{r - 1} \mathbin\Vert h^{e_{\tilde{r}}})$ as per Section \ref{subsubsection:precommitted}) used in round $r$ is precommitted in round $\tilde{r}$ where $r - \tilde{r} > t$ such that it is ungrindable due to the protocol's $t$-unpredictability property. In the protocols based on private lottery (i.e. Algorand, Ouroboros Praos, and Caucus), the private inputs to the lottery (VRF's $sk$ or each $h_r$ of a hash chain) are configured to be ungrindable, removing the possibility of any grinding attack overall.
\end{enumerate}

\subsection{Withholding Attack}
On the other hand, there exists an attack without much countermeasure, namely withholding attack. Any leader-based protocol can be vulnerable to this attack due to heavy reliance on a leader's availability. Any protocol with a private lottery can also be vulnerable due to its nature where the lottery winner has to announce itself as a winner in the first place or can withhold this announcement if desirable.\\

\noindent\textbf{Protocols with a leader.} For instance, take RandHound, RandHerd, SPURT, and RandRunner, all of which are leader-based. With the exception of RandRunner, these protocols suffer from the leader unavailability issue in case the leader withholds its message for whichever reason (Byzantine or non-Byzantine) such that their liveness is affected and a beacon output can be aborted (depending on implementation). In worse cases like RandHound and RandHerd, this can create a bias if the leader aborts after seeing $\mathcal{O}_r$. In RandRunner, a beacon output will not be aborted but delayed at worst due to the usage of VDFs. In any case, assuming that a leader would be available every round can be a naive one, and there needs to be some fallback in case a leader withholds (e.g. HydRand's PVSS recovery).\\

\noindent\textbf{Protocols with a private lottery.} The issue is more fundamental with private lottery schemes like Algorand (where the leader can withhold after privately computing $\mathcal{O}_r$, creating a bias). The crux is that private lottery winners are indeed private such that there is no way to detect once a winner withholds its leadership (perhaps maliciously), i.e. there is no accountability. This is an unavoidable tradeoff to the two notable benefits of a private lottery: resilience to DoS attack (due to its property of delayed unpredictability \cite{azouvi2018winning} where one cannot predict the eligibility of honest nodes until they reveal) and independent participation (i.e. nodes do not have to know other participants in advance in order to participate).

Some possible remedies include the following. First, we can require all participants to post their private lottery outputs every single round even if they lose the lottery, in which case any lack of message at any point would be indicative of some withholding. Naturally, this is costly in terms of communication complexity and thus not the most practical. Second, a technique called SSLE (single secret leader election) \cite{boneh2020single} can be used to guarantee one winner per round, enabling detection of any withholding attack. In a nutshell, SSLE allows a setup where exactly one leader from a group is randomly chosen such that the identity of the leader will only be known to the chosen leader until it publicly reveals its identity. Note that the guarantee of one winner as opposed to the expectation of one winner is what separates SSLE from schemes like Algorand. It does not prevent withholding attack by itself, however.

\subsection{Adaptive Security}
\label{subsection:adaptive}
* Adaptive security: either revelation of leadership coupled with entropy provision OR the size of subset (that adversary needs to adaptively corrupt) is big

* Adaptive insecurity:

1) gap between revelation of leadership/membership and entropy provision

2) leader can withhold

3) prediction possible due to asymmetry in computation power, e.g. RandRunner

\subsection{Quality vs Efficiency}
% Mt. Random's Tier 1 (fresh randomness per node) > 2 (one VRF, not biasable) > 3 (many VRFs, biasable via withholding) -- from quality of randomness perspective
The protocols that we have seen so far provide a range of efficiency and quality trade-offs under different setups, assumptions and adversarial models. PVSS/VSS based protocols offers uniform randomness, but comes at  quartic communication complexity. 
VRF based protocols require very little communication and computation but the output is biasable by withholding. DVRF based protocols get rid of the bias by allowing a set of participants greater than a threshold to recover the output. VDF based protocols require high computational cost (sequential squarings) but generates uniform pseudorandom outputs with quadratic communication cost. While these protocols can be used on their own, they can also be combined in a modular way to build a distributed randomness beacon. Mt. Random \cite{cascudomt}, a multi-tiered randomness beacon is one such example.

\joenote{should there be a separate section on protocols that combine other protocols?}
Mt. Random has three independent tiers, each based on a different technique and providing different trade-off between complexity and quality of randomness. Tier 1 provides uniform randomness via PVSS based protocols. Mt. Random reduces the amortized cost per beacon output by using an extension of Albatross called GULL (Gradually UnLeashed aLbatross) \cite{cascudomt}. GULL could be substituted with any of the Commit-Reveal-Recover variants from Section \ref{section:commit-reveal-recover}. Tier 2 provides uniform pseudorandomness via DVRF based protocols. Mt. Random uses DDH based version of drand, but could be substituted with any of the DVRF based protocols from Section \ref{section:dvrf} or RandRunner from Section \ref{subsection:randrunner}. Tier 3 provides biased pseudorandomness using VRF based protocols. Mt. Random uses a variation of Ouroboros Praos where every participant computes and broadcasts their VRF outputs (and requires no subset selection via private lottery). Even though this makes detecting malicious participants (and maybe punishing them) easier, the beacon output for the round would still remain biased. Randomness from earlier tiers are used to periodically refresh seeds for Tier 2 and Tier 3 protocols, making them more secure than their stand-alone versions.

Mt. Random illustrates a framework in which PVSS and (D)VRF protocols can be combined in a multi-tiered fashion where higher tiers generate random outputs faster than lower tiers albeit with losses in randomness quality. It is possible to extend the framework to other primitives/building blocks or use an altogether different framework to combine different protocols. This remains to be explored further.

\todo{conclusions, open problems}

\printbibliography
\appendix
\section*{Appendix}
\addcontentsline{toc}{section}{Appendix}
\renewcommand{\thesection}{\arabic{section}}
\section{Verifiable Delay Function (VDF)}
\label{appendix:vdf}

A VDF must satisfy the following three properties:
\begin{itemize}
\item $\epsilon$-evaluation time. $\mathsf{Eval}(pp, x)$ runs in time at most $(1 + \epsilon) T$, for all $x$ and all $pp$ output by $\mathsf{Setup}(\lambda, T)$.
\item Sequentiality. A parallel algorithm $\mathcal{A}$, using at most $poly(\lambda)$ processors, that runs in time less than $T$ cannot compute the function. Specifically, for a random $x$ and $pp$ output by $\mathsf{Setup}(\lambda, T)$, if $(y, \pi) = \mathsf{Eval}(pp, x)$ then $Pr[\mathcal{A}(pp, x) = y]$ is $\mathsf{negl(\lambda)}$.
\item Uniqueness. For an input $x$ and $T$, exactly one $y$ will be accepted by $\mathsf{Verify}$ with negligible error probability. Specifically, let $\mathcal{A}$ be an efficient algorithm that given $pp$ as input, outputs $(x, y, \pi)$ such that $\mathsf{Verify}(pp, x, y, \pi) = Accept$. Then $Pr[\mathsf{Eval}(pp, x) \neq y]$ is $\mathsf{negl(\lambda)}$.
\end{itemize}
For sequentiality, computing $y$ using $\mathsf{Eval}(pp,x)$ requires $T$ sequential squarings even on a parallel computer with $poly(\lambda)$ processors. Computing proof $\pi$ increases the running time to $(1+\epsilon)T$, as needed for $\epsilon$-evaluation time. Pietrzak \cite{pietrzak2018simple} and Wesolowski's \cite{wesolowski2019efficient} proposals differ in the way $\pi$ is generated and quickly verified. They give two different public-coin succinct arguments for proving that the output $y$ is correct and can be made non-interactive using the Fiat-Shamir Heuristic \cite{amos1986prove}. 

Both of the proof system has its own strengths. Wesolowski's proof system has shorter proofs (1 group element versus $\log T$ elements) and faster verification time (2 exponentiations versus $2 \log T$). Pietrzak's proof system allows for more efficient computation of the proof requiring only $O(\sqrt{T} \cdot \log T)$ multiplications (vs $O(T/\log (T))$), is more secure and applies in a more general setting.

\subsection{Trapdoor VDF}
\label{appendix:tvdf}
Trapdoor VDFs \cite{wesolowski2019efficient, schindler2021randrunner} are an extension and modification of traditional VDFs in which the $\mathsf{Setup}$ algorithm in addition to the public parameters $pp$ also outputs a trapdoor (secret key) $sk$ to the participant invoking the algorithm.  The parameter $pp$ is published whereas $sk$ is kept secret. Furthermore, the algorithm $\mathsf{TrapdoorEval}$ provides an alternate way to evaluate the VDF efficiently, i.e. within time $\phi{(poly{(\lambda)})}$ to participants which know the trapdoor $sk$. Participants without this knowledge can still use the $\mathsf{Eval}$ algorithm to compute the output in $(1+\epsilon)T$ sequential steps.
Trapdoor VDFs can be described by a set of four algorithms as follows.
\begin{itemize}
    \item $\mathsf{Setup}(\lambda, T) \rightarrow (pp, sk)$ is a randomized algorithm that takes a security parameter $\lambda$ and a delay parameter $T$ and outputs public parameters $pp$ and a trapdoor secret key $sk$.
    \item $\mathsf{VerifySetup}(\lambda, pp) \rightarrow (Accept, Reject)$ returns $Accept$ if the validity of $pp$ can be successfully checked, returns $Reject$ otherwise.
    \item $\mathsf{Eval}(pp, x) \rightarrow (y, \pi)$ takes an input $x$ along with the public parameters $pp$ and outputs $y$ and a proof $\pi$.
    \item $\mathsf{TrapdoorEval}(pp,x,sk) \rightarrow (y, \pi)$ takes an input $x$ and $pp$ along with trapdoor $sk$ and outputs $y$ and a proof $\pi$ such that the algorithm takes less than time $T$ to complete unlike $\mathsf{Eval}$.
    \item $\mathsf{Verify}(pp, x, y, \pi) \rightarrow \{Accept, Reject\}$ outputs $Accept$ if $y$ is the correct evaluation of the VDF on input $x$ and $T$.
\end{itemize}

Due to the introduction of trapdoors and strong uniqueness, in contrast to traditional VDFs, trapdoor-VDF must satisfy the following properties:

\begin{itemize}
    \item $\epsilon$-evaluation time. $\mathsf{Eval}(pp, x)$ runs in time at most $(1 + \epsilon) T$, for all $x$ and all $pp$ output by $\mathsf{Setup}(\lambda)$.
    \item Sequentiality without trapdoor. A parallel algorithm $\mathcal{A}$, using at most $poly(\lambda)$ processors, that runs in time less than $T$ cannot compute the function without the knowledge of a secret trapdoor. Specifically, for a random $x$ and all $pp$ output by $\mathsf{Setup}(\lambda, T)$, if $(y, \pi)$ is the output of $\mathsf{Eval}(pp, x)$ or $\mathsf{TrapdoorEval}(pp,x,sk)$, then the probability that $\mathcal{A}$ can compute $y$ in less than $T$ steps is negligible.
    \item Strong uniqueness. For each input $x$ and all public parameters $pp$, exactly one $y$ will be accepted by $\mathsf{Verify}$ with negligible error probability even if the public parameters have been adversarially generated. Specifically, let $\mathcal{A}$ be an efficient algorithm that outputs $(pp, x, y, \pi)$ such that $\mathsf{Verify}(pp, x, y, \pi) = Accept$. Then $Pr[\mathsf{Eval}(pp, x) \neq y]$ is negligible.
\end{itemize}

\section{Verifiable Secret Sharing (VSS)}
\label{appendix:vss}
VSS schemes have two security requirements:
\begin{itemize}
    \item Secrecy. If the dealer is honest, then the probability of an adversary learning
    any information about the dealer’s secret in the sharing phase is $\mathsf{negl}(\lambda)$.
    \item Correctness. If the dealer is honest, then the honest nodes output the secret
    $s$ at the end of the reconstruction phase with a high probability of $1 - \mathsf{negl}(\lambda)$.
\end{itemize}
Feldman-VSS \cite{feldman1987practical} and Pedersen-VSS \cite{pedersen1991non} are the most commonly used implementations of the above interface.

\subsection{Feldman-VSS}
\label{appendix:feldmanVSS}
The following summarizes a simple VSS scheme proposed by Paul Feldman for sharing a secret $s$ among $n$ participants where any subset of $t+1$ among them can reconstruct the group secret.
\begin{itemize}
    \item $\mathsf{ShareGen}(s) \rightarrow (\{s_i\}, C)$ with $s \in \mathbb{Z}_q$ involves the dealer sampling $t$ random coefficients $a_1, \ldots, a_t \in \mathbb{Z}_q$ and constructing a $t$ degree polynomial $p(x) = s + a_1x+ a_2x^2 +\ldots+a_tx^t$.\\
    The shares are computed as $s_i = p(i)$ in mod $q$ for $1\le i \le n$ and shared privately with each participant.\\
    The commitments to the secret $C_0 = g^s$ as well as coefficients $C_j = g^{a_j}$ for $j = 1,\ldots,t$ are also broadcast by the dealer.
    
    \item $\mathsf{ShareVerify}(s_i, C) \rightarrow \{0, 1\}$ involves each participant $P_k$  checking if:
    $$g^{s_k} = \prod_{j = 0}^{t } C_j^{k^j} = C_0 C_1^k C_2^{k^2} \cdots C_{t }^{k^{t }}$$
     If it does not hold for some $k$, then participant $P_k$ broadcasts an accusation against the dealer, who has to respond by broadcasting the correct $s_k$. \\
     Correct reconstruction is achieved by filtering out shares that do not satisfy $\mathsf{ShareVerify}$.
    \item $\mathsf{Recon}(A, \{s_i\}_{i \in A}) \rightarrow s$ outputs the secret $s$ by performing  Lagrange interpolation involving Lagrange coefficients $\lambda_i = \prod_{j \neq i} \frac{j}{j - i}$ in mod $q$ with a subset of valid $t+1$ shares:
    $$s = p(0) = \sum_{i = 1}^{t+1} s_i \lambda_i$$
\end{itemize}

The verifiability in Feldman-VSS comes from inclusion of commitments to the coefficients. These commitments enable participants to verify the validity of the shares that they receive from the dealer.

\subsection{Pedersen-VSS}
\label{appendix:pedersenVSS}
Reminiscent of Pedersen commitment, Pedersen-VSS is a variation that couples the commitment to the coefficient of secret polynomial with another randomly chosen polynomial. By removing the assumption that $g^s$ is known beforehand as part of the commitment to the coefficients, it results in a secret sharing scheme which is unconditionally secure for the dealer. It can be summarized as follows:

\textbf{Setup.} In addition to parameters $p,q,g$ inherent to Feldman-VSS, it uses an element $h$ in the subgroup of $\mathbb{Z}^*_p$ generated by $g$. It is assumed that the adversary cannot find the discrete logarithm of $h$ relative to the base $g$.

\begin{itemize}
\item $\mathsf{ShareGen}(s) \rightarrow (\{s_i\}, C)$ with $s \in \mathbb{Z}_q$ involves the dealer sampling two random polynomials $p(x) = a_0 + a_1x+ \ldots+a_tx^t$ and $p'(x) = b_0 + b_1x +\ldots+b_tx^t$  where $a_i, b_i \in \mathbb{Z}_q$ and the secret $s = a_0 = p(0)$.\\
The shares are computed as $(s_i = p(i), s'_i = p'(i))$ in mod $q$ for $1 \le i \le n$ and are shared with each participant privately.\\
Also distributed from the dealer are coupled commitments to coefficients of $p$ and $p'$, i.e. $C_j = g^{a_j} h^{b_j}$ for $j = 0, ..., t$.
\item $\mathsf{ShareVerify}(s_i, C) \rightarrow \{0, 1\}$ involves each participant $P_k$ with shares $(s_k, s'_k)$ and the public polynomial coefficient commitments checking if:
$$g^{s_k} h^{s'_k} = \prod_{j = 0}^{t} C_j^{k^j}$$
Similar to Feldman-VSS, any accusation of incorrect sharing against dealer by a participant $P_k$ would require the dealer to broadcast the correct values of shares $(s_k, s'_k)$.
\item $\mathsf{Recon}(A, \{s_i\}_{i \in A}) \rightarrow s$ outputs the secret $s$ by performing Lagrange interpolation involving Lagrange coefficients $\lambda_i = \prod_{j \neq i} \frac{j}{j - i}$ in mod $q$ with a subset of valid $t+1$ shares (of polynomial $p(x)$):
    $$s = p(0) = \sum_{i = 1}^{t+1} s_i \lambda_i$$
\end{itemize}

Effectively, what Pedersen-VSS is able to achieve is the decoupling of $g^{s}$ from the published commitment for verifying the correctness of sharing ( $g^{a_i} h^{b_i}$). In other words, the verification process in which the participants verify their shares does not (even information-theoretically) leak any information regarding the initial secret $s$, a fact that is not true with Feldman-VSS. This would be useful later on, when VSS is used as a subprotocol for distributed key generation (DKG), where an adversary is otherwise able to bias the outcome.

\section{Distributed Key Generation (DKG)}
\label{appendix:dkg}
A DKG protocol should satisfy the following security requirements:
\begin{itemize}
    \item Correctness
        \begin{enumerate}
        \item All subsets of $t+1$ shares provided by honest participants define the same unique secret key $x$.
        \item All honest participants have the same value of public key $y=g^x$, where $x$ is the unique secret guaranteed above.
        \item $x$ is uniformly distributed in $\mathbb{Z}_q$, and thus $y$ is uniformly distributed in $\mathbb{G}_q$ (subgroup of $\mathbb{Z}^*_p$ generated by $g$).
        \end{enumerate}
        
    \item Secrecy. No information on $x$ can be learned by the adversary except for what is implied by the value $y = g^x$.
\end{itemize}

One of the best known DKG schemes is Joint-Feldman \cite{pedersen1991threshold}, proposed by Torben Pryds Pedersen. As discussed in \cite{gennaro1999secure}, Joint-Feldman does not guarantee uniform randomness or secrecy of the shared secret key. Hence a malicious adversary can bias the public global key. Joint-Pedersen, proposed in the same paper combines discrete logarithm and Pedersen's commitments to guarantees uniform randomness by increasing the number of communication rounds by one.  Nevertheless, it has been shown that the public key biasability should not be a problem for applications that use DKG as a subprotocol for distributed randomness.
\subsection{Joint-Feldman}
\label{appendix:jointFeldman}
In Joint-Feldman DKG scheme, each participant use Feldman-VSS to share a randomly chosen secret. The protocol is implemented as follows:
\begin{itemize}
    \item $\mathsf{DKG}(1^{\lambda}, t, n) \rightarrow (\vec{SK}, \vec{PK}, pk)$  proceeds in two phases---Sharing and Reconstruction.
    \begin{enumerate}
        \item In Sharing phase, each participant $P_i$ runs Feldman-VSS by choosing a random polynomial over $\mathbb{Z}_q$ of degree $t$, $p_i(z) = \sum_{j = 0}^{t} a_{ij} z^j$ and sending a subshare $s_{ij} = p_i(j)$ mod $q$ to each participant $P_j$ privately. \\
        To satisfy the verifiability portion of VSS, $P_i$ also broadcasts $C_{ik} = g^{a_{ik}}$ for $k = 0, \ldots, t$. Let the commitment corresponding to the secret be denoted by $y_i = C_{i0}$.
        
        Each participant $P_j$ also verifies the shares he receives from other participants by performing verification steps of Feldman-VSS on each subshare. If the verification for an index $i$ fails, $P_j$ broadcasts a complaint against $P_i$. If $P_i$ receives more than $t$ complaints, then $P_i$ is disqualified. Otherwise, $P_i$ reveals the subshare $s_{ij}$ for every $P_j$ that has broadcast a complaint. We call $QUAL$ the set of non-disqualified participants.
        
        \item Reconstruction phase calculates the keys based on $QUAL$.
        The group public key is calculated as $pk = \prod_{i \in QUAL} y_i$ where the individual public keys are $pk_i = y_i$. Each participant $P_j$'s share of the group secret is  computed as $sk_j = \sum_{i \in QUAL} s_{ij}$ mod $q$.  Though not computed explicitly, the group secret key $sk$ is equal to both $\sum_{i \in QUAL} a_{i0}$ mod $q$ and the Lagrange interpolation involving the shares $\{sk_j\}_{j \in QUAL}$.
    \end{enumerate}
\end{itemize}

\subsection{Joint-Pedersen}
\label{appendix:jointPedersen}
The biasability of Joint-Feldman comes from the fact that the decision on who will be part of $QUAL$ is made after the adversary has seen the $y_i$'s of all the participants. This happens because $y_i = C_{i0}$ is published as part of the commitment (required to prove correctness of sharing). Joint-Pedersen solves this by decoupling the output $y_i$ from the commitments for proving correctness by using Pedersen-VSS. This results in $QUAL$ and the secret $x$ being determined first, and an additional run of Feldman-VSS to recover $y_i$'s. It is implemented as follows:
\begin{itemize}
    \item $\mathsf{DKG}(1^{\lambda}, t, n) \rightarrow (\vec{SK}, \vec{PK}, pk)$ involves two phases---Sharing and Reconstruction. However, the Reconstruction phase requires an additional run of Feldman-VSS to recover the public keys. 
    \begin{enumerate}
    \item Sharing phase involves each participant $P_i$ running Pedersen-VSS by choosing two random polynomials over $\mathbb{Z}_q$ of degree $t$, $p_i(z) = \sum_{j = 0}^{t} a_{ij} z^j$ and $p'_i(z) = \sum_{j = 0}^{t} b_{ij} z^j$ and sending subshares ($s_{ij} = p_i(j)$, $s'_{ij} = p'_i(j)$) in mod $q$ to each participant $P_j$ privately and broadcasting the commitments $C_{ik} = g^{a_{ik}} h^{b_{ik}}$ for $k = 0, \ldots, t$ to prove correctness. Note that unlike Joint-Feldman, publishing $C_{ik}$ does not reveal any information about $y_i = g^{a_{i0}}$.\\
    Each participant $P_j$ verifies the shares he receives from other participants by performing share verification step of Pedersen-VSS on each subshare. If the verification for an index $i$ fails, $P_j$ broadcasts a complaint against $P_i$.
    If $P_i$ receives more than $t$ complaints, then $P_i$ is disqualified. Otherwise, $P_i$ reveals the subshare $(s_{ij}, s'_{ij})$ for every $P_j$ that has broadcast a complaint. We call $QUAL$ the set of non-disqualified participants.
    
    \item Reconstruction is a two-part process. The first part involves calculating each participant's share of group secret and implicitly recovering the group secret based on $QUAL$, like in Joint-Feldman. Each participant $P_j$'s share of the group secret is calculated as $sk_j = \sum_{i \in QUAL} s_{ij}$ mod $q$.  The group secret key $sk$ is equal to the Lagrange interpolation involving the shares $\{sk_j\}_{j \in QUAL}$. 
    
    The second part of Reconstruction phase involves extracting $pk$ by an additional run of Feldman-VSS because unlike Joint-Feldman,  we do not have the corresponding shares $y_i = g^{a_{i0}}$'s required its calculation.  Each participant $P_i \in QUAL$ exposes $y_i = g^{a_{i0}}$ as follows:
        \begin{enumerate}
            \item Each participant $P_i \in QUAL$ broadcasts the commitment to the coefficient of the secret polynomial $p_i(z)$ as $A_{ik} = g^{a_{ik}}$ for $k = 0, \ldots, t$. Let $y_i = A_{i0}$.
            \item Each $P_j$ verifies the values broadcast by each other participant $P_i$ are consistent with the shares $s_{ij}$ shared earlier in a similar way as Feldman-VSS. If the verification fails, $P_j$ broadcasts a complaint against $P_i$ by posting the shares $s_{ij}$ and $s'_{ij}$.
            \item For any participant $P_i$ that receives at least one valid complaint, all the other participants run the reconstruction phase of Pedersen-VSS to recover the secret polynomial $p_i(z)$. 
            \item Finally, the group public key is calculated as $pk = \prod_{i \in QUAL} y_i = \prod_{i \in QUAL} g^{a_{i0}}$ where $y_i$ is individual public key $pk_i$ for participant $P_i$.
        \end{enumerate}
    \end{enumerate}
\end{itemize}

\subsection{Escrow-DKG}
\label{appendix:edkg}
Escrow-DKG \cite{david2019rational} extends DKG to a model where the participants are not expected to follow some predetermined set of instructions and instead are driven to maximize their profit. It does so by introducing a transparent escrow service that takes participants' deposits and can burn or redistribute them. It proceeds in similar phases as Joint-Feldman. However, any complaint of undesired behavior by a participant against another participant is arbitrated by the escrow and can result in deposits being slashed. The protocol fails once a complaint has been filed. The modification of Escrow-DKG used in EVR , with $n$ participants and threshold $t$, can be described by the following algorithms:
\begin{itemize}
    \item $\mathsf{EscrowEnroll}(d, pk, H(C_{0})) \rightarrow \{0,1\}$ is used by a participant with public encryption key $pk$ to register with the escrow with deposit $d$ and hash of commitment to her partial secret $C_{0}$. In case of Feldman-VSS, $C_{0} = g^{s}$. It returns the success of enrollment.
    
    \item $\mathsf{Commit} (s) \rightarrow (\{\mathsf{Enc}(pk_i, s_{i})\}, C)$ is used by a participant with secret $s$ to generate encrypted subshares and commitments by executing $\mathsf{VSS.ShareGen}(s)$. For Feldman-VSS, it outputs commitment to the coefficients of $t$ degree random polynomial $C_j = g^{a_j}$ for $0\le j \le t$ and subshares for every other participant $P_i$ encrypted using their public key $\mathsf{Enc}(pk_i, s_{i})$. \\
    Each participant verifies the consistency of the subshares with the commitments. The escrow also checks if the published $C_{0}$ matches with $H(C_{0})$ for participant $P_i$. Any complaint is arbitrated by the escrow and can result in deposits being slashed.
    
    \item $\mathsf{Reveal}(A, \{x_i\}_{i \in A}) \rightarrow (x, X)$ takes a subset of $t+1$ individual key shares and reconstructs the shared group secret $x$ using $\mathsf{VSS.Recon}$. In Feldman-VSS, each participant $P_i$ calculates their secret key share as $x_i = \sum_{j=1}^{n} s_j$ in mod $q$ and the group secret $x$ is reconstructed by Lagrange interpolation on $t+1$ such shares. Additionally, it also outputs its corresponding public key $X = \prod_{i=1}^{n} C_{i0}$ for verification.
    
    \item $\mathsf{EscrowVerify}(x, X)\rightarrow\{0,1\}$ is used by the escrow to verify that the published secret $x$ is indeed the one that corresponds to $X$.
\end{itemize}

\section{Publicly Verifiable Secret Sharing (PVSS)}
\label{appendix:pvss}
PVSS can be described by the following algorithms.
\begin{itemize}
    \item $\mathsf{Setup}(\lambda) \rightarrow pp$ generates the public parameters $pp$ and is an implicit input to all other algorithms.
    \item $\mathsf{KeyGen}(\lambda) \rightarrow (sk_i, pk_i)$ generates the PVSS key pair used for encryption and decryption for node $i$.
    \item $\mathsf{Enc}(pk_i, m) \rightarrow c$ and $\mathsf{Dec}(sk_i, c) \rightarrow m'$ are subalgorithms used when the dealer sends an encrypted share to node $i$ and when node $i$ decrypts the encrypted share, respectively. Both $\mathsf{Enc}$ and $\mathsf{Dec}$ may optionally output a proof of correctness (e.g. $\pi_{DLEQ}$).
    \item $\mathsf{ShareGen}(s) \rightarrow (\{\mathsf{Enc}(pk_i, s_i)\}, \{s'_i\}, \pi)$ with $s'_i = \mathsf{Dec}(sk_i, \mathsf{Enc}(pk_i, s_i))$ is a two-part process. First, the dealer with secret $s$ generates secret shares $\{s_i\}$, encrypts them to generate $\{\mathsf{Enc}(pk_i, s_i)\}$, and sends each of them to node $i$ along with an optional encryption proof of correctness. Second, node $i$ decrypts the received encryption from the dealer to generate $s'_i$ and broadcasts it for reconstruction along with an optional decryption proof of correctness. At the protocol level, this yields $\{s'_i\}$ as a result. Note that it is possible that $s'_i \neq s_i$. In fact, $s'_i = h^{s_i}$ for some group generator $h$ is standard in the landscape due to certain PVSS implementation details (to be delineated afterwards). Note that $\pi$ incorporates optional encryption and decryption proofs of correctness as well as any auxiliary proof necessary to enable a certain PVSS implementation.
    \item $\mathsf{ShareVerify}(\{\mathsf{Enc}(pk_i, s_i)\}, \{s'_i\}, \pi) \rightarrow \{0, 1\}$ verifies if the sharing is correct overall. Again, verifying $\pi$ should involve verifying the optional proofs for encryption and decryption as well as any auxiliary proof necessary for proving correctness.
    \item $\mathsf{Recon}(A, \{s'_i\}_{i \in A}) \rightarrow s'$ reconstructs the shared secret $s'$ via Lagrange interpolation (in the exponent) from a set $A$ of $t + 1$ nodes whose contributions are passed by the $\mathsf{ShareVerify}$ algorithm. Typically, $s' = h^s$ in the landscape.
\end{itemize}

PVSS is a secure VSS scheme providing the following additional guarantee:
\begin{itemize}
    \item Public Verifiability. If the $\mathsf{ShareVerify}$ algorithm returns 1, then the scheme is valid in a publicly verifiable manner with high probability $1 - \mathsf{negl}(\lambda)$.
\end{itemize}

\subsection{Schoenmakers PVSS}
\label{appendix:schoenmakersPVSS}
One of the most common PVSS schemes used in practice is one by Schoenmakers \cite{schoenmakers1999simple}. As typical, the setup involves $g, h \in \mathbb{G}_q$ for $\mathbb{G}_q$ of prime order $q$. Additionally, each participant $P_i$ generates a private key $x_i \in \mathbb{Z}^*_q$ and registers $y_i = h^{x_i}$ as its public key.

\begin{itemize}
\item $\mathsf{ShareGen}(s) \rightarrow (\{\mathsf{Enc}(y_i, s_i)\}, \{s'_i\}, \pi)$ with $s'_i$ equal to $\mathsf{Dec}(x_i, \mathsf{Enc}(y_i, s_i))$ first involves production of $\{\mathsf{Enc}(y_i, s_i)\}$ by the dealer with secret $s$. Namely, the dealer picks a random polynomial $p$ of degree $t$ with coefficients in $\mathbb{Z}_q$
\[
p(x) = \sum_{i = 0}^{t} a_i x^i
\]
where $s = p(0) = a_0$ and computes $Y_i = \mathsf{Enc}(y_i, s_i) = y_i^{p(i)}$, which is sent to each node $i$ along with information needed to prove its correctness: $C_j = g^{a_j}$ for $0 \leq j \leq t$ such that $X_i = \prod_{j = 0}^{t} C_j^{i^j} = g^{p(i)}$ and $\mathsf{DLEQ}(g, X_i, y_i, Y_i)$. Upon receiving $Y_i$, node $i$ computes $s'_i = \mathsf{Dec}(x_i, Y_i) = Y_i^{1 / x_i} = h^{p(i)}$ and generates information needed to prove its correctness: $\mathsf{DLEQ}(h, y_i, s'_i, Y_i)$.
\item $\mathsf{ShareVerify}(\{Y_i\}, \{s'_i\}, \pi) \rightarrow \{0, 1\}$ verifies the encryption proof of correctness $\mathsf{DLEQ}(g, X_i, y_i, Y_i)$ where $X_i$'s are computed from $C_j$'s as well as the decryption proof of correctness $\mathsf{DLEQ}(h, y_i, s'_i, Y_i)$.
\item $\mathsf{Recon}(A, \{s'_i\}_{i \in A}) \rightarrow h^s$ performs the following Lagrange interpolation in the exponent
\[
\prod_{i \in A} (s'_i)^{\lambda_{0, i, A}} = h^{\sum_{i \in A} p(i) \lambda_{0, i, A}} = h^{p(0)} = h^s
\]
where $\lambda_{0, i, A}$ denotes the Lagrange coefficients. Note that, unlike VSS, the scheme does not require the knowledge of the values $p(i)$ by the participants. The private keys $x_i$ are not exposed as well and thus can be reused.
\end{itemize}

\subsection{Scrape PVSS}
\label{appendix:scrapePVSS}
Following the work of \cite{cascudo2017scrape}, we define a $[n, k, d]$ code $C$ to be a linear error correcting code over $\mathbb{Z}_q$ of length $n$, dimension $k$, and minimum distance $d$. Its dual code $C^\perp$ is the vector space consisting of vectors $c^\perp \in \mathbb{Z}_q^n$ such that $\langle c, c^\perp \rangle = 0$ for all $c \in C$. Scrape's PVSS verification relies on the following lemma.
\begin{lemma}
If $v \in \mathbb{Z}_q^n \setminus C$ and $c^\perp$ is chosen uniformly at random in $C^\perp$, then $Pr\left[\langle v, c^\perp \rangle = 0\right]$ is exactly $\frac{1}{q}$.
\end{lemma}

Assuming that $n < q$, we harness Reed-Solomon codes $C$ of the form
\[
C = \{(p(1), p(2), ..., p(n)) : p(x) \in \mathbb{Z}_q[x], \deg p(x) \leq k - 1\}
\]
where $p(x)$ ranges over all polynomials in $\mathbb{Z}_q[x]$ of degree at most $k - 1$. Then $C$ represents a $[n, k, n - k + 1]$ code while $C^\perp$ is a $[n, n - k, k + 1]$ code given by
\[
C^\perp = \{(\mu_1 f(1), ..., \mu_n f(n)) : f(x) \in \mathbb{Z}_q[x], \deg f(x) \leq n - k - 1\}
\]
where $\mu_i = \prod_{j = 1, j \neq i}^n \frac{1}{i - j}$.

Overall, Scrape PVSS is an optimization to Schoenmakers PVSS requiring $O(n)$ exponentiations to verify $n$ shares as opposed to $O(n t)$ exponentiations, leveraging the above coding theory related to Reed-Solomon codes. The idea is that the dealer, instead of committing to each polynomial coefficient via $C_j$, computes and distributes $v_i = g^{p(i)}$ directly, in which case each verifier needs to sample a random codeword $c^\perp = (c_1^\perp, ..., c_n^\perp)$ from $C^\perp$ and run a verification test involving all $v_i$'s at once.

Scrape PVSS comes in two flavors: $PVSS_{DDH}$ and $PVSS_{DBS}$. The former relies on the DDH (decisional Diffie-Hellman) assumption while the latter uses a bilinear pairing and thus relies on the DBS (decisional bilinear square) assumption \cite{heidarvand2008public}.\\

\noindent\underline{$PVSS_{DDH}$}
\begin{itemize}
\item $\mathsf{ShareGen}(s) \rightarrow (\{\mathsf{Enc}(y_i, s_i)\}, \{s'_i\}, \pi)$ with $s'_i$ equal to $\mathsf{Dec}(x_i, \mathsf{Enc}(y_i, s_i))$ is the same as that of Schoenmakers PVSS except the fact that $v_i = g^{p(i)}$ is computed and sent directly by the dealer as opposed to $C_j$'s. The encryption and decryption proofs $\mathsf{DLEQ}(g, v_i, y_i, Y_i)$ and $\mathsf{DLEQ}(h, y_i, s'_i, Y_i)$ remain unchanged.
\item $\mathsf{ShareVerify}(\{Y_i\}, \{s'_i\}, \pi) \rightarrow \{0, 1\}$ additionally requires a verifier to sample a random codeword $c^\perp = (c_1^\perp, ..., c_n^\perp)$ from $C^\perp$ (dual code of $C$ corresponding to the secret sharing instance) and run the following verification test given by
\[
\prod_{i = 1}^n v_i^{c_i^\perp} = g^{\sum_{i = 1}^n p(i) c_i^\perp} = g^{\langle c, c^\perp \rangle} = g^0 = 1
\]
where $\langle \cdot, \cdot \rangle$ denotes an inner product. It is in this way that $O(n)$ exponentiations are needed to verify $n$ shares.
\item $\mathsf{Recon}(A, \{s'_i\}_{i \in A}) \rightarrow h^s$ is the same as that of Schoenmakers PVSS.
\end{itemize}

\noindent\underline{$PVSS_{DBS}$}\\
$PVSS_{DBS}$ provides a different flavor to $PVSS_{DDH}$, as it uses a bilinear pairing (without loss of generality) $e: \mathbb{G} \times \mathbb{G} \rightarrow \mathbb{G}_T$ with $\mathbb{G} = \langle g \rangle = \langle h \rangle$ for two independent generators of $\mathbb{G}$ and $\mathbb{G}_T$ denoting a cyclic group of prime order $q$. Fundamentally similar to $PVSS_{DDH}$, the scheme necessitates appropriate algebraic modifications accordingly while the final shared secret is $e(h^s, h)$ rather than $h^s$.
\begin{itemize}
\item $\mathsf{ShareGen}(s) \rightarrow (\{\mathsf{Enc}(y_i, s_i)\}, \{s'_i\}, \pi)$ with $s'_i$ equal to $\mathsf{Dec}(x_i, \mathsf{Enc}(y_i, s_i))$ is the same as in $PVSS_{DDH}$ except that both encryption and decryption proofs of correctness are no longer necessary.
\item $\mathsf{ShareVerify}(\{Y_i\}, \{s'_i\}, \pi) \rightarrow \{0, 1\}$ instead requires a verifier to essentially replace the encryption and decryption proofs with verifying two pairing equations, respectively. The encryption proof $\mathsf{DLEQ}(g, v_i, y_i, Y_i)$ is replaced by verifying the pairing equation $e(v_i, y_i) = e(g, Y_i)$. The decryption proof $\mathsf{DLEQ}(h, y_i, s'_i, Y_i)$ is replaced by verifying the pairing equation $e(s'_i, y_i) = e(h, Y_i)$. The same verification test
\[
\prod_{i = 1}^n v_i^{c_i^\perp} = 1
\]
is also run.
\item $\mathsf{Recon}(A, \{s'_i\}_{i \in A}) \rightarrow e(h^s, h)$ outputs $e(h^s, h)$ as the shared secret after the corresponding Lagrange interpolation in the exponent outputs $h^s$.
\end{itemize}

\subsection{Albatross}
\label{appendix:albatross}
Albatross achieves its improvement ($\theta(\log n)$ exponentiations per party per beacon output) over Scrape ($\theta(n^2)$ exponentiations per party beacon output) using the following techniques.\\\\
\noindent\textbf{Packed Shamir Secret Sharing} \\
Packed Shamir secret sharing is a generalization of Shamir secret sharing that allows to secret-share a vector of $\ell$ elements from a field rather than a single element. The key point is that every share is still one element of the field and therefore the sharing has the same computational cost of $\theta(n)$ exponentiations as regular Shamir secret sharing. This is accomplished by having the dealer choose a polynomial $p$ of degree $t+\ell-1$ uniformly at random and use a set of $\ell$ distinct points for secret sharing $\ell$ secrets, e.g. $(s_0, s_1, ..., s_{\ell - 1}) = (p(0), p(-1), ..., p(-(\ell - 1)))$, and another set of $n$ distinct points on the same polynomial for the shares sent by the dealer to each participant, e.g. $(p(1), ..., p(n))$. Any subset of $t+\ell$ points can be used to reconstruct the secret polynomial via Lagrange interpolation and recover the $\ell$ secrets. Note that the usual Shamir secret sharing corresponds to when $\ell = 1$.\\

\noindent\textbf{Linear Perfect $t$-resilient functions}\\
Instead of computing the final randomness from PVSS reconstructions as $\prod_{j \in \mathcal{C}} h^{s^j}$ like in Scrape, Albatross uses a $t$-resilient function for randomness extraction.\\
A $\mathbb{Z}_q$-linear $t$-resilient function is a linear function $\mathbb{Z}_q^r \rightarrow \mathbb{Z}_q^u$ given by a matrix $M \in \mathbb{Z}_q^{u \times r}$ such that the output is uniformly distributed in  $\mathbb{Z}_q^u$ as long as $r-t$ coordinates of the input are uniformly distributed in  $\mathbb{Z}_q^{r-t}$, even if the other $t$ coordinates are completely controlled by the adversary. Such a function can only exist if $u \le r-t$.\\
In the presence of some participant withholding its secret $s$, PVSS only allows us to recover $h^s$ (for some public generator of $h$ of the group) instead of the secret $s$. This would require us to apply $t$-resilient function in the exponent. So, given $h_1, \ldots, h_r$ where $h_i = h^{x_i}$ and $x_i$ is private,  goal is to extract $(\hat{h_1},\ldots, \hat{h_u}) \in \mathbb{G}_q^u$ which is uniformly random. It is achieved by applying the $t$-resilient function given by matrix $M$ to the exponents, i.e., $\hat{h_i} = h^{y_i}$ where $\vec{x} \mapsto \vec{y} = M \cdot \vec{x}$. This can be evaluated efficiently with $O(n^2 \log n)$ exponentiations by choosing $M$ to be a certain type of Vandermonde matrix and adapting the Cooley-Tukey Fast Fourier transform algorithm to work in the exponent (FFTE) \cite{cascudo2020albatross} of the group.\\

In Albatross we assume $n$ participants, of which the static adversary corrupts at most $t$ participants where $t<(n-1)/2$. We then define $\ell = n-2t >0 $. The output of the protocol will be $\ell^2$ elements of $\mathbb{G}_q$. Similar to Scrape, the protocol proceeds in four phases: Commit, Verify, Reveal, Recover and Output.
\begin{enumerate}
    \item \textbf{Commit} Every participant $P_j$ acts as dealer for packed PVSS and publishes encrypted shares and verification information for recovering $\ell$ secrets $h^{s^{(j)}_{0}}, \ldots, h^{s^{(j)}_{\ell-1}}$.
    \item \textbf{Verify} Every participant executes the sharing verification phase on every shared secret. Since verification is public, this fixes the set $\mathcal{C}$ of the first $n-t (= t + \ell)$ participants who have correctly shared.
    \item \textbf{Reveal} Every participant $P_j \in \mathcal{C}$ opens the Shamir secret $(s^{(j)}_{0}, \ldots, s^{(j)}_{\ell-1})$. The other participants verify its consistency with the sharing posted before. The protocol proceeds to the Recover phase only if all the participants in $\mathcal{C}$ have not opened their secrets correctly. Otherwise it proceeds to Case 1 of Output phase.
    \item \textbf{Recover} For each participant $P_a$ that do not open their secret during the Reveal phase, other participants publish the decrypted shares of the secret. Once $t+\ell$ valid shares are published, Lagrange interpolation is used to reconstruct the polynomial and recover the secrets $h^{s^{(a)}_{0}}, \ldots, h^{s^{(a)}_{\ell-1}}$. Then it proceeds to Case 2 of Output phase.
    \item \textbf{Output}
        \begin{itemize}
            \item \textit{Case 1.} When all the participants in $\mathcal{C}$ have opened their secrets correctly, we have a $(n-t) \times \ell$ matrix $S$ with rows indexed by the participants  $P_a \in \mathcal{C}$ and each row corresponding to its $\ell$ opened secrets $(s^{(a)}_{0}, \ldots, s^{(a)}_{\ell-1})$. The final randomness $\mathcal{O}$ with $\ell^2$ elements is computed by each participant as $\mathcal{O} = h^U$, where $U = M \cdot S \in \mathbb{Z}_q^{\ell \times \ell}$.
            
            \item \textit{Case 2.} Otherwise, we have a $(n-t) \times \ell$ matrix $T$ with rows indexed by the participants  $P_a \in \mathcal{C}$ where the row corresponding to $P_a$ is $(h^{s^{(a)}_{0}}, \ldots, h^{s^{(a)}_{\ell-1}})$. The final $\ell \times \ell$ randomness matrix $\mathcal{O}$ is computed as $\mathcal{O} = M \diamond T$ by applying FFTE to each column $T^{(j)}$ of $T$ producing column $\mathcal{O}^{(j)}$ of $\mathcal{O}$.
        \end{itemize}
\end{enumerate}

\section{Threshold Encryption}
\label{appendix:thresholdEnc}
Following the work of \cite{cortier2013distributed}, a $(t, n)$-threshold encryption scheme should provide the following properties:
\begin{itemize}
    \item Completeness. For any $1\le t\le n$ and for every admissible plaintext $m$, if the keys have been honestly generated with $\mathsf{DKG}(1^\lambda, t, n)$, the plaintext encrypted with $\mathsf{Enc}(pk, m)$ and a set of at least $t+1$ honest participants have computed the correct decryption shares with $\mathsf{ShareDec}(sk_i, pk_i, C)$, then we require $\mathsf{Rec}(pk, \vec{PK}, C, \vec{\mu} ) = m$.
    \item Robustness. For any ciphertext $C$ and any two $(t+1)-$subsets of decryption shares $\mu \ne \mu'$ such that $\mathsf{Rec}(pk, C, \mu) \ne {Reject}$ and $\mathsf{Rec}(pk, C, \mu') \ne {Reject}$, then it holds that $\mathsf{Rec}(pk, C, \mu) = \mathsf{Rec}(pk, C, \mu')$.
    \item IND-CPA against static corruptions. A $(t, n)$ threshold cryptosystem is said to be IND-CPA secure if for any polynomial time adversary $\mathcal{A}$ corrupting at most $t$ participants at the beginning of the protocol, $\mathcal{A}$, who acts on behalf of corrupted nodes, has negligible advantage in a  game $\mathsf{Exp}^{\mathsf{cpa}}_{\mathcal{A}}$ played against challenger, who acts on behalf of the remaining servers. In other words,
    $$|Pr[\mathsf{Exp}_{\mathcal{A}}^{\mathsf{cpa}}(\lambda) = 1] - 1/2| < \mathsf{negl}(\lambda)$$
    
    The game $\mathsf{Exp}^{\mathsf{cpa}}_{\mathcal{A}}$ proceeds as follows:
    \begin{enumerate}
        \item The adversary $\mathcal{A}$ and the challenger run together $\mathsf{DKG}(1^\lambda, t, n)$, at the end of which the adversary learns the individual secret keys of all the corrupted nodes $sk_1, sk_2, \ldots, sk_t$. It also obtains the global public key $pk$ and the public keys of all the participants $\vec{PK}$.
        \item $\mathcal{A}$ then chooses two admissible messages $m_0$, $m_1$ of equal length and sends it to the challenger.
        \item The challenger randomly chooses one of them $\beta \leftarrow \{0, 1\}$ and sends $\mathsf{Enc}(pk, m_{\beta})$ back to the adversary.
        \item Finally, $\mathcal{A}$ outputs its guess $\beta' \in \{0,1\}$.
    \end{enumerate}
    The output of the game is $1$ if $\beta' = \beta$ and $0$ otherwise and the advantage of $\mathcal{A}$ is defined as $|Pr[\beta' = \beta] - 1/2|$.
\end{itemize}
\subsection{Threshold ElGamal Cryptosystem}
\label{appendix:thrElGamal}
$(t, n)$-threshold ElGamal cryptosystem \cite{desmedt1990Threshold, cherniaeva2019homomorphic} over an Elliptic Curve $E$ defined in field $\mathbb{F}_p$ ($p$ being a very large prime number), and its cyclic subgroup $\mathbb{G} \in E(\mathbb{F}_p)$ with generator $G$ and prime order $q$, is implemented as follows:
\begin{itemize}
    \item $\mathsf{DKG}(1^\lambda, t, n) \rightarrow (\vec{SK}, \vec{PK}, pk)$ runs DKG protocol and generates the common public key $pk$, individual secret keys $\vec{SK}$ and the corresponding individual public keys $\vec{PK}$.
     \item $\mathsf{Enc}(pk, M) \rightarrow (A, B)$  takes as input a point $M \in \mathbb{G}$ and the global public key $pk$ and generates ciphertext $C = (A, B) = (rG, M+D) $ where $D = r \cdot pk$.
     \item $\mathsf{ShareDec}(pk, sk_i, C) \rightarrow \mu_i$ takes ciphertext $C = (A,B)$, the individual secret key $sk_i$ and the global public key $pk$ as input and generates the decrypted share $\mu_i = sk_i \cdot A$.
     \item $\mathsf{Rec}(pk, C, \mu_i, \ldots, \mu_{t+1} ) \rightarrow M$ reconstructs the point $D$ from the public shares $\mu_i, \ldots, \mu_{t+1}$ using Lagrange interpolation and outputs the decrypted message  $M = B - D$.
\end{itemize}

\section{Verifiable Random Function (VRF)}
\label{appendix:vrf}
A VRF \cite{micali1999verifiable,dodis2005verifiable} is a function that, given an input $x$ and a secret key $sk$, generates a unique, pseudorandom output $y$ as well as a proof $\pi$ verifying that the computation has been done correctly. Due to $\pi$, it is possible to repeatedly generate new pseudorandom outputs with one $sk$ and varying inputs in a verifiable manner whereas otherwise (e.g. using a classical pseudorandom function) one needs to divulge the secret key and sacrifice its reusability for public verification purposes. It can be represented by the following tuple of algorithms:
\begin{itemize}
\item $\mathsf{Prove}(sk, x) \rightarrow (F_{sk}(x), \pi_{sk}(x))$ generates the pseudorandom output $F_{sk}(x)$ and its proof of correctness $\pi_{sk}(x)$ given input $x$ and secret key $sk$.
\item $\mathsf{Verify}(pk, x, y, \pi) \rightarrow \{0, 1\}$ outputs 1 if it is verified that $y = F_{sk}(x)$ using the proof $\pi$ and 0 otherwise.
\end{itemize}

Furthermore, a VRF satisfies the following three properties:
\begin{enumerate}
\item Provability. If $(y, \pi) = \mathsf{Prove}(sk, x)$, then the tuple is accepted by the $\mathsf{Verify}$ algorithm such that $\mathsf{Verify}(pk, x, y, \pi) = 1$.
\item Uniqueness. There does not exist $(y_1, \pi_1) \neq (y_2, \pi_2)$ such that $\mathsf{Verify}(pk, x, y_1, \pi_1) = \mathsf{Verify}(pk, x, y_2, \pi_2) = 1$.
\item Pseudorandomness. The output is indistinguishable from a random number from a uniform distribution except with negligible probability. This can be written as follows.
\[
Pr\left[b = b' \middle\vert \begin{array}{l}
(x, st) \leftarrow \mathcal{A}^{\mathsf{Prove}(\cdot)}_{1}(pk);\\
y_0 = F_{sk}(x);\\
y_1 \leftarrow \{0, 1\}^{\ell_{VRF}};\\
b \leftarrow \{0, 1\};\\
b' \leftarrow \mathcal{A}^{\mathsf{Prove}(\cdot)}_{2}(y_b, st)
\end{array}\right] \leq \frac{1}{2} + \mathsf{negl}(\lambda)
\]
for any probabilistic polynomial-time algorithm $\mathcal{A} = (\mathcal{A}_1, \mathcal{A}_2)$, which does not query the oracle on $x$.
\end{enumerate}

\subsection{Verifiable Unpredictable Function (VUF)}
\label{appendix:vuf}
A VUF \cite{micali1999verifiable,dodis2005verifiable} is a VRF except the last property of pseudorandomness is replaced by the following unpredictability property.
\begin{itemize}
\item Unpredictability. The output is unpredictable except with negligible probability. In other words:
\[
Pr\left[y = F_{sk}(x) \middle\vert (x, y) \leftarrow \mathcal{A}^{\mathsf{Prove}(\cdot)}(pk)\right] \leq \mathsf{negl}(\lambda)
\]
for any probabilistic polynomial-time algorithm $\mathcal{A}$, which does not query the oracle on $x$.
\end{itemize}

\subsection{Distributed Verifiable Random Function (DVRF)}
\label{appendix:dvrf}
A DVRF satisfies the following properties (some of which are inherited from what a VRF should satisfy).
\begin{itemize}
\item Provability (Robustness). If $(y, \pi)$ is output by the $\mathsf{Combine}$ algorithm, then it is accepted by the $\mathsf{Verify}$ algorithm.
\item Uniqueness. There does not exist $(y_1, \pi_1) \neq (y_2, \pi_2)$ such that $\mathsf{Verify}(pk, \{pk_i\}, x, y_1, \pi_1) = \mathsf{Verify}(pk, \{pk_i\}, x, y_2, \pi_2) = 1$.
\item Pseudorandomness. An adversary corrupting $t$ nodes cannot distinguish a DVRF output from a uniformly random value except with negligible probability.
\item Consistency. $\mathsf{Combine}(A, \{(y_i, \pi_i)\}_{i \in A})$ should yield the same $y$ for any set $A$ involving $t + 1$ nodes whose outputs of $\mathsf{PartialEval}(sk_i, x)$ are accepted by $\mathsf{PartialVerify}(pk_i, x, y_i, \pi_i)$.
\end{itemize}

\subsection{DDH-DVRF}
\label{appendix:ddh-dvrf}
DDH-DVRF is described by the following DVRF algorithms.
\begin{enumerate}
\item $\mathsf{DKG}(1^\lambda, t, n)$ runs a typical DKG (a la Joint-Feldman or Joint-Pedersen).
\item $\mathsf{PartialEval}(sk_i, x)$ outputs $(y_i, \pi_i)$ where $y_i = H(x)^{sk_i}$ and $\pi_i = \mathsf{DLEQ}(g, g^{sk_i}, H(x), H(x)^{sk_i})$ denoting the Chaum-Pedersen protocol (see Appendix \ref{appendix:dleq}) non-interactively proving that the discrete log involving the first two parameters to $\mathsf{DLEQ}(\cdot)$ is equal to that involving the last two parameters without revealing the discrete logarithm value itself.
\item $\mathsf{PartialVerify}(pk_i, x, y_i, \pi_i)$ is equivalent to $\mathsf{DLEQ}\text{-}\mathsf{Verify}(g, pk_i, H(x), y_i, \pi_i)$ and verifies the correctness of the $\mathsf{PartialEval}$ algorithm using $\pi_i$.
\item $\mathsf{Combine}(A, \{(y_i, \pi_i)\}_{i \in A})$ outputs $(y, \pi)$ where $y = \prod_{i \in A} y_i^{\lambda_{0, i, A}}$ and $\pi = \{(y_i, \pi_i)\}_{i \in A}$. Details related to Lagrange coefficients $\lambda_{0, i, A}$ are included in Appendix \ref{appendix:lagrange}.
\item $\mathsf{Verify}(pk, \{pk_i\}, x, y, \pi)$ verifies all the partial proofs via $\mathsf{PartialVerify}(pk_i, x, y_i, \pi_i)$ for all $i \in A$ from $\pi$ and also verifies $y = \prod_{i \in A} y_i^{\lambda_{0, i, A}}$.
\end{enumerate}

\subsection{GLOW-DVRF}
\label{appendix:glow-dvrf}
Providing a compact proof $\pi$, GLOW-DVRF uses a bilinear pairing $e: \mathbb{G}_1 \times \mathbb{G}_2 \rightarrow \mathbb{G}_T$ similar to BLS such that the setup includes different hash functions $H_1: \{0, 1\}^* \rightarrow \mathbb{G}_1$ and $H_2: \mathbb{G}_1 \rightarrow \{0, 1\}^{y(\lambda)}$. While the following tuple of algorithms generally resembles that of DDH-DVRF, algebraic modifications are made accordingly to reflect the fact that a pairing is used.
\begin{enumerate}
\item $\mathsf{DKG}(1^\lambda, t, n)$ is adapted so that $pk_i$ resides in $\mathbb{G}_1$ while $pk$ resides in $\mathbb{G}_2$. This is achieved by letting $(pk_i, pk) = (g_1^{sk_i}, g_2^{sk})$ for $g_1 \in \mathbb{G}_1$ and $g_2 \in \mathbb{G}_2$. The purpose of this is to facilitate a compact proof in the final $Verify$ step involving a pairing equation.
\item $\mathsf{PartialEval}(sk_i, x)$ outputs $(y_i, \pi_i)$ where $y_i = H_1(x)^{sk_i}$ and $\pi_i = \mathsf{DLEQ}(g_1, g_1^{sk_i}, H_1(x), H_1(x)^{sk_i})$.
\item $\mathsf{PartialVerify}(pk_i, x, y_i, \pi_i)$ is equivalent to $\mathsf{DLEQ}\text{-}\mathsf{Verify}(g_1, pk_i, H_1(x), y_i, \pi_i)$ and verifies the correctness of the $\mathsf{PartialEval}$ algorithm using $\pi_i$.
\item $\mathsf{Combine}(A, \{(y_i, \pi_i)\}_{i \in A})$ outputs $(y, \pi)$ where $\pi = \prod_{i \in A} y_i^{\lambda_{0, i, A}}$ and $y = H_2(\pi)$. Note that $\pi$ is a group element and thus a compact proof.
\item $\mathsf{Verify}(pk, \{pk_i\}, x, y, \pi)$ verifies $y = H_2(\pi)$ and a pairing equation $e(\pi, g_2) = e(H_1(x), pk)$.
\end{enumerate}

\subsection{Dfinity-DVRF}
\label{appendix:dfinity-dvrf}
Dfinity-DVRF is described by the following DVRF algorithms.
\begin{enumerate}
\item $\mathsf{DKG}(1^\lambda, t, n)$ is adapted so that both $pk_i$ and $pk$ reside in $\mathbb{G}_2$. This is achieved by letting $(pk_i, pk) = (g_2^{sk_i}, g_2^{sk})$ for $g_2 \in \mathbb{G}_2$. The purpose of this is to facilitate the check of some pairing equation in both $\mathsf{PartialVerify}$ and $\mathsf{Verify}$.
\item $\mathsf{PartialEval}(sk_i, x)$ outputs $(y_i, \pi_i)$ where $y_i = H_1(x)^{sk_i}$ and $\pi_i = \text{$\perp$}$. The reason for a null proof is that a pairing equation check is used in $\mathsf{PartialVerify}$ (which is the differentiator from GLOW-DVRF) with no need for any auxiliary information.
\item $\mathsf{PartialVerify}(pk_i, x, y_i, \pi_i)$ checks a pairing equation $e(y_i, g_2) = e(H_1(x), pk_i)$.
\item $\mathsf{Combine}(A, \{(y_i, \pi_i)\}_{i \in A})$ is equal to that in GLOW-DVRF.
\item $\mathsf{Verify}(pk, \{pk_i\}, x, y, \pi)$ is equal to that in GLOW-DVRF.
\end{enumerate}

\section{Other Cryptographic Primitives}
\subsection{Commitment Scheme}
\label{appendix:commitment}
A cryptographic commitment \cite{blum1983coin} to message $m$ can be abstractly seen as a secure box (locked with a padlock) whose content is $m$. Initially, the sender $P$ commits to $m$ by putting it inside the box, locking it, and sending it to the receiver $V$ such that $P$ can later open the commitment (i.e. reveal $m$ to $V$) by sending $V$ the key that unlocks the padlock. These two messages can be represented by the following.
\begin{enumerate}
\item $C = \mathsf{Com}(m, r)$ is a commitment to message $m$ with fresh randomness $r$.
\item $\mathsf{Open}(m, r)$ reveals the opening information necessary to verify the validity of $C$ with respect to $m$ and $r$.
\end{enumerate}

Obviously, such secure box needs to be secure, satisfying the following two properties.
\begin{itemize}
\item \textit{Binding property} requires that it is not possible for $P$ to change $m$ after $\mathsf{Com}(m, r)$ is given to $V$.
\item \textit{Hiding property} requires that it is not possible for $V$ to learn $m$ before $\mathsf{Open}(m, r)$ is given to $V$ by $P$.
\end{itemize}

For further details (e.g. perfectly vs computationally binding and hiding), refer to \cite{damgaard1998commitment}.

\subsection{Lagrange Interpolation}
\label{appendix:lagrange}
Given a non-empty reconstruction set $A \subset \mathbb{Z}_q$, the \textit{Lagrange basis polynomials} are given by $\lambda_{j, A}(x) = \prod_{k \in A \setminus \{j\}} \frac{x - k}{j - k} \in \mathbb{Z}_q[X]$ such that the \textit{Lagrange coefficients} $\lambda_{i, j, A} = \lambda_{j, A}(i) \in \mathbb{Z}_q$ enable the equality $p(i) = \sum_{j \in A} p(j) \lambda_{i, j, A}$ for any polynomial $p \in \mathbb{Z}_q[X]$ of degree at most $|A| - 1$. The process of computing this equality is called \textit{Lagrange interpolation}.

\subsection{BLS Signature}
\label{appendix:bls}
Introduced by Boneh, Lynn, and Shacham in 2003, the BLS signature scheme \cite{boneh2001short} consists of the following tuple of algorithms given a key pair ($sk$, $pk$).
\begin{enumerate}
\item $\mathsf{Sign}_{sk}(m) \rightarrow H_1(m)^{sk}$ outputs a digital signature $\sigma = H_1(m)^{sk}$ given secret key $sk$ and message $m$ where $H_1$ is a hash function such that $H_1: \{0, 1\}^* \rightarrow \mathbb{G}_1$.
\item $\mathsf{Verify}_{pk}(m, \sigma) \rightarrow \{0, 1\}$ verifies a signature given signature $\sigma$, message $m$, and public key $pk$. The test checks the equality $e(\sigma, g_2) = e(H_1(m), pk)$.
\end{enumerate}
Note that BLS uses a bilinear pairing $e: \mathbb{G}_1 \times \mathbb{G}_2 \rightarrow \mathbb{G}_T$ with $\mathbb{G}_1 = \langle g_1 \rangle$, $\mathbb{G}_2 = \langle g_2 \rangle$, $\mathbb{G}_T$ denoting a cyclic group of prime order $q$, and the following requirements.
\begin{itemize}
\item Bilinearity. $e(g_1^x, g_2^y) = e(g_1, g_2)^{x y}$ for all $x, y \in \mathbb{Z}^*_q$.
\item Non-degeneracy. $e(g_1, g_2) \neq 1$.
\item Computability. $e(g_1, g_2)$ can be efficiently computed.
\end{itemize}

\subsection{NIZK of Discrete Logarithm Equality (DLEQ)}
\label{appendix:dleq}
Also known as the Chaum-Pedersen protocol \cite{chaum1992wallet}, the $\Sigma$ protocol for proving that the two discrete logarithms are equal without revealing the discrete logarithm value itself can be turned into a NIZK by applying the Fiat-Shamir heuristic \cite{fiat1986prove}. Namely, the prover can non-interactively prove the knowledge of $\alpha$ such that $(h_1, h_2) = (g_1^\alpha, g_2^\alpha)$ via $\pi_{DLEQ} = \mathsf{DLEQ}(g_1, h_1, g_2, h_2)$ with group elements in $\mathbb{G}_q$ of prime order $q$.\\

\noindent\underline{$\mathsf{DLEQ}(g_1, h_1, g_2, h_2)$}\\
\textit{Input:} $g_1, h_1, g_2, h_2 \in \mathbb{G}_q$, $\alpha \in \mathbb{Z}_q$\\
\textit{Output:} $\pi = (e, s)$
\begin{enumerate}
\item $A_1 = g_1^w, A_2 = g_2^w$ for $w \xleftarrow{R} \mathbb{Z}_q$
\item $e = H(h_1, h_2, A_1, A_2)$
\item $s = w - \alpha \cdot e \pmod q$
\item $\pi = (e, s)$
\end{enumerate}

\noindent\underline{$\mathsf{DLEQ}\text{-}\mathsf{Verify}(g_1, h_1, g_2, h_2, \pi)$}\\
\textit{Input:} $g_1, h_1, g_2, h_2 \in \mathbb{G}_q$, $\pi = (e, s)$\\
\textit{Output:} $b \in \{0, 1\}$
\begin{enumerate}
\item $A'_1 = g_1^s h_1^e, A'_2 = g_2^s h_2^e$
\item $e' = H(h_1, h_2, A'_1, A'_2)$
\item $b = \begin{cases}
1 & \text{if $e' = e$}\\
0 & \text{otherwise}
\end{cases}$
\end{enumerate}

\subsection{NIZK of Correct ElGamal Encryption (CE)}
\label{appendix:ce}
Via $\pi_{CE} = \mathsf{CE}(G, Q, A, B)$ \cite{cherniaeva2019homomorphic} where $G \in \mathbb{G}_q$ of prime order $q$ and $(Q, A, B) = (x G, r G, m G + r Q)$, the prover can non-interactively prove the knowledge of $(m, r)$ and thus prove the legitimacy of an ElGamal encryption (e.g. as opposed to exploiting its malleability). Note that the additive notation is used to reflect the usage of points on an elliptic curve.\\

\noindent\underline{$\mathsf{CE}(G, Q, A, B)$}\\
\textit{Input:} $G, Q, A, B \in \mathbb{G}_q$, $m, r \in \mathbb{Z}_q$\\
\textit{Output:} $\pi = (e, z_1, z_2)$
\begin{enumerate}
\item $T = s_1 G + s_2 Q, E = s_2 G$ for $s_1, s_2 \xleftarrow{R} \mathbb{Z}_q$
\item $e = H(A, B, T, E)$
\item $z_1 = s_1 + m \cdot e \pmod q, z_2 = s_2 + r \cdot e \pmod q$
\item $\pi = (e, z_1, z_2)$
\end{enumerate}

\noindent\underline{$\mathsf{CE}\text{-}\mathsf{Verify}(G, Q, A, B, \pi)$}\\
\textit{Input:} $G, Q, A, B \in \mathbb{G}_q$, $\pi = (e, z_1, z_2)$\\
\textit{Output:} $b \in \{0, 1\}$
\begin{enumerate}
\item $T' = z_1 G + z_2 Q - e B, E' = z_2 G - e A$
\item $e' = H(A, B, T', E')$
\item $b = \begin{cases}
1 & \text{if $e' = e$}\\
0 & \text{otherwise}
\end{cases}$
\end{enumerate}

\begin{table*}[pt]
\aboverulesep=0ex
\belowrulesep=0ex
% \footnotesize
\renewcommand{\arraystretch}{1}
\begin{threeparttable}
\caption{Subset-Based DRB Protocols}
\label{table:subset-based}
\begin{tabularx}{\textwidth}{|c|c|c|l|l|}
\cmidrule{4-5}
\multicolumn{3}{c|}{} & \multicolumn{2}{c|}{Step 2: Beacon Output Generation} \\
\cmidrule{4-5}
\multicolumn{3}{c|}{} & \multicolumn{1}{c|}{Fresh per-node entropy} & \multicolumn{1}{c|}{$\mathcal{O}_{r - 1}$ \& precommitted per-node entropy} \\
\cmidrule{1-5}
\multirow{5}{*}{\spheading[0.425\textwidth]{\mbox{Step 1: Subset Selection}}} & \multirow{3}{*}[-2.8cm]{Public} & RR & \begin{tabular}{@{}l@{}}\textbf{BRandPiper}\\\textit{Step 1}: Node $i \equiv r \pmod n$\\\textit{Step 2}: Share-aggregate-reconstruct\end{tabular} & \\
\cmidrule{3-5}
& & RS & \begin{tabular}{@{}l@{}}\textbf{Ouroboros}\\\textit{Step 1}: Follow-the-satoshi \cite{bentov2014proof,kiayias2017ouroboros}\\\textit{Step 2}: Share-reconstruct-aggregate\end{tabular} & \begin{tabular}{@{}l@{}}\textbf{HydRand}\\\textit{Step 1}: Node $i \equiv \mathcal{O}_{r - 1} \pmod{\tilde{n}}$\\\textit{Step 2}: $\mathcal{O}_r = H(\mathcal{O}_{r - 1} \mathbin\Vert h^{e_{\tilde{r}}})$\\\\\textbf{GRandPiper}\\\textit{Step 1}: Node $i \equiv \mathcal{O}_{r - 1} \pmod{\tilde{n}}$\\\textit{Step 2}: $\mathcal{O}_r = H(h^{e_{\tilde{r}}}, \mathcal{O}_{r - 1}, ..., \mathcal{O}_{r - t})$\end{tabular} \\
\cmidrule{3-5}
& & LS & \begin{tabular}{@{}l@{}}\textbf{RandHound}\\\textit{Step 1}: Node $\argmin_{i} H(C \mathbin\Vert pk_i)$\\\textit{Step 2}: Share-reconstruct-aggregate\\\\\textbf{SPURT}\\\textit{Step 1}: Node $i \equiv r \pmod n$\\\textit{Step 2}: Share-aggregate-reconstruct\end{tabular} & \\
\cmidrule{2-5}
& \multirow{2}{*}[-0.6cm]{Private} & VRF & \begin{tabular}{@{}l@{}}\textbf{NV++}\\\textit{Step 1}: $VRF_{sk}(\mathcal{O}_{r - 1} \mathbin\Vert nonce) < target$\\\textit{Step 2}: Threshold ElGamal\end{tabular} & \begin{tabular}{@{}l@{}}\textbf{Algorand}\\\textit{Step 1}: $VRF_{sk}(\mathcal{O}_{r - 1} \mathbin\Vert role) < target$\\\textit{Step 2}: $\mathcal{O}_r = VRF_{sk}(\mathcal{O}_{r - 1} \mathbin\Vert r)$\\\\\textbf{Ouroboros Praos}\\\textit{Step 1}: $VRF_{sk}(\mathcal{O}_{r - 1} \mathbin\Vert slot \mathbin\Vert \mathsf{TEST}) < target$\\\textit{Step 2}: $\mathcal{O}_r = H(\mathcal{O}_{r - 1} \mathbin\Vert epoch \mathbin\Vert \rho_1 \mathbin\Vert ... \mathbin\Vert \rho_K)$\end{tabular} \\
\cmidrule{3-5}
& & Hash chain & & \begin{tabular}{@{}l@{}}\textbf{Caucus}\\\textit{Step 1}: $H(h_r \oplus \mathcal{O}_{r - 1}) < target$\\\textit{Step 2}: $\mathcal{O}_r = h_r \oplus \mathcal{O}_{r - 1}$\end{tabular} \\
\cmidrule{1-5}
\end{tabularx}
\begin{tablenotes}[para,flushleft]
\item Note that public subset selection mechanisms (Section \ref{subsubsection:public-subset-selection}) include RR (round-robin), RS (random selection), and LS (leader-based selection) while details regarding private subset selection can be found in Section \ref{subsubsection:private-subset-selection}. For details on the two columns under beacon output generation, see Sections \ref{subsubsection:fresh} and \ref{subsubsection:precommitted}. Details on notation and beacon output generation process can be found in Section \ref{subsection:beacon-output-generation}.
\end{tablenotes}
\end{threeparttable}
\end{table*}

\begin{table*}[pt]
% \footnotesize
\scriptsize
\begin{threeparttable}
\caption{DRB Comparison}
\label{table:comparison}
\begin{tabularx}{\textwidth}{@{} l *{20}c}
% \begin{tabularx}{\textwidth}{@{} l *{20}{@{\phantom{x}}c@{\phantom{x}}}}
\toprule
\spheading{} & \spheading{Section\\(from paper)} & \spheading{Cryptographic Primitive}   & \spheading{Fault Tolerance (less than)}  & \spheading{Independent Participation}  & \spheading{Per-Round Entropy Provider}  & \spheading{Unpredictability}  & \spheading{Immunity to Withholding}  & \spheading{Adaptive Security}   & \spheading{Verifier Complexity}  & \multicolumn{2}{c}{\spheading{Communication Complexity}}  &  \spheading{Damage}  & \spheading{Recovery Cost}\\ 
\cmidrule{11-12}
 & & & & & & & & & & Optimistic & Worst & & \\
\toprule
Commit-Reveal & \hyperref[subsection:commit-reveal]{2} & Commitment  &  1  & \cmark   & All   &  \xmark  & \xmark    & \cmark   & $O(n)$  & $O(n^3)$   & $O(n^3)$  & Bias & $O(1)$ \\ 
\midrule
Unicorn++ & \multirow{3}{*}{\ref{section:vdf}} & VDF  & $n$   & \cmark   & All   & 1   & \cmark    & \cmark   & $O(n)$  & $O(n^3)$   & $O(n^3)$  & None & $O(1)$ \\ 
Ext. Beacon+VDF &  & VDF  &  $n$  & \cmark  & External   & 1   & \cmark    & \cmark   & $O(1)$  &  $O(n)$  & $O(n)$  & None & $O(1)$ \\ 
RandRunner &  & Trapdoor VDF  & $n$   & \xmark   & None   & $t$   & \cmark    & \cmark   & $O(\log T)$  & $O(n^2)$   & $O(n^2)$  & Predict & $O(n^3)$ \\ 
\midrule
RANDAO & \multirow{2}{*}{\ref{section:commit-reveal-punish}} & Commitment  & $n$   & \cmark    & All   & 1   & \cmark    & \cmark   & $O(n)$  & $O(n)$   & $O(n)$  & Halt & $O(n)$ \\ 
EVR &  & Escrow-DKG & $n/3$   & \xmark   & All   & 1   & \cmark    & \cmark   & $O(n^3)$  & $O(n^2)$   & $O(n^3)$  & Halt & $O(n)$ \\ 
\midrule
Scrape & \multirow{5}{*}{\ref{section:commit-reveal-recover}} & PVSS  & $n/2$   & \xmark   & All   & 1   & \cmark    & \cmark   & $O(n^2)$  & $O(n^3)$   & $O(n^4)$  & Predict & $O(n^2)$ \\ 
Albatross &  & PVSS & $n/2$   & \xmark   & All   & 1   & \cmark    & \cmark   & $O(n^2)$  & $O(n)$   & $O(n^2)$  & Predict & $O(n^2)$ \\ 
RandShare &  & PVSS & $n/3$   & \xmark   & All   & 1   & \cmark    & \cmark   & $O(n^3)$  & $O(n^3)$   & $O(n^4)$  & Predict & $O(1)$ \\ 
SecRand &  & PVSS &  $n/2$  & \xmark   & All   & 1   & \cmark    & \cmark   & $O(n^2)$  & $O(n^3)$   & $O(n^4)$  & Predict & $O(n^2)$ \\ 
HERB &  & Thr. ElGamal & $n/3$   & \xmark   & All   & 1   & \cmark    & \cmark   & $O(n)$  & $O(n^3)$   & $O(n^3)$  & Predict & $O(n^3)$ \\ 
\midrule
HydRand & \multirow{10}{*}{\ref{section:subset-based}} & PVSS & $n/3$   & \xmark   & Leader   & $t$   & \cmark    & \xmark   & $O(n)$  & $O(n^2)$   & $O(n^3)$  & Bias & $O(n^2)$ \\ 
GRandPiper &  & PVSS  & $n/2$   & \xmark   & Leader   & $t$   & \cmark    & \xmark   & $O(n^2)$  & $O(n^2)$   & $O(n^2)$  & Bias & $O(n^2)$ \\ 
BRandPiper &  & PVSS  & $n/2$   & \xmark   & Leader   & 1   & \cmark    & \cmark   & $O(n^2)$  & $O(n^2)$   & $O(n^3)$  & Predict & $O(n^2)$ \\ 
Ouroboros &  & PVSS & $n/2$   & \xmark   & Subset   & 1   & \cmark    & \xmark   & $O(n^3)$  & $O(n^4)$   & $O(n^4)$  & Bias & $O(n^2)$ \\ 
RandHound &  & PVSS & $n/3$   & \xmark   & Subset   & 1   & \xmark    & \xmark   & $O(c^2 n)$  & $O(c^2n)$   & $O(c^2n)$  & Bias & $O(n^2)$ \\ 
SPURT &  & PVSS  & $n/3$   & \xmark   & Subset   & 1   & \cmark    & \cmark   & $O(n)$  & $O(n^2)$   & $O(n^2)$  & Bias & $O(n^2)$ \\ 
Algorand &  & VRF  & $n/3$   & \cmark    & Leader   & $t$   & \xmark    & \cmark   & $O(1)$  & $O(cn)$   & $O(cn)$  & Bias & $O(n^2)$ \\ 
Ouroboros Praos &  & VRF & $n/2$   & \cmark    & Subset   & 1   & \xmark    & \cmark   & $O(1)$  & $O(n)$   & $O(n)$  & Bias & $O(n^2)$ \\ 
Caucus &  & Hash chain &  $n/2$  & \cmark    & Leader   & $t$   & \xmark    & \cmark   & $O(1)$  & $O(n^2)$   & $O(n^2)$  & Bias & $O(n^3)$ \\ 
NV++ &  & VRF, thr. ElGamal &  $n$  & \xmark   & Subset   & $1$   & \xmark    & \cmark   & $O(n)$  & $O(n^3)$   & $O(n^3)$  & Bias & $O(n^2)$ \\ 
\midrule
drand & \multirow{4}{*}{\ref{section:dvrf}} & Thr. BLS & $n/2$   & \xmark   & None   & 1   & \cmark    & \cmark   & $O(1)$  & $O(n^2)$   & $O(n^2)$  & Predict & $O(n^3)$ \\ 
RandHerd &  & Thr. Schnorr & $n/3$   & \xmark   & None   & 1   & \xmark    & \xmark   & $O(1)$  & $O(c^2 \log n)$   & $O(n^3)$  & Bias & $O(n^3)$ \\ 
DDH-DRB &  & DDH-based DVRF  & $n/2$ & \xmark   & None   & 1   & \cmark    & \cmark   & $O(1)$  & $O(n^2)$   & $O(n^2)$  & Predict & $O(n^3)$ \\ 
GLOW-DRB &  & Pairing-based DVRF  & $n/2$ & \xmark   & None   & 1   & \cmark    & \cmark   & $O(1)$  & $O(n^2)$   & $O(n^2)$  & Predict & $O(n^3)$ \\ 
\bottomrule
\end{tabularx}
\begin{tablenotes}[flushleft]
\item $c$ is the size of shards in RandHerd and RandHound and the size of committee in Algorand. Unlike Algorand, $c$ in RandHound/RandHerd depends on $n$ and is not constant.
\item $T$ is the delay parameter for VDF.
\end{tablenotes}
\end{threeparttable}
\end{table*}

\end{document}