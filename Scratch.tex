\documentclass[conference]{IEEEtran}
% \documentclass[letterpaper,twocolumn,10pt]{article}
% \usepackage{usenix-2020-09}
% \usepackage[backend=bibtex,sortcites]{biblatex}
% \addbibresource{bib.bib}
\bibliographystyle{IEEEtranS}
\usepackage[noadjust]{cite}
% Language and font encodings
% \usepackage[english]{babel}
% \usepackage[utf8]{inputenc}

% Sets page size and margins
% \usepackage[letterpaper,margin=1.5in]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage[hidelinks]{hyperref}
\usepackage{seqsplit}
\usepackage{indentfirst}
\usepackage{tabu}
\usepackage{lipsum}
\usepackage{array}
\usepackage{tocloft}
\usepackage{float}
\usepackage[font=small,labelfont=bf]{caption}
\usepackage{etoolbox}
\usepackage{setspace}
\usepackage{braket}
\usepackage{enumitem}
% start table
\usepackage{tabularx,booktabs,multirow}
\usepackage{diagbox}
\newcolumntype{C}{>{\centering\arraybackslash}X} % centered version of "X" type
\setlength{\extrarowheight}{1pt}
\newcommand{\spheading}[2][7em]{ % \spheading[<width>]{<stuff>}
    \rotatebox{90}{\parbox{#1}{\raggedright #2}}}
\usepackage{pifont} % http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}
\usepackage{threeparttable}
\DeclareMathOperator*{\argmin}{argmin}
% end table
\AtBeginEnvironment{quote}{\singlespace\vspace{1em}\small}
\AtEndEnvironment{quote}{\vspace{1em}\endsinglespace}
\renewcommand{\arraystretch}{1.5}
\tabulinesep = 2mm
% \setlist[itemize]{wide=0.5\parindent,itemsep=0pt,parsep=0pt}
% \setlist[enumerate]{wide=0.5\parindent,itemsep=0pt,parsep=0pt}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{notes}{Notes}
\renewcommand\qedsymbol{$\blacksquare$}

\usepackage{color}
\newcommand{\todo}[1]{\textcolor{red}{\textbf{TODO:} #1}}
\newcommand{\joenote}[1]{\textcolor{blue}{\textbf{JOE:} #1}}
\newcommand{\kevinnote}[1]{\textcolor{green}{\textbf{KEVIN:} #1}}
\newcommand{\aathiranote}[1]{\textcolor{purple}{\textbf{AATHIRA:} #1}}

\title{SoK: Distributed Randomness Beacons}
% \author{
% {\rm Kevin Choi}\\
% New York University
% \and
% {\rm Aathira Manoj}\\
% New York University
% }
% \date{Spring 2021}

\begin{document}

\maketitle
\thispagestyle{plain}
\pagestyle{plain}
% \tableofcontents
\begin{abstract}
    Motivated and inspired by the emergence of Proof of Stake blockchains, many new protocols have recently been proposed for generating publicly verifiable randomness in a distributed yet secure fashion. These protocols work under different setups and assumptions, use various cryptographic tools, and entail unique tradeoffs and characteristics. In this paper, we systematize the design of distributed randomness beacons (DRBs). We separate two components: selection of entropy providers and randomness generation. We evaluate protocols on four key security properties---unbiasability, unpredictability, liveness, and public verifiability---and discuss common attack vectors for predicting or biasing the beacon output and the countermeasures employed by protocols. We also evaluate protocols by communication and computational efficiency.
    %We start by delving into protocols where every node plays an active role contributing to the final randomness. Next, we provide an overview of techniques used to select and generate the randomness with only a subset of active nodes to improve scalability. However, this may come at the cost of diminished quality of randomness or vulnerability to biasing by an adversary.
    %We then discuss some attack vectors for predicting or biasing the beacon and the countermeasures employed by protocols.
    Finally, we provide insights on the applicability of different protocols in various deployment scenarios and highlight possible directions for further research.
\end{abstract}

\section{Introduction}
Public, trustworthy randomness has been a useful tool for millennia, dating at least to the earliest known use of dice around 3000 BCE. Today, periodic public randomness is crucial to applications including gambling and lotteries \cite{bonneau2015bitcoin}, sampling ballots for election audits \cite{adida2008helios}, selecting parameters for cryptographic protocols \cite{baigneres2015trap, lenstra2015random}, leader election in Proof of Stake protocols \cite{gilad2017algorand, kiayias2017ouroboros}, and blockchain sharding \cite{al2017chainspace, kokoris2018omniledger}. The concept of a \emph{randomness beacon} was first formalized by Rabin \cite{rabin1983Rabin} to describe an ideal service that emits fresh random numbers at regular intervals in a way that no party can manipulate. Because no such ideal beacon exists, various protocols are used to approximate this beacon functionality for practical use.
%solutions ranging from centralized approaches (relying on a single source or organization) to distributed approaches (decentralizing the randomness generation among a set of nodes) are used to approximate it.

\textbf{Centralized Beacons.} Relying on a trusted third party like NIST \cite{fischer2011public} or random.org \cite{haahr2010random} might be the simplest way to realize a beacon. It carries drawbacks typically associated with centralized services, such as the risk of compromise or misbehavior and the inability of the end user to verify the correctness of the beacon.
%For this reason, it is strongly desirable to construct a beacon with no trusted party or central point of failure.

\textbf{Public Implicit Beacons.} Another approach is to construct a beacon using publicly available implicit sources of entropy such as stock market data \cite{clark2010use} or Proof of Work (PoW) blockchains like Bitcoin \cite{nakamoto2008bitcoin, bentov2016bitcoin,bonneau2015bitcoin, han2020randchain}. However, these entropy sources are potentially vulnerable to malicious insiders (e.g. high-frequency traders making unnatural trades to fix stock prices, financial exchanges blocking trades or reporting incorrect data, miners that can withhold blocks or choose between colliding blocks, etc.). The entropy of these sources can also be difficult to precisely measure. While potentially secure and low-cost in practice, we will not discuss these approaches in detail in this survey.

\textbf{Distributed Randomness Beacons.}
A natural approach to reduce complete trust in a centralized beacon is to use a distributed beacon protocol capable of gracefully handling a minority of Byzantine participants and a potentially untrusted network. We call a beacon realized in this manner a \textit{distributed randomness beacon} (DRB). DRB protocols are typically round-based, producing a fresh random output in each round.

\textbf{Contribution.} The goal of the paper is to systematize the current progress on DRBs specifically. We propose a generalized framework encompassing all distributed randomness protocols in the landscape. To aid comparison and discussion of properties, we provide an overview of these protocols along with the various cryptographic building blocks used to construct them. We identify two key components of DRB design: selection of entropy providers and beacon output generation, which can be decoupled from each other. Enabling a more holistic analysis of a DRB as a result, we also provide new insights and discussion on potential attack vectors, countermeasures, and techniques that lead to better scalability.

\textbf{Paper organization.} We begin with preliminaries including our system model, a strawman DRB under perfect synchrony (an ideal assumption), commit-reveal \cite{blum1983coin}, and the definition of an ideal DRB in Section \ref{section:preliminaries}. Section \ref{section:vdf} introduces protocols using verifiable delay functions \cite{boneh2018verifiable}, which (assuming secure VDFs can be realized) offer the best security and simplicity. Then from Section \ref{section:commit-reveal-punish} to \ref{section:dvrf}, we introduce non-VDF-based DRB protocols based on the number of nodes contributing \textit{marginal entropy} (i.e. per-round randomness that is independently generated at a node level) in each round. Sections \ref{section:commit-reveal-punish} and \ref{section:commit-reveal-recover} review protocols in which all nodes contribute marginal entropy. These protocols vary in mechanisms used to recover from faulty nodes, including financial punishment \cite{youcai2017randao, david2020economically}, threshold secret sharing \cite{schoenmakers1999simple, cascudo2017scrape}, and threshold encryption \cite{desmedt1990Threshold}. Section \ref{section:committee-based} covers committee-based protocols in which each round includes an extra committee selection step, after which only a committee (non-empty proper subset) of nodes contributes marginal entropy. These protocols are more complex but can offer greater communication efficiency with large numbers of nodes. Section \ref{section:dvrf} covers pseudorandom protocols that do not require any marginal entropy; these protocols can be highly efficient but have no mechanism to recover from compromise. We conclude with discussion and comparisons in Sections \ref{section:discussion}--\ref{section:conclusion}, including a comparison of all studied protocols in Table~\ref{table:comparison}.

\section{Preliminaries}
\label{section:preliminaries}
We delineate the necessary preliminaries in this section, starting with the description of our system model (including threat model) relevant in all protocols portrayed in this paper (unless stated otherwise). We then introduce a strawman DRB assuming a perfectly synchronous network (with zero latency) as well as the classical commit-reveal \cite{blum1983coin}. Identifying problems in both, we define the security of an ideal DRB.

\subsection{System Model}
We consider a system model with $\mathcal{P} = \{P_1, P_2, ..., P_n\}$ comprising $n$ participants (called nodes), also often denoted by $\mathcal{P} = \{1, 2, ..., n\}$ for the purpose of algebraic formulations without loss of generality. Out of $n$, up to $t$ faulty nodes (deemed \textit{Byzantine}) may engage in incorrect (arbitrary) behavior during a protocol run, and an adversary $\mathcal{A}$ that controls up to $t$ such nodes is called \textit{$t$-limited}. Otherwise, nodes that are \textit{honest} abide by the specified protocol.

We assume a standard public key infrastructure (PKI) such that all nodes know each others' public keys, and that all nodes are connected via point-to-point secure (providing authenticity) communication channels. All messages exchanged by honest nodes are digitally signed by the sender, and recipients always validate each message before proceeding. By default, we assume a \textit{synchronous} network, in which there exists some known finite message delay bound $\Delta$. This means that an adversary can delay a message by at most $\Delta$.

Moreover, we assume a computationally bounded adversary $\mathcal{A}$ runs in PPT (probabilistic polynomial time) and that $\mathcal{A}$ cannot break standard cryptographic constructions such as hash functions, digital signatures, etc. The three ways in which $\mathcal{A}$ can deviate from a protocol are omitting a message (i.e. \textit{withholding attack}), sending invalid messages, and colluding to coordinate an attack based on private information shared among Byzantine nodes. Additionally, $\mathcal{A}$ has the power to perform a \textit{grinding attack}, in which $\mathcal{A}$ privately precomputes and iterates through as many combinations of inputs to an algorithm as possible in order to derive a desirable output. By default, we assume a \textit{static} adversary that chooses nodes to be corrupted before a protocol run whereas an \textit{adaptive} adversary can choose nodes to be corrupted at any time during a protocol run (although we assume a model where nodes remain corrupted once corrupted).

We denote our computational model's security parameter by $\lambda$. We call a function $negl(\lambda)$ \textit{negligible} if for all $c > 0$ there exists a $\lambda_0$ such that $negl(\lambda) < \frac{1}{\lambda^c}$ for all $\lambda > \lambda_0$. The group elements $g, h \in \mathbb{G}$ are generators of $\mathbb{G}$ while $p, q$ denote primes where $q \mid p - 1$ (unless stated explicitly) such that $\mathbb{G}_q$ is a group of prime order $q$. The notation $tuple[0]$ denotes the first element of $tuple$. Furthermore, we model any hash function $H(\cdot)$ as a random oracle. In the context of a distributed randomness beacon, we use $r$ to denote round number and $\mathcal{O}_r$ to denote the \textit{beacon output} (i.e. the distributed randomness output) in round $r$. The \textit{entropy-providing committee} denoted by $\mathcal{C}_r$ refers to a non-empty proper subset of nodes (hereafter called \textit{entropy providers}) that proactively generate and provide marginal entropy in round $r$. $\mathcal{C}_r$ can include all nodes, some but not all nodes, one node (i.e. a leader), or no node.

\subsection{Strawman Protocol: Rock-Paper-Scissors}
Distributed randomness assuming perfect synchrony is straightforward. Consider the following one-round ``rock-paper-scissors'' protocol where each participant $i$ broadcasts its \textit{entropy contribution} (i.e. independently generated randomness) $e_i \in \mathbb{Z}_p$ to every other participant at the same time as per simultaneity observed (say) in rock-paper-scissors. Naturally, its protocol output $\mathcal{O}$ (via addition in a finite group) can be given by
\[
\mathcal{O} = \sum_{i = 1}^n e_i
\]
such that applying this mechanism $\tilde{r}$ times at $\tilde{r}$ chronological timestamps would yield a DRB.
% \joenote{Round notation not introduced yet?}

This protocol is simple and, under a perfect synchrony assumption, is secure as long as any single participant chooses its $e_i$ randomly. However, security falls apart completely once messages can be delayed.
%assumption is never true. In fact, situations can change dramatically in a practical setting where participants can go offline (perhaps temporarily) due to network failure, messages can be delayed either non-significantly or significantly, and Byzantine attackers can try to predict or bias the randomness to their benefit.
Consider a simple scenario with three participants $\{P_1, P_2, P_3\}$ participating to produce $\mathcal{O} = e_1 + e_2 + e_3$. If $P_3$ can read $e_1$ and $e_2$ before sending $e_3$ (due to non-zero message latency) to $P_1$ and $P_2$, then $P_3$ can fix the output $\mathcal{O}$ to any value $\tilde{\mathcal{O}}$ by choosing $e_3 = \tilde{\mathcal{O}} - e_1 - e_2$. Effectively, the protocol cannot tolerate any Byzantine participants without perfect synchrony.

\subsection{Commit-Reveal}
\label{subsection:commit-reveal}
A classic fix for the above issue is to introduce a cryptographic commitment step before each party reveals its entropy contribution.
\begin{enumerate}
\item \underline{Commit}. Each participant $P_i$ broadcasts a cryptographic commitment $C_i = \mathsf{Com}(e_i, r_i)$ (with fresh randomness $r_i$) to its entropy contribution $e_i$ rather than $e_i$ itself. Note that $\mathsf{Com}(x, r_0)$ denotes a cryptographic commitment to $x$ with hiding and binding properties \cite{blum1983coin,damgaard1998commitment}.
\item \underline{Reveal}. Once all participants have shared their corresponding commitments, each participant $P_i$ then opens its commitment by revealing the pair $(e_i, r_i) = \mathsf{Open}(e_i, r_i)$. In turn, $P_i$ verifies each received pair $(e_j, r_j)$ for $j \neq i$ by recomputing $C_j = \mathsf{Com}(e_j, r_j)$. Given that these checks pass, the final output $\mathcal{O}$ can canonically be given by
\[
\mathcal{O} = \sum_{i = 1}^n e_i
\]
all of which can be repeated to produce a DRB. If any of the checks do not pass, however, the protocol aborts.
\end{enumerate}

With the additional commit step, it becomes impossible for any participant to manipulate the output $\mathcal{O}$, as their values are bound by commitments published before any participants reveal. Nonetheless, the protocol can still be biased, as the last participant $P_k$ to reveal can in fact compute $\mathcal{O}$ earlier than others and hence can decide not to reveal $(e_k, r_k)$ if $\mathcal{O}$ is not to its liking. This is called the \textit{last revealer attack}. Note that this attack is indistinguishable from a faulty node going offline, and indeed the protocol also has no robustness against non-Byzantine faults in this basic form.

\subsection{Ideal Distributed Randomness Beacon}
Clearly, a DRB should prevent any one participant from tampering with (e.g. predicting, biasing, or aborting) each round's output. The beacon output should also be verifiable by any third party. Based on these requirements, the overall security properties of an ideal DRB are given by the following.

\begin{definition}[Ideal distributed randomness beacon]
A distributed randomness beacon is \textit{ideal} or \textit{secure} if it satisfies the following four properties.
\begin{enumerate}
\item Bias Resistance (or Unbiasability). No PPT adversary $\mathcal{A}$ can bias any $c$ bits of $\mathcal{O}_r$. In other words, $\mathcal{A}$ cannot force $c$ bits of $\mathcal{O}_r$ to be some arbitrarily chosen bits with probability greater than $\frac{1}{2^c} + negl(\lambda)$.
\item Unpredictability. Similarly, $\mathcal{A}$ cannot predict any $c$ bits of $\mathcal{O}_r$ with probability greater than $\frac{1}{2^c} + negl(\lambda)$. The protocol satisfies \textit{$d$-unpredictability} \cite{bhat2020randpiper} for $d \in \mathbb{N}$ if this is true for any round greater than or equal to $r + d$ (where $r$ denotes the current round).
\item Liveness. A la game-based security, we can define liveness \cite{guo2020secRand} by requiring that the advantage of $\mathcal{A}$ denoted by $Pr[\mathcal{O}_r = \text{$\perp$}]$ (i.e. the probability that the honest beacon output at the end of round $r$ is null) is negligible, given a DRB that runs among honest participants and $\mathcal{A}$.
\item Public Verifiability. Any third party should be able to verify the beacon output based on public information. See Appendix \ref{appendix:pv} for a game-based formulation.
\end{enumerate}
\end{definition}

We next begin our discussion of various approaches to realizing an ideal DRB, starting with protocols based on verifiable delay functions.

\section{VDF-Based Protocols}
\label{section:vdf}
One way to prevent the last revealer attack is to add a delay function after collecting each node's entropy contribution, delaying the derivation of $\mathcal{O}_r$. As long as the delay is suitably long, no participant can predict what effect their contribution will have on the output before their share must be published. A verifiable delay function (VDF) \cite{boneh2018verifiable,boneh2018survey} can be used to accomplish this.

\begin{definition}[Verifiable delay function]
A \textit{verifiable delay function} (VDF) is a function that takes a specified number of sequential steps to compute (even with a large amount of parallelism available) but takes exponentially less time to verify once computed. It can be described by the following algorithms.
\begin{itemize}
\item $\mathsf{Setup}(\lambda, T) \rightarrow pp$ is a randomized algorithm that outputs public parameters $pp$ given security parameter $\lambda$ and time bound $T$.
\item $\mathsf{Eval}(pp, x) \rightarrow (y, \pi)$ outputs $y$ in $T$ sequential steps and a proof $\pi$ given $pp$ and an input $x$.
\item $\mathsf{Verify}(pp, x, y, \pi) \rightarrow \{0, 1\}$ outputs 1 if $y$ is the correct evaluation of the VDF on input $x$ and 0 otherwise.
\end{itemize}
\end{definition}

The two well-known VDF proposals, one due to Pietrzak \cite{pietrzak2018simple} and the other due to Wesolowski \cite{wesolowski2019efficient}, make use of the (believed) inherently sequential nature of repeated squaring in a group of unknown order.
VDFs can be used to derive unbiasable randomness either from existing, biasable protocols (e.g. commit-reveal or public implicit beacons) or as the building block for an entirely new protocol (like RandRunner \cite{schindler2021randrunner}).

\subsection{Modifying Commit-Reveal}
\label{subsection:modifying-commit-reveal}
The Unicorn protocol~\cite{lenstra2015random} proposed using the Sloth function (a VDF precursor based on computing square roots modulo a prime) in a manner similar to commit-reveal. In fact, commitments are no longer needed, participants simply publish their entropy contributions directly. Unicorn can be improved using a VDF in place of Sloth to achieve an exponential gap between computation and verification times. We refer to this VDF-based Unicorn as \textit{Unicorn++}. 
%In Unicorn++ (as well as Unicorn), participants can skip the commit step and send their contributions directly. 
It runs as follows.
\begin{enumerate}
    \item \textbf{Collect.} Every participant $P_i$ broadcasts its entropy contribution $e_i$ between time $t_1$ and $t_2$ (assuming synchronized clocks). At $t_2$, they are combined into $seed_r = H(e_1,\ldots, e_n)$.
    \item \textbf{Evaluate.} Some party evaluates the VDF with $seed_r$ and a chosen delay parameter $T$ (part of $pp$) via
    $$y_r, \pi_r = \mathsf{VDF.Eval}(pp, seed_r)$$
    such that $\mathcal{O}_r = H(y_r)$, which is posted and can be efficiently verified by any observer using $\pi_r$ via $\mathsf{VDF.Verify}$.
\end{enumerate}

As long as $T$ is longer than the duration of the collect period plus any potential network delay ($t_2-t_1 + \Delta$), Unicorn++ successfully defends against any attack possible by the last entropy provider. Also desirably, it is unbiasable by an adversary that controls $n - 1$ of the participants, as even one honest entropy contribution requires computation of $\mathsf{VDF.Eval}$ from scratch.
The biggest downside of the protocol is that \emph{somebody} must evaluate the VDF, which is slow by design (it doesn't matter for security who evaluates, since VDFs are deterministic and verifiable).
Thyagrajan et al.~\cite{thyagarajan2021opensquare} recently proposed a protocol for outsourcing VDF evaluation.

We quickly note a variation of above: as proposed in \cite{bunz2017proofs, bonneau2015bitcoin}, beacons using stock prices \cite{clark2010use} or PoW blockchains \cite{nakamoto2008bitcoin, bentov2016bitcoin, han2020randchain} (which are otherwise susceptible to manipulation) can be used to supply $seed_r$ in Collect. Such schemes are collectively denoted by \textit{Ext. Beacon+VDF} in Table~\ref{table:comparison}.
Unfortunately they do not easily compare to other DRBs as the security model depends on the cost of manipulating the external beacon, which has not yet been formally analyzed.

% \iffalse
% \subsection{Extending Public Randomness}
% As proposed in \cite{bunz2017proofs, bonneau2015bitcoin}, beacons using stock prices \cite{clark2010use} or PoW blockchains \cite{bonneau2015bitcoin} which are otherwise susceptible to manipulation can also be used to supply $seed_r$ via
% $$y_r, \pi_r = \mathsf{VDF.Eval}(pp, seed_r)$$
% where $seed_r = H(e_r)$ with $e_r$ denoting the output of a public implicit beacon.

% Adding a VDF prevents miners (or any other party) from determining the beacon output (and deciding whether to withhold/manipulate) before $T$, at which point it is already too late to attack as the beacon would have moved on to the next round with another $seed_r$. For PoW blockchains, this results in the miner to lose the block reward as well as any influence on the beacon. A sufficiently long $T$ also increases the attack cost significantly as changing the block at that point would require a deeper fork of the network.
% \fi

%TODO: need to add Thyagarajan protocol\cite{Thyagarajan21timedcommitments}

\subsection{Chain of VDFs}
\label{subsection:randrunner}
The disadvantage of above is that each round may require consensus \cite{castro1999practical} on inputs to the VDF, incurring communication cost. Also, the rate at which beacon outputs are generated is limited by $T$. RandRunner \cite{schindler2021randrunner} tackles these issues by leveraging a VDF design that builds a deterministic chain of outputs (more precisely, a chain of $n$ interleaved VDFs each set up by a node) to bypass per-round consensus while allowing each round's duration to be independent of $T$ in the optimistic case. As a result, the protocol achieves lower communication complexity as well as more beacon outputs generated per time frame. Trapdoor VDFs \cite{wesolowski2019efficient} with the strong uniqueness property \cite{schindler2021randrunner} serve as its key building block.

\begin{definition}[Strongly unique trapdoor VDF]
A \textit{strongly unique trapdoor VDF} extends VDF by allowing any participant who knows the \textit{trapdoor} (e.g. $p, q$ for RSA's $N = p q$) to efficiently evaluate the VDF without $T$ sequential steps. Moreover, it provides \textit{strong uniqueness}, i.e. uniqueness even when VDF's public parameters are adversarially generated. It can be described by the algorithms $\mathsf{TVDF} = (\mathsf{Setup}, \mathsf{VerifySetup}, \mathsf{TrapdoorEval}, \mathsf{Eval}, \mathsf{Verify})$, extending those of a traditional VDF with the following.
\begin{itemize}
    \item $\mathsf{VerifySetup}(\lambda, pp) \rightarrow \{0, 1\}$ verifies the validity of $pp$.
    \item $\mathsf{TrapdoorEval}(pp, x, sk) \rightarrow (y, \pi)$ outputs $y$ in time less than $T$ (unlike $\mathsf{Eval}$) and a proof $\pi$ given $pp$, an input $x$, and the trapdoor $sk$.
\end{itemize}
\end{definition}

Wesolowski's VDF \cite{wesolowski2019efficient} is not strongly unique, as knowing the trapdoor allows an adversary to forge proofs accepted by $\mathsf{VDF.Verify}$. As a result, RandRunner uses Pietrzak's VDF \cite{pietrzak2018simple}. After an initial Setup phase, RandRunner reiterates its Execution phase as follows.
\begin{enumerate}
    \item \textbf{Setup.} Each participant $P_i$ executes $\mathsf{TVDF.Setup}$ to compute its public parameters $pp_i$ and the corresponding secret trapdoor $sk_i$ and broadcasts $pp_i$, which is verified by others via $\mathsf{TVDF.VerifySetup}$. This ensures that the uniqueness of Pietrzak's VDF is guaranteed. At the end, all participants should have the same set of public parameters $\{pp_i\}_{i = 1, ..., n}$. The initial value $\mathcal{O}_0$ used to bootstrap the protocol is also agreed upon.
    \item \textbf{Execution.} A unique leader for round $r$, $l_r$ is selected via either round-robin (i.e. taking turns in some permuted order) or random selection (i.e. using $\mathcal{O}_{r - 1}$ as seed, originally called randomized sampling). The implications of each are discussed in Section \ref{subsubsection:public-committee-selection}. Each round can proceed in two ways depending on $l_r$'s status.
    \begin{itemize}
        \item \textbf{Honest Leader (Common Case).} The leader advances the protocol into the next round by broadcasting
        $$y_r, \pi_r = \mathsf{TVDF.TrapdoorEval}(pp_{l_r}, H_1(\mathcal{O}_{r - 1}), sk_{l_r})$$
        in which case other nodes check the correctness of the received values via $\mathsf{TVDF.Verify}$. Then the beacon output is
        $$\mathcal{O}_r = H_2(y_r)$$
        where $H_1$ and $H_2$ map values from the beacon output space to the VDF space and vice versa.
        \item \textbf{Dishonest Leader.} Given a dishonest leader that withholds or broadcasts an invalid message, every non-leader computes and broadcasts the round's VDF output via
        $$y_r, \pi_r = \mathsf{TVDF.Eval}(pp_{l_r}, H_1(\mathcal{O}_{r - 1}))$$
        in $T$ sequential steps. Then $\mathcal{O}_r = H_2(y_r)$ similarly.
    \end{itemize}
\end{enumerate}

Consequently, RandRunner generates each beacon output rapidly with only $O(n)$ communication complexity in the common case. Adversarial leaders can increase the round duration to $T$ (or more with network delay $\Delta$) and the communication complexity to $O(n^2)$. Due to its \textit{pseudorandomness} (as opposed to \textit{true randomness} \cite{cascudomt, das2021spurt}) sprouting from the deterministic nature of VDFs, RandRunner exhibits two other beneficial properties. First, liveness is retained even with a dishonest majority and when network connectivity breaks down completely, as a node can simply compute the beacon outputs over time via $\mathsf{TVDF.Eval}$. Second, it is impossible to bias the beacon once bootstrapped such that even the strongest adversary can only predict but not bias. These benefits have a counterpart, however. Namely, RandRunner can never achieve the ideal 1-unpredictability property due to the existence of leaders that can withhold and adversaries with higher compute power. In other words, the parameter $d$ as in RandRunner's $d$-unpredictability must be greater than one but can be calculated and bounded \cite{schindler2021randrunner} depending on assumptions.

\section{Commit-Reveal-Punish}
\label{section:commit-reveal-punish}
Representing an entirely different approach, \textit{commit-reveal-punish} schemes involve financial punishment and assume that all participants are rational entities willing to collude or withhold based on incentive. To motivate such a participant into joining the service that realizes a DRB, we assume an intrinsic value associated with it derived from the required deposits needed to join such a service. Namely, an \textit{escrow} (e.g. smart contract on Ethereum \cite{wood2014ethereum}) is used to collect initial deposits from the participants as part of their commitment, which can be slashed and redistributed if misbehavior is detected. In this setting, commit-reveal-punish schemes defend against the last revealer attack either by forcing every participant to reveal \cite{youcai2017randao, andrychowicz2014secure, bentov2014use} or by tolerating some number of withholding participants via a threshold variant of commit-reveal \cite{david2020economically}. These two approaches are summarized in the following.

\subsection{Enforcing Every Reveal}
Extending a basic commit-reveal, RANDAO \cite{youcai2017randao} implements commit-reveal-punish in the most literal sense via punishing participants that withhold during the reveal phase by confiscating (and redistributing) each deposit of $m$ coins made to the escrow during the initial commit phase. If no one withholds, participants receive their deposits back, and all entropy contributions are aggregated and broadcast as $\mathcal{O}_r$ as usual.

While this should enforce every reveal, the drawback of protocols like RANDAO is two-fold. First, honest failures are also punished without much flexibility. Second, a high deposit of $m = O(n^2)$ is required to provide fairness in certain scenarios \cite{andrychowicz2014secure, bentov2014use}. These imply that the protocol is suitable in cases where each participant is expected to be highly available and possess an ample supply of coins, but not otherwise.

% Note that it is possible to optimize in a lottery setting (i.e. where we choose a random winner not a number) such that constant or no deposits are required \cite{bartoletti2017constant, miller2017zero} by constructing a binary-tree tournament consisting of $n - 1$ two-player lottery instances (which can be realized as per \cite{andrychowicz2014fair,andrychowicz2014secure}) in $O(\log n)$ rounds where a participant automatically loses by not revealing. While this mechanism allows the protocol to tolerate withholding, it is unclear as to how to extend a random winner into a random number for the purpose of a DRB.

\subsection{Rational Threshold Commit-Reveal}
Economically Viable Randomness (EVR) \cite{david2020economically}, on the other hand, does provide an alternative requiring constant deposits while tolerating (honest) withholding to an extent. This is achieved by devising a threshold variant of commit-reveal (i.e. in which $t + 1$, as opposed to all $n$, nodes reveal to compute $\mathcal{O}_r$) and having an incentive mechanism around it. The threshold nature also invites collusion, which is counteracted by EVR's \textit{informing} mechanism: if the escrow is notified of collusion (via informing), it rewards the informer and slashes the deposits of all others (\textit{collective punishment}). Realizing this, nodes are discouraged to collude, fearing another node within the collusion would inform.

EVR uses Escrow-DKG \cite{david2019rational}, an extension of DKG (distributed key generation) \cite{pedersen1991threshold,gennaro1999secure}, to realize a threshold commit-reveal. DKG allows a set of $n$ nodes to collectively generate a pair $(sk, pk)$ of group secret and public keys such that $sk$ is shared and ``implied'' (i.e. never computed explicitly) by $n$ nodes via the following building blocks.

\begin{definition}[$(t, n)$-secret sharing]
A \textit{$(t, n)$-secret sharing} scheme (also known as Shamir's secret sharing \cite{shamir1979share}) allows a dealer to share a secret $s = p(0)$ for some \textit{secret sharing polynomial} $p \in \mathbb{Z}_q[X]$ of degree $t$ among $n$ participants each holding a \textit{share} $s_i = p(i)$ for $i = 1, ..., n$. Any subset of $t + 1$ or more participants can reconstruct the secret $s$ via \textit{Lagrange interpolation} (see Appendix \ref{appendix:lagrange}), but smaller subsets cannot.
\end{definition}

\begin{definition}[Verifiable secret sharing]
\textit{Verifiable secret sharing} (VSS) \cite{feldman1987practical, pedersen1991non} protects a $(t, n)$-secret sharing scheme against a malicious dealer sending incorrect shares by providing an additional verification step per share. VSS can be described by the following algorithms.
\begin{itemize}
    \item $\mathsf{Setup}(\lambda) \rightarrow pp$ generates the public parameters $pp$, an implicit input to all other algorithms.
    \item $\mathsf{ShareGen}(s) \rightarrow (\{s_i\}, C)$ is executed by the dealer with secret $s$ to generate secret shares $\{s_i\}$ (each of which is sent to node $i$ correspondingly) as well as commitment $C$ to the secret sharing polynomial of degree $t$.
    \item $\mathsf{ShareVerify}(s_i, C) \rightarrow \{0, 1\}$ verifies the correctness of the share $s_i$ using $C$.
    \item $\mathsf{Recon}(A, \{s_i\}_{i \in A}) \rightarrow s$ reconstructs $s$ via Lagrange interpolation from a set $A$ of $t + 1$ nodes that pass $\mathsf{ShareVerify}$.
\end{itemize}
See Appendix \ref{appendix:vss} for details.
% Feldman-VSS and Pedersen-VSS are two of the most popular VSS protocols. See Appendix \ref{appendix:vss} for details.
\end{definition}

\begin{definition}[Distributed key generation]
A \textit{distributed key generation} (DKG) \cite{pedersen1991threshold,gennaro1999secure} allows $n$ participants to collectively generate a \textit{group public key} (for an implied \textit{group secret key}), \textit{individual secret keys}, and \textit{individual public keys} without a trusted third party. It does so by running $n$ instances of VSS (with each participant acting as a dealer for its independent secret). Unlike secret sharing schemes, DKG can be used repeatedly for an unlimited number of times, as the group secret key does not need to be computed explicitly.
\begin{itemize}
    \item $\mathsf{DKG}(1^\lambda, t, n) \rightarrow (sk_i, pk_i, pk)$ outputs the $i$-th node's secret key, its public key (e.g. $pk_i = g^{sk_i}$), and a group public key $pk$ (e.g. $pk = g^{sk}$) for an implied group secret key $sk$ given security parameter $1^\lambda$, $n$, and threshold parameter $t$.
\end{itemize}
See Appendix \ref{appendix:dkg} for details.
% Joint-Feldman and Joint-Pedersen are two of the most popular DKG protocols. See Appendix \ref{appendix:dkg} for details.
\end{definition}

\begin{definition}[Escrow-DKG]
Escrow-DKG \cite{david2019rational} is a rational variant of DKG with the following variations.
\begin{itemize}
    \item Unlike traditional DKG, Escrow-DKG does not a priori assume a $t$-limited adversary. However, it assumes the participants are rational in a setting where collusion of more than $t$ participants would be financially punished such that, effectively, we have a $t$-limited adversary.
    \item It assumes an escrow denoted by $\mathcal{G}$.
    \item Escrow-DKG has a deposit requirement, considers how a DKG may fail, and associates a financial penalty to each failure case to disincentivize misbehavior.
\end{itemize}
\end{definition}

The crux is that EVR adapts Escrow-DKG to realize a DRB by using the group secret (i.e. the implied group secret key $sk$ after a DKG) as $\mathcal{O}_r$, retrievable from $t + 1$ $sk_i$'s. EVR proceeds in four phases---Setup, Commit, Inform, and Reveal.
\begin{enumerate}
    \item \textbf{Setup.} Every participant registers by depositing 1 coin per secret (i.e. entropy contribution), and $\mathcal{G}$ accordingly sets the threshold parameter $t = 2n / 3$ required for Escrow-DKG. It also sets the \textit{illicit profit bound} (i.e. bound on extra profit an adversary can gain as a result of using EVR's beacon output as opposed to an ideal beacon's output) $P = n - t = n / 3$ and the \textit{informing reward} $\ell = n$.
    \item \textbf{Commit.} Escrow-DKG is run, and each participant ends up with an individual key pair $(sk_i, pk_i)$ as well as $pk$.
    \item \textbf{Inform.} Any colluding participant that preemptively knows $\mathcal{O}_r$ can inform $\mathcal{G}$ to earn a high informing reward ($\ell$) obtained via collective punishment. Due to this phase, the incentive is that no one should collude.
    \item \textbf{Reveal.} $\mathcal{O}_r = sk$ is reconstructed once $t + 1$ (or more) honest participants reveal their $sk_i$'s. Initial deposits are returned after verification by $\mathcal{G}$. If $\mathcal{O}_r$ is not reconstructed by the end, $\mathcal{G}$ also initiates collective punishment.
\end{enumerate}

While a node's malicious behaviors in EVR are limited to withholding to abort the protocol during Reveal or colluding to learn $\mathcal{O}_r$ before Reveal, its security comes from the fact that both are disincentivized. First, setting $P = n - t$ makes withholding unprofitable, as $n - t$ or more participants that withhold to successfully abort EVR would earn at most $P$ at the cost of losing their deposits. This prevents biasability. Second, setting $\ell = n$ makes informing more profitable than any illicit profit such that any coalition of nodes colluding to preemptively learn $\mathcal{O}_r$ is disincentivized due to the inevitability of an informer. This prevents predictability.

Despite the benefits of the threshold nature and constant deposits enabling a flexible incentive mechanism, EVR needs to assume certain bounds on the amount of coins, e.g. $P$ (an assumed limit on illicit profit) or $n / 3$ (a participant with more coins than this is not allowed to join EVR as per decentralization assumption \cite{david2020economically}), and thus can be limited in scope.

\section{Commit-Reveal-Recover Variants}
\label{section:commit-reveal-recover}
Without an escrow to enforce desired behaviors, commit-reveal-recover variants extend commit-reveal and defend against the last revealer attack by providing a mechanism to \textit{recover} or \textit{reconstruct} one's entropy contribution if withheld. This can be achieved by either threshold secret sharing or threshold encryption. Protocols based on commit-reveal-recover assume a $t$-limited adversary and require the cooperation of at least $t + 1$ nodes to reconstruct such that two desirable properties are achieved simultaneously: there is no need for all $n$ nodes to reveal while $t$ Byzantine nodes cannot collude to preemptively reconstruct.

\subsection{From Threshold Secret Sharing}
Building on $(t, n)$-secret sharing, commit-reveal-recover variants based on threshold secret sharing often use PVSS (publicly verifiable secret sharing) \cite{schoenmakers1999simple, cascudo2017scrape} as a subprotocol in order to allow any external party (not just the participants) to verify the correctness of sharing and reconstruction.

\begin{definition}[Publicly verifiable secret sharing]
\textit{Publicly verifiable secret sharing} (PVSS) extends VSS by enabling public verification. It can be realized by the algorithms $\mathsf{PVSS} = (\mathsf{Setup}, \mathsf{KeyGen}, \mathsf{Enc}, \mathsf{Dec}, \mathsf{ShareGen}, \mathsf{ShareVerify}, \mathsf{Recon})$, extending those of VSS. To provide public verifiability, PVSS requires $\mathsf{PVSS.ShareGen}$ to use keys (secret-public key pair per participant) generated by $\mathsf{PVSS.KeyGen}$ to encrypt and decrypt shares via $\mathsf{PVSS.Enc}$ and $\mathsf{PVSS.Dec}$ as subroutines and to generate proofs, e.g. NIZK (non-interactive zero-knowledge) proofs, for public verification as another subroutine. Then $\mathsf{PVSS.ShareVerify}$ can be run by anyone (not just the participants). See Appendix \ref{appendix:pvss} for details.
\end{definition}

The idea is that these commit-reveal-recover variants start with each of $n$ nodes generating a secret (i.e. entropy contribution), distributing its PVSS shares, and receiving $n$ respective shares of $n$ secrets. These shares are then used to compute $\mathcal{O}_r$ via Lagrange interpolation ($\mathsf{PVSS.Recon}$) in case some nodes withhold. Based on when and how such Lagrange interpolation takes place, we subdivide the protocols into the following categories: commit-reveal-recover, share-reconstruct-aggregate, and share-aggregate-reconstruct.

\subsubsection{Commit-Reveal-Recover}
Extending commit-reveal, \textit{commit-reveal-recover} adds another step to the commit phase where every participant is additionally required to distribute PVSS shares of its corresponding secret so that others can reconstruct it via Lagrange interpolation (\textit{recover}) if withheld during reveal. The tradeoff is additional communication cost, which could be amplified multiplicatively in the recover phase if $O(n)$ Lagrange interpolations need to take place. Scrape \cite{cascudo2017scrape} adopts this technique.\\

\noindent\textbf{Scrape.} The main building block of Scrape is its own PVSS scheme \cite{cascudo2017scrape}. The initial setup for Scrape requires generating $(sk_i, pk_i)$ for each of the $n$ participants using $\mathsf{PVSS.KeyGen}$. The protocol then proceeds as follows.
\begin{enumerate}
\item \textbf{Commit.} Every participant $P_j$ executes $\mathsf{PVSS.ShareGen}(s^{(j)})$ as a dealer and publishes the encrypted shares $\mathsf{Enc}(pk_i, s^{(j)}_i)$ for $1 \le i \le n$ and encryption proofs. $P_j$ also publishes a commitment to the secret exponent $\mathsf{Com}(s^{(j)}, r_j)$ (with fresh randomness $r_j$).
\item \textbf{Verify.} For every set of published encrypted shares and proofs, all participants run $\mathsf{PVSS.ShareVerify}$ to verify correct encryption. Let $\mathcal{C}_r$ be the set of all participants with published commitments and valid shares.
\item \textbf{Reveal.} Once $t + 1$ participants have distributed their commitments and valid shares, every participant $P_j$, $j \in \mathcal{C}_r$ opens its commitment, and shares $\mathsf{Open}(s^{(j)}, r_j)$.
\item \textbf{Recover.} For every participant $P_a \in \mathcal{C}_r$ that withholds $\mathsf{Open}(s^{(a)}, r_a)$ in Reveal phase, other participants $P_j$ for $j \neq a$ reconstruct $h^{s^{(a)}}$ via $\mathsf{PVSS.Recon}$, which requires each participant to publish its decrypted share $h^{s_j^{(a)}}$ and the proof of correct decryption passing $\mathsf{PVSS.ShareVerify}$.
\item \textbf{Aggregate.} The final randomness is $\mathcal{O}_r = \prod_{j \in \mathcal{C}_r} h^{s^{(j)}}$.
\end{enumerate}

Note that Scrape, in the optimistic case (without Recover), is basically a commit-reveal with $O(n^2)$ PVSS shares distributed in the network during commit, $O(n)$ per node. In the worst case (with Recover), it requires an entirely new round of communication and potentially $O(n)$ Lagrange interpolations.\\

\noindent\textbf{Albatross.} Extending Scrape, Albatross \cite{cascudo2020albatross} provides an improved amortized communication complexity of $O(n)$ per beacon output by generating a batch of $O(n^2)$ beacon outputs per round (as opposed to Scrape's one). This is achieved by two techniques: packed Shamir secret sharing and linear $t$-resilient functions \cite{cascudo2020albatross}, each of which contributes a multiplicative factor of $O(n)$ to the number of beacon outputs produced per round.

\subsubsection{Share-Reconstruct-Aggregate}
One alternative is to skip the commit-reveal phase involving cryptographic commitments altogether and by default reconstruct each secret shared via PVSS. In other words, we can remove the $\mathsf{Com}(s^{(j)}, r_j)$ portion from Scrape's commit (\textit{share}), perform Lagrange interpolation per secret for a total of $O(n)$ times (\textit{reconstruct}), and sum up the interpolated secrets to output $\mathcal{O}_r$ (\textit{aggregate}). While the resulting \textit{share-reconstruct-aggregate} saves a round of communication from Scrape's worst case, its average case does incur substantial communication cost due to $O(n)$ Lagrange interpolations, each of which requires cooperation of $t + 1$ nodes. RandShare \cite{syta2017scalable} uses this technique alongside a Byzantine agreement protocol to reach consensus on $O(n)$ secrets to be reconstructed.

\subsubsection{Share-Aggregate-Reconstruct}
Another alternative is to harness the homomorphic property of PVSS where the sum of $n$ respective shares of $n$ secrets is a share of the sum of $n$ secrets (note that the sum of $n$ secrets is precisely $\mathcal{O}_r$ in these protocols). Due to this, only one, as opposed to $O(n)$, Lagrange interpolation is sufficient to reconstruct $\mathcal{O}_r$ once nodes essentially perform \textit{aggregate} before \textit{reconstruct}, hence the name \textit{share-aggregate-reconstruct}. SecRand \cite{guo2020secRand} uses this technique to reduce the communication complexity by a factor of $n$ during reconstruct as only $t + 1$ aggregated shares are exchanged to compute $\mathcal{O}_r$.

\subsection{From Threshold Encryption}
While protocols based on threshold secret sharing can incur high communication cost of $O(n^4)$ due to $O(n)$ Lagrange interpolations, protocols relying on a different cryptographic primitive, namely threshold encryption \cite{desmedt1990Threshold}, offer a variant where only one Lagrange interpolation suffices even in the worst case. Though reminiscent of share-aggregate-reconstruct, these protocols differ in that they do not necessarily assume a PKI (mandatory in PVSS) but rather a DKG, which may be run multiple times to refresh keys. In this section, we define threshold encryption and summarize how a protocol like HERB \cite{cherniaeva2019homomorphic} exhibits above.

\begin{definition}[$(t, n)$-threshold encryption]
A \textit{$(t, n)$-threshold encryption} scheme uses DKG among $n$ nodes as a subroutine and allows encryption of a message under the resulting group public key $pk$ such that the message can be decrypted by any $t + 1$ of the $n$ nodes, but not less. The scheme ($\mathsf{ThrEnc}$) is composed of the following algorithms.
\begin{itemize}
    \item $\mathsf{DKG}(1^\lambda, t, n) \rightarrow (sk_i, pk_i, pk)$ runs a typical DKG.
    \item $\mathsf{Enc}(pk, m) \rightarrow c$ encrypts message $m$ with group public key $pk$ and outputs ciphertext $c$.
    \item $\mathsf{DecShare}(sk_i, c) \rightarrow d_i$ generates decryption share $d_i$ for ciphertext $c$ using individual secret key $sk_i$.
    \item $\mathsf{Rec}(A, c, pk, \{pk_i\}_{i \in A}, \{d_i\}_{i \in A}) \rightarrow m$ takes ciphertext $c$, $pk$, and a set $A$ of $t + 1$ nodes with valid decryption shares along with their individual public keys and recovers the message $m$ via Lagrange interpolation.
\end{itemize}
\end{definition}

HERB uses threshold ElGamal encryption \cite{desmedt1990Threshold, fouque2001threshold} (see Appendix \ref{appendix:thrElGamal} for details) though it can be replaced with any other threshold homomorphic encryption scheme. After an initial DKG ($\mathsf{ThrEnc.DKG}$), the protocol proceeds in two phases. In the first phase, nodes play the role of \textit{entropy providers} each offering some entropy contribution to generate a group ciphertext. In the second phase, nodes play the role of \textit{key holders} performing threshold decryption. While entropy providers and key holders could technically be different nodes, we assume they are the same below.

\begin{enumerate}
    \item \textbf{Publication.} Each entropy provider $P_j$ encrypts its entropy contribution $m_j$ using $\mathsf{ThrEnc.Enc}$ to generate a ciphertext share $c_j$, published along with a proof of correct encryption $\pi_{CE}^{(j)}$ (Appendix \ref{appendix:ce}) to account for malleability \cite{dolev2003nonmalleable}. When $\mathcal{C}_r$ (the agreed set of nodes with verified published $c_j$'s) reaches a certain size (based on system parameters), the included $c_j$'s are summed into group ciphertext $c$ corresponding to group plaintext $m$ (which is in turn a sum of $m_j$'s).
    \item \textbf{Disclosure.} Each key holder $P_i$ uses $\mathsf{ThrEnc.DecShare}$ to generate a decryption share $d_i$, published along with a proof of correct decryption $\pi_{DLEQ}^{(i)}$ (Appendix \ref{appendix:dleq}). When $t + 1$ decryption shares are published and verified, nodes use $\mathsf{ThrEnc.Rec}$ to output $\mathcal{O}_r = m$.
\end{enumerate}

Offering a different flavor but similar to SecRand's share-aggregate-recover, HERB achieves a communication complexity of $O(n^2)$ and $O(n^3)$ in the optimistic and worst cases, respectively, due to one needed Lagrange interpolation per $\mathcal{O}_r$. Its requirement of DKG in the setup presents a caveat however, as a new DKG must take place for any attempt to refresh keys of participants, e.g. in case of a suspected hack or a simple \textit{reconfiguration} (in which the set of participants changes). This can incur additional cost per DKG. On the flip side, HERB provides a positive feature where entropy providers need not be key holders (as noted before), implying that the level of randomness quality and that of security can aptly be scaled independently if necessary.

\section{Committee-Based Protocols}
\label{section:committee-based}
While all aforementioned commit-reveal variants (Sections \ref{subsection:modifying-commit-reveal}, \ref{section:commit-reveal-punish}, and \ref{section:commit-reveal-recover}) include every node in the entropy-providing committee $\mathcal{C}_r$, the issue with this approach is one of scalability. Requiring communication of marginal entropy by all nodes is unsurprisingly inefficient, and hence a natural optimization is to reduce $|\mathcal{C}_r|$ (the size of $\mathcal{C}_r$).

In this section, we consider DRBs that are \textit{committee-based}, where a committee refers to a non-empty proper subset of nodes. Committee-based protocols proceed in two steps: \textit{committee selection} and \textit{beacon output generation}. As the names suggest, $\mathcal{C}_r$ is agreed upon during committee selection while the beacon output $\mathcal{O}_r$ is generated and agreed upon during beacon output generation. Provided below is a summary of ten preexisting protocols, and we offer intuition (refer to corresponding citations for full details) on interpreting them under our simple framework.

The insight is that committee selection and beacon output generation are theoretically modular such that (cryptographic) tools used in the first step can be independent of those used in the second step. It is in this way that these two steps can be seen as two ``dimensions'' explaining a committee-based DRB. Refer to Table \ref{table:committee-based} to visualize.

\subsection{Step 1. Committee Selection}
The first step of a committee-based DRB involves selecting $\mathcal{C}_r$ in a way agreeable by all nodes. We classify committee selection mechanisms into two: public and private.

\subsubsection{Public Committee Selection}
\label{subsubsection:public-committee-selection}
In a \textit{public committee selection}, only public information is needed to derive $\mathcal{C}_r$.\\

\noindent\textbf{Round-Robin (RR).} A first example is \textit{round-robin} (RR), in which nodes simply take turns being selected such that there is no notion of hierarchy among nodes. While RR can work with committees of any size as long as the exact mechanism is clearly defined in advance, it is canonical that RR usually refers to the selection of committee of size one (i.e. a leader) corresponding to node $i \equiv r \pmod n$. Protocols like BRandPiper \cite{bhat2020randpiper} (in which the round leader is the only active entropy provider) adopt RR as their leader selection mechanism due to its innate fairness property \cite{azouvi2018winning} (also known as chain quality \cite{garay2015bitcoin} in the blockchain context) where all nodes, by RR's definition, take equal leadership.\\

\noindent\textbf{Random Selection (RS).} A second example is \textit{random selection} (RS), which uses some public randomness (e.g. most commonly $\mathcal{O}_{r - 1}$) to derive $\mathcal{C}_r$. While RR is simple and deterministic, RS is randomized. In HydRand \cite{schindler2020hydrand} and GRandPiper \cite{bhat2020randpiper}, for instance, $\mathcal{C}_r$ consists of a node $i \equiv \mathcal{O}_{r - 1} \pmod{\tilde{n}}$ where $\tilde{n}$ is the number of eligible nodes. Similar is the process in Ouroboros \cite{kiayias2017ouroboros} called the follow-the-satoshi algorithm \cite{bentov2014proof,kiayias2017ouroboros}, which can output more than one node in $\mathcal{C}_r$.

That RS is randomized incurs a side effect where some nodes may, in theory, never be selected and therefore may never be able to provide entropy contribution. A more realistic concern is that an adversary can attempt to bias, via grinding attack, $\mathcal{O}_r$ in order to bias $\mathcal{C}_{r + 1}$ (which can bias $\mathcal{O}_{r + 1}$ and so on). This is a notable attack vector given RS.

On the other hand, this is not an issue in RR, as its committee selection is deterministic and independent of the preceding beacon output. Nonetheless, a tradeoff of RR is that DoS attack becomes indefinitely possible (for all rounds $\tilde{r}$ for $\tilde{r} > r$ given $\mathcal{O}_r$) since each committee is publicly known in advance. All in all, RR gains unbiasability (due to determinism) at the cost of indefinite DoS attack while RS benefits from less DoS attack, i.e. that only for round $r + 1$ (due to randomization given $\mathcal{O}_r$), at the cost of grinding attack.\\

\noindent\textbf{Leader-Based Selection (LS).} A third example, \textit{leader-based selection} (LS) is a hybrid method that exhibits both determinism and randomization. It runs in two steps: the first step involves electing a round leader (either by RR or RS) while the second involves selection of $\mathcal{C}_r$ by the elected leader. It is in this way that the mechanism is deterministic from the leader's perspective while randomized from that of others.

One requirement, due to the power delegated to the leader, is that $|\mathcal{C}_r|$ needs to be greater than $t$ so that a malicious leader wouldn't be able to choose $\mathcal{C}_r$ maliciously. RandHound \cite{syta2017scalable} and SPURT \cite{das2021spurt} demonstrate such LS.
\begin{itemize}
\item RandHound. As instantiated in RandHerd \cite{syta2017scalable}, RandHound's leader election (i.e. via RS as the first step of LS) involves a public lottery where each node generates a lottery ticket $t_i = H(C \mathbin\Vert pk_i)$ given a public configuration parameter $C$ (assuming its randomness) such that the owner of $min(t_i)$ becomes the leader (originally called client). In the second step of LS, RandHound adopts a form of sharding (involving PVSS groups). The leader selects more than a threshold number of nodes in each shard (PVSS group), guaranteeing a threshold number of entropy providers across all shards.
\item SPURT. Unlike RandHound, SPURT adopts RR as its first part of LS such that nodes simply take turns being a round leader. Then the leader chooses $\mathcal{C}_r$ based on received encrypted messages.
\end{itemize}

Given an underlying DRB that utilizes the concept of a leader as an orchestrator of communication among nodes, LS is a natural choice to committee selection, as a leader helps mitigate the protocol's communication cost overall.

\subsubsection{Private Committee Selection}
\label{subsubsection:private-committee-selection}
In a \textit{private committee selection}, also known as \textit{private lottery}, each node needs to input some private information (e.g. secret key) in order to check whether or not it has been selected into $\mathcal{C}_r$ (i.e. has won the lottery). The general formulation of a private lottery can be given by
\[
f_{priv}(\cdot) < target
\]
where $f_{priv}(\cdot)$ is a lottery function (i.e. pseudorandom function) that takes some private input $priv$ and $target$ denotes the lottery's ``difficulty level'' (a la Proof of Work difficulty) such that we can tinker with $target$ to make the lottery arbitrarily easy or hard to win. The idea is that each node calculates $f_{priv}(\cdot)$ and checks if the above inequality is satisfied, in which case it wins the lottery and becomes an entropy provider.

As it is possible for an adversary to perform a grinding attack by trying many values of $priv$ until a desirable function output is achieved, one crucial requirement is that $priv$ should be provably committed in the past and thus be ungrindable at the time of computation of $f_{priv}(\cdot)$. Two examples of the above formulation exist in the landscape: a VRF-based lottery and Caucus' \cite{azouvi2018winning} lottery involving a hash chain.\\

\noindent\textbf{VRF-based approach.} In Algorand \cite{gilad2017algorand}, a VRF (verifiable random function) \cite{micali1999verifiable,dodis2005verifiable} is used each round to process a lottery. (While there exist more than one version of Algorand's private lottery algorithm, we consider its first version, as the versions do not differ fundamentally.) Quite naturally, one's private input to $VRF_{sk}(\cdot)$ is its secret key such that the lottery is given by
\[
VRF_{sk}(\mathcal{O}_{r - 1} \mathbin\Vert role) < target
\]
where $role$ is some parameter specific to Algorand. As both $\mathcal{O}_{r - 1}$ and $role$ are already public and ungrindable at the time of computation, Algorand makes sure $sk$ is likewise ungrindable by requiring that $sk$ is derived from some threshold number of rounds ago. Similar are private lotteries for protocols like Ouroboros Praos \cite{david2018ouroboros} and NV (from Nguyen-Van et al. \cite{nguyen2019scalable}). See Table \ref{table:committee-based} for details.\\

\noindent\textbf{Replacing VRF with $H(\cdot)$ and hash chain.} In Caucus, a VRF is replaced by a hash function combined with a hash chain, i.e. a list ($h_1, ..., h_m$) with $h_r = H(h_{r + 1})$ for all $r = 1, ..., m - 1$ where $h_m = s$ for some random seed. A hash chain provides the functionality of provably committing to private inputs as one can publicize one $h_r$ at a time (i.e. $h_r$ in round $r$) such that doing so commits to $h_{r + 1}$. Thus, each participant of Caucus independently generates a private hash chain comprising $m$ private inputs such that the lottery is given by
\[
H(h_r \oplus \mathcal{O}_{r - 1}) < target
\]
which simply involves a hash function. One downside is that the hash chain needs to be periodically regenerated, as $m$ is finite while we desire our DRB to be prolonged indefinitely.\\

Private lottery exhibits two notable benefits: resilience to DoS attack (due to its property of delayed unpredictability \cite{azouvi2018winning} where one cannot predict the eligibility of honest nodes until they reveal) and \textit{independent participation} (i.e. nodes do not have to know other participants in advance to participate) allowing less communication cost as well as a more permissionless setting. Nonetheless, it can incur biasing via withholding in the worst case (as discussed in Section \ref{subsection:withholding}).

\subsection{Step 2. Beacon Output Generation}
\label{subsection:beacon-output-generation}
Once given $\mathcal{C}_r$, the issue then shifts to outputting $\mathcal{O}_r$. While a typical commit-reveal-recover run among nodes in $\mathcal{C}_r$ may be sufficient to realize a DRB, there can be other variations coupled with different tradeoffs as well. Largely, we classify these variations into two: one that requires \textit{fresh} (independently generated on the spot) per-node entropy (contribution) and one that combines previous beacon output with \textit{precommitted} (independently generated but precommitted, hence ungrindable) per-node entropy.

\subsubsection{Fresh Per-Node Entropy}
\label{subsubsection:fresh}
The beacon output generation process involving fresh (also referred to as true randomness \cite{cascudomt, das2021spurt} as opposed to pseudorandomness) per-node entropy for committee-based protocols is essentially a commit-reveal-recover variant from Section \ref{section:commit-reveal-recover}. Some protocols in this bucket and their implementation details are portrayed below.\\

\noindent\textbf{Share-Reconstruct-Aggregate.} In Ouroboros, nodes in $\mathcal{C}_r$ (i.e. slot leaders of epoch $r$) perform a RandShare-style share-reconstruct-aggregate using PVSS to output $\mathcal{O}_r$. Similar is true in RandHound facilitated by a round leader.\\

\noindent\textbf{Share-Aggregate-Reconstruct.} In SPURT and BRandPiper, nodes in $\mathcal{C}_r$ perform a SecRand-style share-aggregate-reconstruct to output $\mathcal{O}_r$. BRandPiper has a caveat, however: it utilizes the idea of buffering PVSS shares in advance. While there exists one entropy provider per round, $n$ secrets (one from each node) are combined such that it provides the ideal 1-unpredictability property as opposed to $t$-unpredictability (as in HydRand or GRandPiper). The trick is that each round leader generates $n$ fresh secrets that become combined with others' secrets in the next $n$ rounds, respectively. One node distributes $O(n^2)$ PVSS shares (buffered by other nodes) per round in BRandPiper whereas, in a typical share-aggregate-reconstruct like SPURT, each of $O(n)$ nodes distributes $O(n)$ PVSS shares per round (with no buffering).\\

\noindent\textbf{From Threshold Encryption.} Similar to HERB, entropy providers of NV \cite{nguyen2019scalable} contribute their fresh entropy using ElGamal although they use its classical, non-threshold version due to NV's centralized model in which a third party called Requester is the direct recipient of a beacon output. As a result, each entropy provider generates and encrypts its entropy and sends it to the Requester, which then decrypts all the messages received from entropy providers and outputs their sum as $\mathcal{O}_r$. Naturally, this Requester version of NV can be modified into what we call \textit{NV++}, which differs from NV in two ways. First, those in $\mathcal{C}_r$ (once finalized) can be made to perform HERB among themselves. This eliminates the existence of the centralized Requester. Second, entropy provision (i.e. broadcasting one's entropy) can be coupled with proof of membership to $\mathcal{C}_r$ (i.e. broadcasting the fact that a node has won the VRF private lottery). In NV, these two are separate steps potentially incurring adaptive insecurity (a concept delineated in Section \ref{subsection:adaptive}). Thus, NV++ distributes the Requester and achieves adaptive security.

\subsubsection{Combining Previous Output and Precommitted Per-Node Entropy}
\label{subsubsection:precommitted}
To optimize and lower communication cost, we can require generally less input from entropy providers each round. The canonical optimization involves utilizing $\mathcal{O}_{r - 1}$ as a source of entropy to produce $\mathcal{O}_{r}$. Nonetheless, the caveat in doing so is that grinding attack may become a possibility once $\mathcal{O}_{r - 1}$ becomes public, which is why we need to require entropy providers' per-node entropy used in round $r$ to be precommitted before combining it with $\mathcal{O}_{r - 1}$ to output $\mathcal{O}_r$. Preventing grindability while taking advantage of the convenience of $\mathcal{O}_{r - 1}$, such a requirement can be observed in many committee-based protocols in the landscape and is indeed a commonality among them even if their details seem unrelated on the surface. We provide some examples as follows.
\begin{itemize}
\item HydRand and GRandPiper. Each round, an entropy provider (i.e. round leader) in HydRand commits its entropy that becomes opened in the next round it is selected as the leader again. In other words, the round leader's precommitted entropy $e_{\tilde{r}}$ from its last round $\tilde{r}$ of leadership is the one that becomes combined with $\mathcal{O}_{r - 1}$ in the form of $h^{e_{\tilde{r}}}$ to generate
\[
\mathcal{O}_r = H(\mathcal{O}_{r - 1} \mathbin\Vert h^{e_{\tilde{r}}})
\]
while PVSS recovery is used in case the leader fails to open $e_{\tilde{r}}$ in round $r$. Notable in HydRand is the fact (achieving ungrindability of $h^{e_{\tilde{r}}}$) that one honest node must be present in any $t + 1$ consecutive rounds due to the requirement that a leader cannot gain another leadership in the next $t$ rounds. Similar overall is GRandPiper's beacon output generation (see Table \ref{table:committee-based}).
\item Algorand and Ouroboros Praos. In VRF-based schemes that use a VRF for beacon output generation (rather than only for committee selection as in NV++), the secret key $sk$ of the round leader often corresponds to precommitted per-node entropy as long as the assumption that nodes cannot switch their $sk$ at the time of VRF's computation holds. Algorand's beacon output is therefore given by
\[
\mathcal{O}_r = VRF_{sk}(\mathcal{O}_{r - 1} \mathbin\Vert r)
\]
combining the previous output $\mathcal{O}_{r - 1}$ with the precommitted entropy $sk$. Note that the input to the VRF in beacon output generation is different from that in committee selection, as the VRF output in committee selection is always going to be less than $target$ by design. Similar overall is Ouroboros Praos' beacon output generation (see Table \ref{table:committee-based}).
\item Caucus. Each new reveal ($h_r$ in round $r$) of one's private hash chain in Caucus corresponds to an entropy provider's precommitted entropy. The beacon output is given by
\[
\mathcal{O}_r = h_r \oplus \mathcal{O}_{r - 1}
\]
such that it naturally follows its committee selection mechanism $H(h_r \oplus \mathcal{O}_{r - 1}) < target$.
\end{itemize}

\section{Protocols With No Marginal Entropy}
\label{section:dvrf}
While DRBs can have all nodes or some subset of nodes contribute entropy to the beacon output every round, it is possible to devise a protocol where no node produces any marginal entropy to prolong a beacon. The advantage of this approach is that no node needs to generate and communicate any fresh entropy (which alleviates communication cost) while the disadvantage is that the entire beacon can be predictable once compromised (perhaps undetectably).

\subsection{From Distributed Verifiable Random Function}
Guaranteeing randomness entirely via pseudorandomness, such DRB can be based on distributed VRF \cite{hanke2018dfinity,galindo2020fully} (DVRF, also known as threshold VRF or TVRF \cite{cascudomt}), which is a distributed version of VRF. The idea is that the usual VRF's $sk$ is distributed among $n$ nodes via DKG such that $t + 1$ nodes can cooperate to compute a VRF output (as well as its proof) as if the computation involves one node with access to $sk$.

\begin{definition}[Distributed verifiable random function]
A \textit{distributed verifiable random function} (DVRF) is a VRF where $n$ nodes cooperate to yield a pseudorandom output such that up to $t$ Byzantine nodes are tolerated while any $t + 1$ honest nodes are able to yield an honest output. It can be described by the following tuple of algorithms.
\begin{itemize}
\item $\mathsf{DKG}(1^\lambda, t, n) \rightarrow (sk_i, pk_i, pk)$ runs a typical DKG.
\item $\mathsf{PartialEval}(sk_i, x) \rightarrow (y_i, \pi_i)$ outputs the partial evaluation $y_i$ as well as its proof of correctness $\pi_i$ given an input $x$ and a node's secret key $sk_i$.
\item $\mathsf{PartialVerify}(pk_i, x, y_i, \pi_i) \rightarrow \{0, 1\}$ verifies the correctness of the partial evaluation $y_i$ given its proof $\pi_i$, an input $x$, and a node's public key $pk_i$.
\item $\mathsf{Combine}(A, \{(y_i, \pi_i)\}_{i \in A}) \rightarrow (y, \pi)$ outputs the DVRF evaluation $y$ as well as its proof of correctness $\pi$ given a set $A$ of $t + 1$ nodes and their outputs of $\mathsf{PartialEval}(sk_i, x)$, all of which pass $\mathsf{PartialVerify}$.
\item $\mathsf{Verify}(pk, \{pk_i\}, x, y, \pi) \rightarrow \{0, 1\}$ verifies the correctness of the DVRF evaluation $y$ given $\pi$, input $x$, and public keys.
\end{itemize}
% Naturally, it should satisfy VRF's properties of provability, uniqueness, and pseudorandomness. See Appendix \ref{appendix:dvrf}.
\end{definition}

\noindent\textbf{DVRF-based DRB.} Each beacon output of a DVRF-based DRB is then given by
\begingroup\makeatletter\def\f@size{8}\check@mathfonts
\[
\mathcal{O}_r = \mathsf{DVRF.Combine}(A, \{\mathsf{DVRF.PartialEval}(sk_i, f(\mathcal{O}_{r - 1}))\}_{i \in A})[0]
\]\endgroup
where $sk_i$ denotes each node's secret key after a DKG and $f$ denotes some premeditated (mostly uncomplicated) function of $\mathcal{O}_{r - 1}$ on which nodes compute a DVRF.

Equivalently, suppose there exists one imaginary node with the knowledge of $sk$ (which should not happen in a typical DVRF or a DKG to begin with) computing a VRF. Then
\[
\mathcal{O}_r = VRF_{sk}(f(\mathcal{O}_{r - 1}))
\]
yields a computationally equivalent output to when a DVRF is computed among $n$ nodes. As $f$ typically takes a form resembling $f(\mathcal{O}_{r - 1}) = H(r \mathbin\Vert \mathcal{O}_{r - 1})$, there is no marginal entropy generated by the participants. The precise reason for the security of the above DVRF formulation is that no one node (or up to $t$ nodes) can gain knowledge of $sk$ to be able to compute and predict future beacon outputs.\\

\noindent\textbf{DVRF-based DRB from a chain of unique signatures.} Since the hash of a verifiable unpredictable function (VUF) \cite{micali1999verifiable} equals a VRF, a unique digital signature (which is a VUF \cite{dodis2005verifiable}) can be made into a DVRF by taking its threshold signature variant \cite{boldyreva2003threshold} and hashing the output. Adopting the BLS signature scheme \cite{boneh2001short}, protocols like Dfinity \cite{hanke2018dfinity} and drand \cite{drand} (though with slightly different trivial details) offer a DRB given by
\[
\mathcal{O}_r = H(\mathsf{Sign}_{sk}(r \mathbin\Vert \mathcal{O}_{r - 1}))
\]
where $\mathsf{Sign}_{sk}(\cdot)$ is a BLS signature though computed by at least $t + 1$ nodes with $sk$ as the implied group secret key from a DKG such that the actual computation of $\mathcal{O}_r$ involves combining of partial signatures using $sk_i$ (see Appendix \ref{appendix:bls}).\\

\noindent\textbf{Variations on a chain of unique signatures.} Besides a chain of BLS signatures, there exist other variations in the landscape, such as RandHerd \cite{syta2017scalable}, DDH-DRB, and GLOW-DRB \cite{galindo2020fully}.
\begin{itemize}
\item RandHerd. Two modifications are made in RandHerd. First, a form of ``sharding'' is performed where nodes are randomly configured into groups (each of size $c$) via some initial configuration seed (e.g. derived from RandHound) such that each group emits a group leader while that of the first group is deemed a cothority (collective authority) leader. This results in the notion of hierarchy among nodes in a tree structure and thus has the effect of reducing the communication complexity from $O(n^2)$ to $O(c^2 \log n)$. Second, the underlying signature scheme used is Schnorr instead of BLS. Each beacon output in RandHerd is essentially a threshold Schnorr signature on message (as per the original protocol) $m = t_r$ where $t_r$ denotes the timestamp at the beginning of round $r$. As $m$ can technically be chosen (and thus biased) by the leader, one simple improvement can be setting $m = r \mathbin\Vert \mathcal{O}_{r - 1}$ a la Dfinity or drand.
\item DDH-DRB. Each round of DDH-DRB involves DDH-DVRF. As $\mathsf{PartialVerify}$ and $\mathsf{Verify}$ from Dfinity-DVRF (i.e. each round of Dfinity) rely on verifying pairing equations (see Appendix \ref{appendix:dfinity-dvrf}), the speed at which each beacon output is generated can be made faster if we replace each pairing equation with a DLEQ NIZK (Appendix \ref{appendix:dleq}) achieving the same effect. The tradeoff is space, as $\pi$ grows linearly in $n$. See Appendix \ref{appendix:ddh-dvrf} for details.
\item GLOW-DRB. Each round involves GLOW-DVRF, which strikes a balance between Dfinity-DVRF and DDH-DVRF by involving a pairing equation in $\mathsf{Verify}$ (a la Dfinity-DVRF) but a DLEQ NIZK in $\mathsf{PartialVerify}$ (a la DDH-DVRF). This has the effect of generating a compact proof $\pi$ from $\mathsf{Verify}$ while enjoying less computational cost from $\mathsf{PartialVerify}$. See Appendix \ref{appendix:glow-dvrf} for details.
\end{itemize}

\section{Discussion}
\label{section:discussion}
We summarize key properties of all protocols discussed in Table~\ref{table:comparison} and explore several practical issues with DRBs.

\subsection{Grinding Attack}
In a grinding attack, an adversary can search over many possible inputs to broadcast in a given round, with the possibility of influencing the outcome. While grinding attacks are not a threat in commit-reveal-recover variants or protocols with no marginal entropy, they are a valid concern in committee-based protocols involving random selection (RS), a private lottery, or a beacon output generated by combining precommitted per-node entropy with $\mathcal{O}_{r - 1}$. The idea is that an adversary can grind to produce a biased $\mathcal{C}_r$, $\mathcal{O}_r$, or both (leading to a vicious cycle in the worst case).
% \joenote{What about the countermeasure of just making grinding statistically not effective for a subexponential adversary?}
% \kevinnote{can mention quantum/exponential adversary later?}

Two countermeasures are possible. First, inclusion of fresh marginal entropy from at least one honest node can be required, in which case grinding fails due to the adversary's inability to control such entropy. Second, precommitted entropy must indeed be precommitted, in which case grinding vacuously fails due to the lack of any grindable entropy.
\begin{enumerate}
\item \textbf{Requirement of fresh marginal entropy from at least one honest node.} Due to the $t$-limited adversary assumption, it is possible to force the inclusion of fresh marginal entropy from at least one honest node if we require more than $t$ entropy providers each round. Such a requirement is used in protocols like RandHound (where committee selection via LS has an explicit size requirement), Ouroboros (where the size of each epoch can be made large), and NV++ (where the VRF's target used for committee selection can be adjusted).
\item \textbf{Requirement of precommitted entropy.} No grindable entropy naturally means no possible grinding attack. In HydRand (and similarly GRandPiper), it is required that the precommitted entropy ($e_{\tilde{r}}$ from $\mathcal{O}_r = H(\mathcal{O}_{r - 1} \mathbin\Vert h^{e_{\tilde{r}}})$ as per Section \ref{subsubsection:precommitted}) used in round $r$ is precommitted in round $\tilde{r}$ where $r - \tilde{r} > t$ such that it is ungrindable due to the protocol's $t$-unpredictability property. In the protocols based on private lottery (i.e. Algorand, Ouroboros Praos, and Caucus), the private inputs to the lottery (VRF's $sk$ or each $h_r$ of a hash chain) are fixed in advance to make them ungrindable.
\end{enumerate}

\subsection{Withholding Attack}
\label{subsection:withholding}
In a withholding attack, an adversary can influence the outcome by not publishing some information in a given round. Any leader-based protocol is vulnerable to withholding due to the inherent reliance on a leader's availability, affecting the protocol's liveness (as well as potentially unpredictability and unbiasability). Any protocol with a private lottery is also vulnerable due to its nature where the lottery winner has to announce itself as a winner in the first place or can withhold this announcement if desirable.
\begin{enumerate}
\item \textbf{Protocols with a leader.} RandHound, RandHerd, and SPURT suffer from the leader unavailability issue in case the leader withholds its message such that their liveness is affected and a beacon output can be aborted (depending on implementation). In worse cases like RandHound and RandHerd, this can create a bias if the leader aborts after seeing $\mathcal{O}_r$. In either case, it is desirable to have some fallback in case a leader withholds (e.g. HydRand's PVSS recovery).
\item \textbf{Protocols with a private lottery.} The issue of withholding is more fundamental with private lottery schemes like Algorand (where the leader can bias via withholding after privately computing $\mathcal{O}_r$), as there is no way to conclusively detect if a winner withholds its leadership, i.e. there is no accountability. There are two possible remedies. First, we can require all participants to post their lottery outputs every single round even if they lose the lottery, in which case any lack of message would be indicative of withholding. However, this incurs communication cost, negating the advantages of a private lottery. Second, a technique called SSLE (single secret leader election) \cite{boneh2020single} can be used to guarantee one winner per round, enabling detection of withholding. In a nutshell, SSLE ensures exactly one leader from a group is randomly chosen while the identity of the leader will only be known when the winner publicly reveals its identity. The guarantee of one winner as opposed to the expectation of one winner is what differentiates SSLE. While this guarantee makes withholding obvious, it does not prevent withholding by itself, nor does it enable detecting \emph{who} the withholding winner was in the case of withholding.
\end{enumerate}

\begin{table*}[h!]
% \footnotesize
\scriptsize
% \tiny
\begin{threeparttable}
\caption{DRB Comparison}
\label{table:comparison}
% \begin{tabularx}{\textwidth}{@{} l *{20}c}
% \begin{tabularx}{\textwidth}{@{} l *{20}{@{\phantom{x}}c@{\phantom{x}}}}
\begin{tabularx}{\textwidth}{@{} l *{20}{@{\phantom{w}}c@{\phantom{w}}}}
\toprule
\spheading{} & \spheading{Section\\(from paper)} & \spheading{Cryptographic Primitive} & \spheading{Fault Tolerance (less than)} & \spheading{Independent Participation} & \spheading{Per-Round Entropy Provider} & \spheading{Unpredictability} & \spheading{Immunity to Withholding} & \spheading{Adaptive Security} & \spheading{Verifier Complexity} & \multicolumn{2}{c}{\spheading{Communication Complexity}} & \spheading{Max Damage} & \spheading{Recovery Cost}\\
\cmidrule{11-12}
 & & & & & & & & & & Optimistic & Worst & & \\
\toprule
Commit-Reveal & \hyperref[subsection:commit-reveal]{II} & Commitment & 1 & \cmark & All & \xmark & \xmark & \xmark & $O(n)$ & $O(n^2)$ & $O(n^3)$ & Bias & $O(1)$ \\
\midrule
Unicorn++ & \multirow{3}{*}{\ref{section:vdf}} & VDF & $n$ & \cmark & All & 1 & \cmark & \cmark & $O(n)$ & $O(n^2)$ & $O(n^3)$ & None & $O(1)$ \\
Ext. Beacon+VDF & & VDF & $n$ & \cmark & External & 1 & \cmark & \cmark & $O(1)$ & $O(n)$ & $O(n^2)$ & None & $O(1)$ \\
RandRunner & & Trapdoor VDF & $n$ & \xmark & None & $t$\tnote{} & \cmark & \xmark & $O(\log T)$\tnote{} & $O(n)$ & $O(n^2)$ & Predict & $O(n^3)$ \\
\midrule
RANDAO & \multirow{2}{*}{\ref{section:commit-reveal-punish}} & Commitment & $n$ & \cmark & All & 1 & \cmark & \cmark & $O(n)$ & $O(n^2)$ & $O(n^2)$\tnote{} & None & $O(n)$\tnote{} \\
EVR & & Escrow-DKG & $n/3$ & \xmark & All & 1 & \cmark & \cmark & $O(n^3)$ & $O(n^3)$ & $O(n^4)$ & None & $O(n)$ \\
\midrule
Scrape & \multirow{5}{*}{\ref{section:commit-reveal-recover}} & PVSS & $n/2$ & \xmark & All & 1 & \cmark & \cmark & $O(n^2)$ & $O(n^3)$ & $O(n^4)$ & Bias\tnote{r} & $O(n^3)$ \\
Albatross & & PVSS & $n/2$ & \xmark & All & 1 & \cmark & \cmark & $O(1)$ & $O(n)$ & $O(n^2)$ & Bias\tnote{r} & $O(n^3)$ \\
RandShare & & (P)VSS & $n/3$ & \xmark & All & 1 & \cmark & \cmark & $O(n^3)$ & $O(n^3)$ & $O(n^4)$ & Bias\tnote{r} & $O(1)$ \\
SecRand & & PVSS & $n/2$ & \xmark & All & 1 & \cmark & \cmark & $O(n^2)$ & $O(n^3)$ & $O(n^4)$ & Bias\tnote{r} & $O(n^3)$ \\
HERB & & Thr. ElGamal & $n/3$ & \xmark & All & 1 & \cmark & \cmark & $O(n)$ & $O(n^2)$ & $O(n^3)$ & Bias\tnote{r} & $O(n^4)$ \\
\midrule
HydRand & \multirow{10}{*}{\ref{section:committee-based}} & PVSS & $n/3$ & \xmark & Committee\tnote{*} & $t$ & \cmark & \xmark & $O(n)$ & $O(n^2)$ & $O(n^3)$ & Bias & $O(n^3)$ \\
GRandPiper & & PVSS & $n/2$ & \xmark & Committee\tnote{*} & $t$ & \cmark & \xmark & $O(n^2)$ & $O(n^2)$ & $O(n^2)$ & Bias & $O(n^3)$ \\
BRandPiper & & (P)VSS & $n/2$ & \xmark & Committee\tnote{*} & 1 & \cmark & \cmark & $O(n^2)$ & $O(n^2)$ & $O(n^3)$ & Bias\tnote{r} & $O(n^4)$ \\
Ouroboros & & PVSS & $n/2$ & \xmark & Committee & 1 & \cmark & \xmark & $O(n^2)$ & $O(n^3)$ & $O(n^3)$\tnote{} & Bias\tnote{r} & $O(n^2)$\tnote{} \\
RandHound & & PVSS & $n/3$ & \xmark & Committee & 1 & \xmark & \xmark & $O(c n)$ & $O(c^2 n)$ & $O(c^2 n^2)$ & Bias & $O(n^3)$ \\
SPURT & & PVSS & $n/3$ & \xmark & Committee & 1 & \xmark & \xmark & $O(n)$ & $O(n^2)$ & $O(n^2)$ & Bias & $O(n^3)$ \\
Algorand & & VRF & $n/3$ & \cmark & Committee\tnote{*} & 1 & \xmark & \cmark & $O(1)$ & $O(n)$ & $O(n)$\tnote{} & Bias & $O(n^2)$\tnote{} \\
Ouroboros Praos & & VRF & $n/2$ & \cmark & Committee & 1 & \xmark & \cmark & $O(n)$ & $O(n^2)$ & $O(n^2)$\tnote{} & Bias & $O(n^2)$\tnote{} \\
Caucus & & Hash chain & $n/3$ & \cmark & Committee\tnote{*} & 1 & \xmark & \cmark & $O(1)$ & $O(n)$ & $O(n^2)$ & Bias & $O(n^3)$ \\
NV++ & & VRF, thr. ElGamal & $n/3$ & \xmark & Committee & 1 & \xmark & \cmark & $O(n)$ & $O(n)$ & $O(n)$\tnote{} & Bias & $O(n^2)$\tnote{} \\
\midrule
drand & \multirow{4}{*}{\ref{section:dvrf}} & Thr. BLS & $n/2$ & \xmark & None & 1 & \cmark & \cmark & $O(1)$ & $O(n^2)$ & $O(n^3)$ & Predict & $O(n^4)$ \\
RandHerd & & Thr. Schnorr & $n/3$ & \xmark & None & 1 & \xmark & \xmark & $O(1)$ & $O(c^2 \log n)$ & $O(n^3)$ & Bias & $O(n^4)$ \\
DDH-DRB & & DDH-based DVRF & $n/2$ & \xmark & None & 1 & \cmark & \cmark & $O(1)$ & $O(n^2)$ & $O(n^3)$ & Predict & $O(n^4)$ \\
GLOW-DRB & & Pairing-based DVRF & $n/2$ & \xmark & None & 1 & \cmark & \cmark & $O(1)$ & $O(n^2)$ & $O(n^3)$ & Predict & $O(n^4)$ \\
\bottomrule
\end{tabularx}
\begin{tablenotes}[flushleft,para]
\item $c$ is the size of a shard in RandHerd and RandHound. We assume a leader can be Byzantine for both.
\item Albatross' verifier and communication complexities are per beacon output.
\item In Ouroboros and Ouroboros Praos, we assume the number of slot leaders in an epoch is denoted by $n$.
\item We assume Scrape's PVSS \cite{cascudo2017scrape} is used as the default PVSS scheme.
\item[*] Each committee consists of a leader by default or by expectation.
\item[] PBB (public bulletin board) is assumed.
\item[] Verification of Pietrzak's VDF is logarithmic in $T$ (VDF's delay parameter).
\item[] $d = t$ for RandRunner's $d$-unpredictability assuming a dishonest minority without any computational advantage. See \cite{schindler2021randrunner} for more scenarios.
\item[r] In a non-rushing adversary model, max damage would be predict rather than bias.
\end{tablenotes}
\end{threeparttable}
\end{table*}

\subsection{Adaptive Security}
\label{subsection:adaptive}
A DRB is \textit{adaptively secure} if its security properties remain unaffected against an adaptive adversary instead of a static one. Otherwise, it is \textit{adaptively insecure}. In this section, we discuss three ways in which adaptive security is achieved.

\begin{enumerate}
\item \textbf{$|\mathcal{C}_r|$ is greater than $t$ or equal to 0.} Due to the $t$-limited adversary assumption, a large enough $\mathcal{C}_r$ (or an empty one as per Section \ref{section:dvrf}) guarantees adaptive security. Otherwise, a protocol may be vulnerable. In HydRand and GRandPiper (where $|\mathcal{C}_r| = 1$), an adaptive adversary can corrupt the next $t$ round leaders to predict $t + 1$ future rounds. In Ouroboros, it can adaptively corrupt the entire $\mathcal{C}_r$ (which could probabilistically be less than or equal to $t$ in size) publicly known in advance.
\item \textbf{Protocols with a private lottery require lottery winners to broadcast marginal entropy and proof of selection into $\mathcal{C}_r$ in the same message.} While some private lottery schemes (i.e. Algorand, Ouroboros Praos, and Caucus) may involve less than or equal to $t$ entropy providers per round, the fact that one message (per entropy provider) comprises both announcement of winning the lottery and provision of marginal entropy is what allows adaptive security. The idea is that by the time an adversary knows which nodes to corrupt adaptively in a round (after the nodes reveal their identity as entropy providers), there is no extra step left to be corrupted, as each entropy provider's contribution to $\mathcal{O}_r$ has been broadcast already in the same message.
\item \textbf{There is no central point of dependency in any step of the protocol.} In leader-based protocols where a leader functions more as an orchestrator than an entropy provider, participating nodes may still need to depend on the leader to make progress on the beacon such that an adversary can adaptively corrupt such leaders to its benefit. In RandRunner, corrupting the next $t$ leaders allows predictability. In RandHound and RandHerd, corrupting the round leader allows biasability if the leader aborts after seeing $\mathcal{O}_r$ as aforementioned. In SPURT, corrupting the next $t$ leaders to withhold endangers liveness.
\end{enumerate}

\subsection{Comparison of DRBs}
Table~\ref{table:comparison} provides an overall comparison of DRBs. \textit{Fault Tolerance} indicates the minimum number of faulty nodes that can abort a protocol (after the initial setup). Protocols with \textit{Independent Participation} allow a node to contribute to beacon output without the knowledge of other nodes in advance. However, it differs from a permissionless setting in the sense that a node may still have to register in advance to allow verification of its contribution.

\textit{Verifier Complexity} refers to the computational cost for a passive node (third party) to verify a beacon output. We exclude the cost associated with the initial setup for both verifier and communication complexities. We assume a verifier complexity of $O(n)$ per Lagrange interpolation or Scrape's PVSS \cite{cascudo2017scrape} run. \textit{Communication Complexity} concerns bitwise point-to-point communication among nodes by default. Alternatively, we consider a \textit{public bulletin board} (PBB) as a reliable information exchange medium in protocols where it is intrinsic (e.g. in blockchains). In a PBB model, we assume both the bitwise writing cost (amount of data posted to PBB) and the reading cost (by all nodes where each node only reads data relevant to it) contribute to the total cost. In the absence of PBB, Byzantine consensus \cite{castro1999practical} incurs a cost of $O(n^2)$ per decision by default.

\textit{Max Damage} refers to the maximum damage possible when $n - 1$ rushing \cite{gennaro1999secure} (where an adversary can delay sending messages until \textit{after} reading messages sent by the honest nodes in any round of communication) adversarial nodes cooperate to predict or bias. In escrow-based protocols, we assume the adversaries are rational. \textit{Recovery Cost} refers to the communication cost associated with recovering from an adversarial corruption. Regenerating keys (e.g. $\mathsf{PVSS.KeyGen}$ or for private lottery schemes) and $\mathsf{VDF.Setup}$ incur $O(n^3)$ recovery cost without PBB (and $O(n^2)$ with PBB) while we assume each DKG incurs $O(n^4)$ recovery cost.
% \iffalse
% \subsection{Quality vs Efficiency}
% % Mt. Random's Tier 1 (fresh randomness per node) > 2 (one VRF, not biasable) > 3 (many VRFs, biasable via withholding) -- from quality of randomness perspective
% The protocols that we have seen so far provide a range of efficiency and quality tradeoffs under different setups, assumptions and adversarial models. PVSS/VSS based protocols offers uniform randomness, but comes at quartic communication complexity.
% VRF based protocols require very little communication and computation but the output is biasable by withholding. DVRF based protocols get rid of the bias by allowing a set of participants greater than a threshold to recover the output. VDF based protocols require high computational cost (sequential squarings) but generates uniform pseudorandom outputs with quadratic communication cost. While these protocols can be used on their own, they can also be combined in a modular way to build a distributed randomness beacon. Mt. Random \cite{cascudomt}, a multi-tiered randomness beacon is one such example.

% \joenote{should there be a separate section on protocols that combine other protocols?}
% Mt. Random has three independent tiers, each based on a different technique and providing different tradeoff between complexity and quality of randomness. Tier 1 provides uniform randomness via PVSS based protocols. Mt. Random reduces the amortized cost per beacon output for PVSS by using an extension of Albatross called GULL (Gradually UnLeashed aLbatross) \cite{cascudomt}, but could be substituted with any of the Commit-Reveal-Recover variants from Section \ref{section:commit-reveal-recover}. Tier 2 provides uniform pseudorandomness via DVRF based protocols. Mt. Random uses DDH based version of drand, but any of the DVRF based protocols from Section \ref{section:dvrf} or RandRunner from Section \ref{subsection:randrunner} could be used instead. Tier 3 provides biased pseudorandomness using VRF based protocols. Mt. Random uses a variation of Ouroboros Praos where every participant computes and broadcasts their VRF outputs (and requires no committee selection via private lottery). Though this makes detecting malicious participants (and maybe punishing them) easier, the beacon output for the round would still remain biased. Randomness from earlier tiers are used to periodically refresh seeds for Tier 2 and Tier 3 protocols, making them more secure than their stand-alone versions.

% Mt. Random illustrates a framework in which PVSS and (D)VRF protocols can be combined in a multi-tiered fashion where higher tiers generate random outputs faster than lower tiers albeit with losses in randomness quality. It is possible to extend the framework to other primitives/building blocks or use an altogether different framework to combine different protocols. This remains to be explored further.
% \fi

\section{Conclusion}
\label{section:conclusion}
In this paper, we systematize distributed randomness beacons and describe a modular framework comprising two components: selection of entropy providers and beacon output generation, which can be used to analyze a DRB's design. Our systematization highlights important insights both for practitioners and the research literature. Based on practical considerations such as scalability (in $n$), flexibility (reconfiguration and independent participation), robustness (fault tolerance and max damage), and randomness quality (true randomness versus pseudorandomness), we would advise practitioners interested in deploying a DRB as follows.
\begin{itemize}
    \item VDF-based protocols stand above the competition in terms of scalability, flexibility, and robustness. In theory, VDFs appear to be a silver bullet for DRBs, though they have yet to be widely used in practice and assumptions about VDF security and hardware speeds remain relatively new.
    \item If not using VDFs, practitioners need to think critically about two design dimensions: how large is the set of participants, and how frequently will it change? Given a small, static set of participants, DKG-based protocols, e.g. HERB (from threshold encryption) and drand (from DVRF), scale better than PVSS-based protocols. HERB and drand are both competitive in this setting, differing in randomness quality at the cost of max damage, and vice versa.
    \item For a small but dynamic set of participants, PVSS-based protocols offer better flexibility (by avoiding a costly DKG setup per reconfiguration) and randomness quality. Committees may be necessary to scale to a larger number of participants.
    \item Given a large, dynamic set of participants, protocols with a private lottery like Algorand offer better scalability and flexibility simultaneously although the randomness quality suffers due to potential withholding.
    \item Finally, escrow-based protocols are quite simple and are suitable against purely financially-motivated adversaries in applications such as lotteries or finance, at the cost of locking up some amount of capital while the protocol runs.
\end{itemize}
We conclude by identifying the following areas which we consider most promising for further research.
\begin{itemize}
    \item While VDFs are a very promising tool, practical deployment of VDFs urgently needs good estimates of the lower bound of wall-clock time for VDF evaluation. This means more research (and small scale deployments) are needed to gain confidence in the security of underlying VDF primitives (such as repeated modular squaring). To guarantee the security of VDF-based protocols, designs for efficient modular squaring targeting different hardware is an important area of research.
    \item VDFs might be useful as a modular layer in strengthening other DRBs in a ``belt-and-suspender'' approach, though this does not appear to have been explored yet.
    \item Vulnerable to withholding, protocols based on private lottery can generate biased outputs. Though the guarantee of a single lottery winner every round via SSLE makes detecting withholding easier, extending these protocols to generate unbiased outputs requires further research.
    \item With the exception of VDF-based protocols like Unicorn++, all other DRBs assume a permissioned setting which requires some initial setup (PKI, DKG) to establish participants' identities. Extending these protocols to allow ad hoc participation requires further research.
    \item Multiple independent protocols might be combined in a modular way to build a heterogeneous beacon. Mt. Random \cite{cascudomt} explores this idea by building a multi-tiered beacon with PVSS-based (Scrape variant), DVRF-based (drand variant), and VRF-based (Ouroboros Praos variant) protocols, with each tier providing different tradeoff between cost and randomness quality. Extending this framework of juxtaposition to combine other primitives can be explored further.
    \item While most of the existing DRBs rely on the assumption of synchronous communication model, the underlying timing assumptions may still fail in practice. Extending protocols to support fully asynchronous communication is an important area for future research.
    % communication cost bottleneck due to consensus
    % proactively detecting corruption and automatic recovery
\end{itemize}

% \printbibliography
\bibliography{IEEEabrv,bib}
\appendix
% \section*{Appendix}
% \addcontentsline{toc}{section}{Appendix}
% \renewcommand{\thesection}{\arabic{section}}

\subsection{Public Verifiability}
\label{appendix:pv}
Public verifiability of a DRB can be defined by the following game. Suppose the advantage of $\mathcal{A}$ is given by
\[
\left\lvert 1 - Pr\left[b = b' \middle\vert \begin{array}{l}
y_0 = \mathcal{O}_r;\\
y_1 \leftarrow \mathcal{A}(priv_r, pub_r);\\
b \leftarrow \{0, 1\};\\
b' \leftarrow V(y_b, pub_r)
\end{array}\right]
\right\rvert
\]
where the protocol runs among honest participants and $\mathcal{A}$ (which has access to private information $priv_r$ in round $r$ as a $t$-limited participant), $pub_r$ denotes public information emitted in round $r$, and $V$ is a third party verifier. Then this advantage is negligible such that $\mathcal{A}$ cannot fool a verifier into accepting $\tilde{\mathcal{O}_r} \neq \mathcal{O}_r$ as a DRB output.

% \iffalse
% \section{Verifiable Delay Function (VDF)}
% \label{appendix:vdf}

% A VDF must satisfy the following three properties:
% \begin{itemize}
% \item $\epsilon$-evaluation time. $\mathsf{Eval}(pp, x)$ runs in time at most $(1 + \epsilon) T$, for all $x$ and all $pp$ output by $\mathsf{Setup}(\lambda, T)$.
% \item Sequentiality. A parallel algorithm $\mathcal{A}$, using at most $poly(\lambda)$ processors, that runs in time less than $T$ cannot compute the function. Specifically, for a random $x$ and $pp$ output by $\mathsf{Setup}(\lambda, T)$, if $(y, \pi) = \mathsf{Eval}(pp, x)$ then $Pr[\mathcal{A}(pp, x) = y]$ is $\mathsf{negl(\lambda)}$.
% \item Uniqueness. For an input $x$ and $T$, exactly one $y$ will be accepted by $\mathsf{Verify}$ with negligible error probability. Specifically, let $\mathcal{A}$ be an efficient algorithm that given $pp$ as input, outputs $(x, y, \pi)$ such that $\mathsf{Verify}(pp, x, y, \pi) = 1$. Then $Pr[\mathsf{Eval}(pp, x) \neq y]$ is $\mathsf{negl(\lambda)}$.
% \end{itemize}
% For sequentiality, computing $y$ using $\mathsf{Eval}(pp,x)$ requires $T$ sequential squarings even on a parallel computer with $poly(\lambda)$ processors. Computing proof $\pi$ increases the running time to $(1+\epsilon)T$ as needed for $\epsilon$-evaluation time.

% Pietrzak's \cite{pietrzak2018simple} and Wesolowski's \cite{wesolowski2019efficient} proposals differ in the way $\pi$ is generated and verified. Both proof systems have their own strengths. Wesolowski's proof system generates a shorter proof (1 group element versus $\log T$ elements) and enjoys better verifier complexity (2 exponentiations versus $2 \log T$). Pietrzak's proof system enjoys better prover complexity requiring $O(\sqrt{T})$ group operations as opposed to Wesolowski's $O(T)$.

% \subsection{Trapdoor VDF}
% \label{appendix:tvdf}
% Trapdoor VDFs \cite{wesolowski2019efficient, schindler2021randrunner} are an extension and modification of traditional VDFs in which the $\mathsf{Setup}$ algorithm in addition to the public parameters $pp$ also outputs a trapdoor (secret key) $sk$ to the participant invoking the algorithm. The parameter $pp$ is published whereas $sk$ is kept secret. Furthermore, the algorithm $\mathsf{TrapdoorEval}$ provides an alternate way to evaluate the VDF efficiently, i.e. within time $\phi{(poly{(\lambda)})}$ to participants which know the trapdoor $sk$. Participants without this knowledge can still use the $\mathsf{Eval}$ algorithm to compute the output in $(1+\epsilon)T$ sequential steps.
% Trapdoor VDFs can be described by a set of four algorithms as follows.
% \begin{itemize}
%     \item $\mathsf{Setup}(\lambda, T) \rightarrow (pp, sk)$ is a randomized algorithm that takes a security parameter $\lambda$ and a delay parameter $T$ and outputs public parameters $pp$ and a trapdoor secret key $sk$.
%     \item $\mathsf{VerifySetup}(\lambda, pp) \rightarrow \{0, 1\}$ returns 1 if the validity of $pp$ can be successfully checked, returns 0 otherwise.
%     \item $\mathsf{Eval}(pp, x) \rightarrow (y, \pi)$ takes an input $x$ along with the public parameters $pp$ and outputs $y$ and a proof $\pi$.
%     \item $\mathsf{TrapdoorEval}(pp, x, sk) \rightarrow (y, \pi)$ takes an input $x$ and $pp$ along with trapdoor $sk$ and outputs $y$ and a proof $\pi$ such that the algorithm takes less than time $T$ to complete unlike $\mathsf{Eval}$.
%     \item $\mathsf{Verify}(pp, x, y, \pi) \rightarrow \{0, 1\}$ outputs 1 if $y$ is the correct evaluation of the VDF on input $x$ and $T$.
% \end{itemize}

% Due to the introduction of trapdoors and strong uniqueness, in contrast to traditional VDFs, trapdoor-VDF must satisfy the following properties:

% \begin{itemize}
%     \item $\epsilon$-evaluation time. $\mathsf{Eval}(pp, x)$ runs in time at most $(1 + \epsilon) T$, for all $x$ and all $pp$ output by $\mathsf{Setup}(\lambda)$.
%     \item Sequentiality without trapdoor. A parallel algorithm $\mathcal{A}$, using at most $poly(\lambda)$ processors, that runs in time less than $T$ cannot compute the function without the knowledge of a secret trapdoor. Specifically, for a random $x$ and all $pp$ output by $\mathsf{Setup}(\lambda, T)$, if $(y, \pi)$ is the output of $\mathsf{Eval}(pp, x)$ or $\mathsf{TrapdoorEval}(pp, x, sk)$, then the probability that $\mathcal{A}$ can compute $y$ in less than $T$ steps is negligible.
%     \item Strong uniqueness. For each input $x$ and all public parameters $pp$, exactly one $y$ will be accepted by $\mathsf{Verify}$ with negligible error probability even if the public parameters have been adversarially generated. Specifically, let $\mathcal{A}$ be an efficient algorithm that outputs $(pp, x, y, \pi)$ such that $\mathsf{Verify}(pp, x, y, \pi) = 1$. Then $Pr[\mathsf{Eval}(pp, x) \neq y]$ is negligible.
% \end{itemize}
% \fi

% \iffalse
\subsection{Verifiable Secret Sharing (VSS)}
\label{appendix:vss}

VSS schemes have two security requirements.
\begin{itemize}
    \item Secrecy. If the dealer is honest, then the probability of an adversary learning
    any information about the dealer's secret in the sharing phase is $\mathsf{negl}(\lambda)$.
    \item Correctness. If the dealer is honest, then the honest nodes output the secret
    $s$ at the end of the reconstruction phase with a high probability of $1 - \mathsf{negl}(\lambda)$.
\end{itemize}
Feldman-VSS \cite{feldman1987practical} and Pedersen-VSS \cite{pedersen1991non} are the most commonly used VSS schemes.\\\\
\noindent \textbf{Feldman-VSS.}
\label{appendix:feldmanVSS}
The following summarizes a simple VSS scheme proposed by Paul Feldman for sharing a secret $s$ among $n$ participants where any subset of $t + 1$ among them can reconstruct the group secret.

\begin{itemize}
\item $\mathsf{ShareGen}(s) \rightarrow (\{s_i\}, C)$ with $s \in \mathbb{Z}_q$ involves the dealer sampling $t$ random coefficients $a_1, \ldots, a_t \in \mathbb{Z}_q$ and constructing $p(x) = s + a_1x+ a_2x^2 +\ldots+a_tx^t$. The shares are computed as $s_i = p(i)$ in mod $q$ for $1\le i \le n$ and shared privately with each participant. The commitments to the secret $C_0 = g^s$ as well as coefficients $C_j = g^{a_j}$ for $j = 1,\ldots,t$ are also broadcast by the dealer.
\item $\mathsf{ShareVerify}(s_i, C) \rightarrow \{0, 1\}$ involves each participant $P_i$ checking if:
$$g^{s_i} = \prod_{j = 0}^{t} C_j^{i^j} = C_0 C_1^i C_2^{i^2} \cdots C_{t}^{i^{t}}$$
If it does not hold for some $i$, then $P_i$ broadcasts an accusation against the dealer, who has to respond by broadcasting the correct $s_i$. Correct reconstruction is achieved by filtering out shares that do not satisfy $\mathsf{ShareVerify}$.
\item $\mathsf{Recon}(A, \{s_i\}_{i \in A}) \rightarrow s$ outputs the secret $s$ by performing Lagrange interpolation (see Appendix \ref{appendix:lagrange}) with $t + 1$ valid shares from the reconstruction set $A$ of nodes:
$$s = p(0) = \sum_{j \in A} p(j) \lambda_{0, j, A}$$
\end{itemize}

The verifiability in Feldman-VSS comes from inclusion of commitments to the coefficients. These commitments enable participants to verify the validity of the shares that they receive from the dealer.
% \fi

% \iffalse
% \subsection{Pedersen-VSS}
% \label{appendix:pedersenVSS}
% A la Pedersen commitment, Pedersen-VSS is a variation that couples the commitment to $p(x)$ with another randomly chosen polynomial. By removing the assumption that $g^s$ is known beforehand as part of the commitment to the coefficients, it results in a secret sharing scheme which is unconditionally secure for the dealer. It can be summarized as follows:

% \textbf{Setup.} In addition to parameters $p,q,g$ inherent to Feldman-VSS, it uses an element $h$ in the subgroup of $\mathbb{Z}^*_p$ generated by $g$. It is assumed that the adversary cannot find the discrete logarithm of $h$ relative to the base $g$.

% \begin{itemize}
% \item $\mathsf{ShareGen}(s) \rightarrow (\{s_i\}, C)$ with $s \in \mathbb{Z}_q$ involves the dealer sampling two random polynomials $p(x) = a_0 + a_1x+ \ldots+a_tx^t$ and $p'(x) = b_0 + b_1x +\ldots+b_tx^t$ where $a_i, b_i \in \mathbb{Z}_q$ and the secret $s = a_0 = p(0)$ while $s' = b_0 = p'(0)$. The shares are computed as $(s_i = p(i), s'_i = p'(i))$ in mod $q$ for $1 \le i \le n$ and are shared with each participant privately. Also distributed from the dealer are coupled commitments to coefficients of $p$ and $p'$, i.e. $C_j = g^{a_j} h^{b_j}$ for $j = 0, ..., t$.
% \item $\mathsf{ShareVerify}(s_i, C) \rightarrow \{0, 1\}$ involves each participant $P_i$ with shares $(s_i, s'_i)$ and the public polynomial coefficient commitments checking if:
% $$g^{s_i} h^{s'_i} = \prod_{j = 0}^{t} C_j^{i^j}$$
% Similar to Feldman-VSS, any accusation of incorrect sharing against dealer by a participant $P_i$ would require the dealer to broadcast $(s_i, s'_i)$.
% \item $\mathsf{Recon}(A, \{s_i\}_{i \in A}) \rightarrow s$ outputs the secret $s$ by performing Lagrange interpolation with $t + 1$ valid shares of $p(x)$ from the reconstruction set $A$:
% $$s = p(0) = \sum_{j \in A} p(j) \lambda_{0, j, A}$$
% \end{itemize}

% Effectively, what Pedersen-VSS is able to achieve is the decoupling of $g^s$ (as the public key corresponding to the secret key $s$) and $g^{s} h^{s'}$ (as a published commitment for verification purposes). In other words, the share verification process does not (even information-theoretically) leak any information regarding the initial secret $s$, a fact that is not true with Feldman-VSS. This is useful when VSS is used as a subprotocol for distributed key generation, where an adversary is otherwise able to bias the outcome.
% \fi

% \iffalse
% \section{RandShare}
% \label{appendix:randshare}
% RandShare \cite{syta2017scalable} uses VSS as a subprotocol, extended by adopting the concept of barrier, a specific point in the protocol execution after which the output is fixed and guaranteed to complete successfully. In RandShare, the barrier is reached when the first honest node reveals his shares.
% RandShare proceeds as follows.

% \begin{enumerate}
%     \item \textbf{Share Distribution.} Each participant $P_j$ executes the distribution phase $\mathsf{VSS.ShareGen}(s^{(j)})$ as the dealer, publishing the polynomial commitments and securely sending the shares $s_i^{(j)}$ to all other participants $P_i$, $1\le i\le n$.
%     \item \textbf{Share Verification and Consensus.} To ensure that all honest participants have a consistent view of the secrets that will be recovered after the barrier or if the protocol run has already failed , a Byzantine agreement protocol is run in combination with $\mathsf{VSS.ShareVerify}$. This ensures that at least $t + 1$ honest participants have verified the secret and will be able to recover it. Let $\mathcal{S}$ be the set of secrets that have been agreed upon by the participants.
%     \item \textbf{Share Reconstruction.} If $\lvert \mathcal{S} \rvert \ge t + 1$, each of these secrets $s^{(j)}$ where $j \in \mathcal{S}$ is recovered by collecting at least $t + 1$ shares of the secret and reconstructing it using $\mathsf{VSS.Recon}$. Otherwise, the protocol fails.
%     \item \textbf{Aggregation.} Final randomness is $\mathcal{O}_r = \sum_{j \in \mathcal{S}} s^{(j)}$.

% \end{enumerate}
% \fi

% \iffalse
% \section{Distributed Key Generation (DKG)}
% \label{appendix:dkg}
% A DKG protocol should satisfy the following security requirements:
% \begin{itemize}
%     \item Correctness
%         \begin{enumerate}
%         \item All subsets of $t + 1$ shares provided by honest participants define the same unique secret key $x$.
%         \item All honest participants have the same value of public key $y=g^x$, where $x$ is the unique secret guaranteed above.
%         \item $x$ is uniformly distributed in $\mathbb{Z}_q$, and thus $y$ is uniformly distributed in $\mathbb{G}_q$ (subgroup of $\mathbb{Z}^*_p$ generated by $g$).
%         \end{enumerate}

%     \item Secrecy. No information on $x$ can be learned by the adversary except for what is implied by the value $y = g^x$.
% \end{itemize}
% One of the best known DKG schemes is Joint-Feldman \cite{pedersen1991threshold}, proposed by Pedersen. As discussed in \cite{gennaro1999secure}, Joint-Feldman does not guarantee uniform randomness or secrecy of the shared secret key. Joint-Pedersen, proposed in the same paper, uses Pedersen commitments to guarantee uniform randomness by increasing the number of communication rounds by one. Nevertheless, it has been shown that the public key biasability should not be a problem for applications that use DKG as a subprotocol for distributed randomness.

\subsection{Distributed Key Generation (DKG)}
\label{appendix:dkg}
One of the best known DKG schemes is Joint-Feldman \cite{pedersen1991threshold}, proposed by Pedersen.\\\\
%As discussed in \cite{gennaro1999secure}, Joint-Feldman does not guarantee uniform randomness or secrecy of the shared secret key. Joint-Pedersen, proposed in the same paper, uses Pedersen commitments \cite{pedersen1991non} to guarantee uniform randomness by increasing the number of communication rounds by one. Nevertheless, it has been shown that the public key biasability should not be a problem for applications that use DKG as a subprotocol for distributed randomness.\\\\
\noindent \textbf{Joint-Feldman.}
\label{appendix:jointFeldman}
 In this DKG scheme, each participant use Feldman-VSS to share a randomly chosen secret. The protocol is implemented as follows.
\begin{itemize}
    \item $\mathsf{DKG}(1^\lambda, t, n) \rightarrow (sk_i, pk_i, pk)$ proceeds in two phases---Sharing and Reconstruction.
    \begin{enumerate}
        \item In Sharing phase, each participant $P_i$ runs Feldman-VSS by choosing a random polynomial over $\mathbb{Z}_q$ of degree $t$, $p_i(z) = \sum_{j = 0}^{t} a_{ij} z^j$ and sending a subshare $s_{ij} = p_i(j)$ mod $q$ to each participant $P_j$ privately. \\
        To satisfy the verifiability portion of VSS, $P_i$ also broadcasts $C_{ik} = g^{a_{ik}}$ for $k = 0, \ldots, t$. Let the commitment corresponding to the secret be denoted by $y_i = C_{i0}$.

        Each participant $P_j$ also verifies the shares he receives from other participants by performing verification steps of Feldman-VSS on each subshare. If the verification for an index $i$ fails, $P_j$ broadcasts a complaint against $P_i$. If $P_i$ receives more than $t$ complaints, then $P_i$ is disqualified. Otherwise, $P_i$ reveals the subshare $s_{ij}$ for every $P_j$ that has broadcast a complaint. We call $\mathcal{C}$ the set of non-disqualified participants.

        \item Reconstruction phase calculates the keys based on $\mathcal{C}$.
        The group public key is calculated as $pk = \prod_{i \in \mathcal{C}} y_i$ where the individual public keys are $pk_i = y_i$. Each participant $P_j$'s share of the group secret is computed as $sk_j = \sum_{i \in \mathcal{C}} s_{ij}$ mod $q$. Though not computed explicitly, the group secret key $sk$ is equal to both $\sum_{i \in \mathcal{C}} a_{i0}$ mod $q$ and the Lagrange interpolation involving the shares $\{sk_j\}_{j \in \mathcal{C}}$.
    \end{enumerate}
\end{itemize}

% \fi
% \iffalse
% \subsection{Joint-Pedersen}
% \label{appendix:jointPedersen}
% The biasability of Joint-Feldman comes from the fact that the decision on who will be part of $\mathcal{C}$ is made after the adversary has seen the $y_i$'s of all the participants. This happens because $y_i = C_{i0}$ is published as part of the commitment (required to prove correctness of sharing). Joint-Pedersen solves this by decoupling the output $y_i$ from the commitments for proving correctness by using Pedersen-VSS. This results in $\mathcal{C}$ and the secret $x$ being determined first, and an additional run of Feldman-VSS to recover $y_i$'s. It is implemented as follows:
% \begin{itemize}
%     \item $\mathsf{DKG}(1^\lambda, t, n) \rightarrow (sk_i, pk_i, pk)$ involves two phases---Sharing and Reconstruction. However, the Reconstruction phase requires an additional run of Feldman-VSS to recover the public keys.
%     \begin{enumerate}
%     \item Sharing phase involves each participant $P_i$ running Pedersen-VSS by choosing two random polynomials over $\mathbb{Z}_q$ of degree $t$, $p_i(z) = \sum_{j = 0}^{t} a_{ij} z^j$ and $p'_i(z) = \sum_{j = 0}^{t} b_{ij} z^j$ and sending subshares ($s_{ij} = p_i(j)$, $s'_{ij} = p'_i(j)$) in mod $q$ to each participant $P_j$ privately and broadcasting the commitments $C_{ik} = g^{a_{ik}} h^{b_{ik}}$ for $k = 0, \ldots, t$ to prove correctness. Note that unlike Joint-Feldman, publishing $C_{ik}$ does not reveal any information about $y_i = g^{a_{i0}}$.\\
%     Each participant $P_j$ verifies the shares he receives from other participants by performing share verification step of Pedersen-VSS on each subshare. If the verification for an index $i$ fails, $P_j$ broadcasts a complaint against $P_i$.
%     If $P_i$ receives more than $t$ complaints, then $P_i$ is disqualified. Otherwise, $P_i$ reveals the subshare $(s_{ij}, s'_{ij})$ for every $P_j$ that has broadcast a complaint. We call $\mathcal{C}$ the set of non-disqualified participants.

%     \item Reconstruction is a two-part process. The first part involves calculating each participant's share of group secret and implicitly recovering the group secret based on $\mathcal{C}$, like in Joint-Feldman. Each participant $P_j$'s share of the group secret is calculated as $sk_j = \sum_{i \in \mathcal{C}} s_{ij}$ mod $q$. The group secret key $sk$ is equal to the Lagrange interpolation involving the shares $\{sk_j\}_{j \in \mathcal{C}}$.

%     The second part of Reconstruction phase involves extracting $pk$ by an additional run of Feldman-VSS because unlike Joint-Feldman, we do not have the corresponding shares $y_i = g^{a_{i0}}$'s required its calculation. Each participant $P_i \in \mathcal{C}$ exposes $y_i = g^{a_{i0}}$ as follows:
%         \begin{enumerate}
%             \item Each participant $P_i \in \mathcal{C}$ broadcasts the commitment to the coefficient of the secret polynomial $p_i(z)$ as $A_{ik} = g^{a_{ik}}$ for $k = 0, \ldots, t$. Let $y_i = A_{i0}$.
%             \item Each $P_j$ verifies the values broadcast by each other participant $P_i$ are consistent with the shares $s_{ij}$ shared earlier in a similar way as Feldman-VSS. If the verification fails, $P_j$ broadcasts a complaint against $P_i$ by posting the shares $s_{ij}$ and $s'_{ij}$.
%             \item For any participant $P_i$ that receives at least one valid complaint, all the other participants run the reconstruction phase of Pedersen-VSS to recover the secret polynomial $p_i(z)$.
%             \item Finally, the group public key is calculated as $pk = \prod_{i \in \mathcal{C}} y_i = \prod_{i \in \mathcal{C}} g^{a_{i0}}$ where $y_i$ is individual public key $pk_i$ for participant $P_i$.
%         \end{enumerate}
%     \end{enumerate}
% \end{itemize}
% \fi

% \iffalse
% \subsection{Escrow-DKG}
% \label{appendix:edkg}
% It does so by introducing a transparent escrow service that takes participants' deposits and can burn or redistribute them. It proceeds in similar phases as Joint-Feldman. However, any complaint of undesired behavior by a participant against another participant is arbitrated by the escrow and can result in deposits being slashed. The protocol fails once a complaint has been filed.

% Escrow-DKG \cite{david2019rational} extends DKG to a model where the participants are not expected to follow some predetermined set of instructions and instead are driven to maximize their profit. The modification of Escrow-DKG used in EVR, with $n$ participants and threshold $t$, can be described by the following algorithms:
% \begin{itemize}
%     \item $\mathsf{EscrowEnroll}(d, pk, H(C_{0})) \rightarrow \{0,1\}$ is used by a participant with public encryption key $pk$ to register with the escrow with deposit $d$ and hash of commitment to her partial secret $C_{0}$. In case of Feldman-VSS, $C_{0} = g^{s}$. It returns the success of enrollment.

%     \item $\mathsf{Commit}(s) \rightarrow (\{\mathsf{Enc}(pk_i, s_{i})\}, C)$ is used by a participant with secret $s$ to generate encrypted subshares and commitments by executing $\mathsf{VSS.ShareGen}(s)$. For Feldman-VSS, it outputs commitments $C_j = g^{a_j}$ for $0 \le j \le t$ to the coefficients of the secret sharing polynomial and subshares for every other participant $P_i$ encrypted via $\mathsf{Enc}(pk_i, s_{i})$. Each participant verifies the correctness of the sharing. The escrow also checks if the published $C_{0}$ matches with $H(C_{0})$ for participant $P_i$. Any complaint is arbitrated by the escrow and can result in deposits being slashed.

%     \item $\mathsf{Reveal}(A, \{x_i\}_{i \in A}) \rightarrow (x, X)$ takes a subset of $t + 1$ individual key shares and reconstructs the shared group secret $x$ using $\mathsf{VSS.Recon}$. In Feldman-VSS, each participant $P_i$ calculates their secret key share as $x_i = \sum_{j=1}^{n} s_j$ in mod $q$ and the group secret $x$ is reconstructed via Lagrange interpolation. Additionally, it also outputs its corresponding public key $X = \prod_{i=1}^{n} C_{i0}$ for verification.

%     \item $\mathsf{EscrowVerify}(x, X)\rightarrow\{0,1\}$ is used by the escrow to verify that the published secret $x$ is indeed the one that corresponds to $X$.
% \end{itemize}
% \fi

\subsection{Publicly Verifiable Secret Sharing (PVSS)}
\label{appendix:pvss}
PVSS can be described by the following algorithms.
\begin{itemize}
    \item $\mathsf{Setup}(\lambda) \rightarrow pp$ generates the public parameters $pp$, an implicit input to all other algorithms.
    \item $\mathsf{KeyGen}(\lambda) \rightarrow (sk_i, pk_i)$ generates the PVSS key pair used for encryption and decryption for node $i$.
    \item $\mathsf{Enc}(pk_i, m) \rightarrow c$ and $\mathsf{Dec}(sk_i, c) \rightarrow m'$ are subalgorithms used to encrypt and decrypt the share to node $i$, respectively. Both $\mathsf{Enc}$ and $\mathsf{Dec}$ may optionally output a proof (e.g. $\pi_{DLEQ}$).
    \item $\mathsf{ShareGen}(s) \rightarrow (\{\mathsf{Enc}(pk_i, s_i)\}, \{s'_i\}, \pi)$ with $s'_i = \mathsf{Dec}(sk_i, \mathsf{Enc}(pk_i, s_i))$ is a two-part process. First, the dealer with secret $s$ generates secret shares $\{s_i\}$ and sends each encrypted share $\mathsf{Enc}(pk_i, s_i)$ to node $i$ with an optional encryption proof $\pi_{Enc_{i}}$. Second, node $i$ decrypts the received encrypted share to generate $s'_i$ and broadcasts it with an optional decryption proof $\pi_{Dec_{i}}$. Note that it is possible that $s'_i \neq s_i$. In fact, $s'_i = h^{s_i}$ is standard due to certain PVSS implementation details. $\pi$ incorporates $\{\pi_{Enc_{i}}\}$ and $\{\pi_{Dec_{i}}\}$ as well as any auxiliary proof necessary.
    \item $\mathsf{ShareVerify}(\{\mathsf{Enc}(pk_i, s_i)\}, \{s'_i\}, \pi) \rightarrow \{0, 1\}$ verifies if $\mathsf{ShareGen}$ is correct overall using $\pi$.
    \item $\mathsf{Recon}(A, \{s'_i\}_{i \in A}) \rightarrow s'$ reconstructs the shared secret $s'$ via Lagrange interpolation (in the exponent) from a set $A$ of $t + 1$ nodes whose contributions are passed by the $\mathsf{ShareVerify}$ algorithm. Typically, $s' = h^s$ in the landscape.
\end{itemize}

PVSS is a secure VSS scheme providing the following additional guarantee:
\begin{itemize}
    \item Public Verifiability. If the $\mathsf{ShareVerify}$ algorithm returns 1, then the scheme is valid in a publicly verifiable manner with high probability $1 - \mathsf{negl}(\lambda)$.\\
\end{itemize}

% \iffalse
\noindent \textbf{Schoenmakers PVSS.}
\label{appendix:schoenmakersPVSS}
One of the most common PVSS schemes used in practice is one by Schoenmakers \cite{schoenmakers1999simple}. As typical, the setup involves $g, h \in \mathbb{G}_q$. Additionally, each participant $P_i$ generates a secret key $x_i \in \mathbb{Z}^*_q$ and registers $y_i = h^{x_i}$ as its public key.

\begin{itemize}
\item $\mathsf{ShareGen}(s) \rightarrow (\{\mathsf{Enc}(y_i, s_i)\}, \{s'_i\}, \pi)$ with $s'_i$ equal to $\mathsf{Dec}(x_i, \mathsf{Enc}(y_i, s_i))$ first involves production of $\{\mathsf{Enc}(y_i, s_i)\}$ by the dealer with secret $s$. Namely, the dealer picks a random polynomial $p$ of degree $t$ with coefficients in $\mathbb{Z}_q$
\[
p(x) = \sum_{i = 0}^{t} a_i x^i
\]
where $s = p(0) = a_0$ and computes $Y_i = \mathsf{Enc}(y_i, s_i) = y_i^{p(i)}$, which is sent to each node $i$ along with information needed to prove its correctness: $C_j = g^{a_j}$ for $0 \leq j \leq t$ such that $X_i = \prod_{j = 0}^{t} C_j^{i^j} = g^{p(i)}$ and $\mathsf{DLEQ}(g, X_i, y_i, Y_i)$ (see Appendix \ref{appendix:dleq}). Upon receiving $Y_i$, node $i$ computes $s'_i = \mathsf{Dec}(x_i, Y_i) = Y_i^{1 / x_i} = h^{p(i)}$ and generates information needed to prove its correctness: $\mathsf{DLEQ}(h, y_i, s'_i, Y_i)$.
\item $\mathsf{ShareVerify}(\{Y_i\}, \{s'_i\}, \pi) \rightarrow \{0, 1\}$ verifies the encryption proof of correctness $\mathsf{DLEQ}(g, X_i, y_i, Y_i)$ where $X_i$'s are computed from $C_j$'s as well as the decryption proof of correctness $\mathsf{DLEQ}(h, y_i, s'_i, Y_i)$.
\item $\mathsf{Recon}(A, \{s'_i\}_{i \in A}) \rightarrow h^s$ performs the following Lagrange interpolation in the exponent
\[
\prod_{i \in A} (s'_i)^{\lambda_{0, i, A}} = h^{\sum_{i \in A} p(i) \lambda_{0, i, A}} = h^{p(0)} = h^s
\]
where $\lambda_{0, i, A}$ denotes the Lagrange coefficients. Note that, unlike VSS, the scheme does not require the knowledge of the values $p(i)$ by the participants. The secret keys $x_i$ are not exposed as well and thus can be reused.
\end{itemize}

% \subsection{Scrape PVSS}
% \label{appendix:scrapePVSS}
% Following the work of \cite{cascudo2017scrape}, we define a $[n, k, d]$ code $C$ to be a linear error correcting code over $\mathbb{Z}_q$ of length $n$, dimension $k$, and minimum distance $d$. Its dual code $C^\perp$ is the vector space consisting of vectors $c^\perp \in \mathbb{Z}_q^n$ such that $\langle c, c^\perp \rangle = 0$ for all $c \in C$. Scrape's PVSS verification relies on the following lemma.
% \begin{lemma}
% If $v \in \mathbb{Z}_q^n \setminus C$ and $c^\perp$ is chosen uniformly at random in $C^\perp$, then $Pr\left[\langle v, c^\perp \rangle = 0\right]$ is exactly $\frac{1}{q}$.
% \end{lemma}

% Assuming that $n < q$, we harness Reed-Solomon codes $C$ of the form
% \[
% C = \{(p(1), p(2), ..., p(n)) : p(x) \in \mathbb{Z}_q[x], \deg p(x) \leq k - 1\}
% \]
% where $p(x)$ ranges over all polynomials in $\mathbb{Z}_q[x]$ of degree at most $k - 1$. Then $C$ represents a $[n, k, n - k + 1]$ code while $C^\perp$ is a $[n, n - k, k + 1]$ code given by
% \[
% C^\perp = \{(\mu_1 f(1), ..., \mu_n f(n)) : f(x) \in \mathbb{Z}_q[x], \deg f(x) \leq n - k - 1\}
% \]
% where $\mu_i = \prod_{j = 1, j \neq i}^n \frac{1}{i - j}$.

% Overall, Scrape PVSS is an optimization to Schoenmakers PVSS requiring $O(n)$ exponentiations to verify $n$ shares as opposed to $O(n t)$ exponentiations, leveraging the above coding theory related to Reed-Solomon codes. The idea is that the dealer, instead of committing to each polynomial coefficient via $C_j$, computes and distributes $v_i = g^{p(i)}$ directly, in which case each verifier needs to sample a random codeword $c^\perp = (c_1^\perp, ..., c_n^\perp)$ from $C^\perp$ and run a verification test involving all $v_i$'s at once.

% Scrape PVSS comes in two flavors: $PVSS_{DDH}$ and $PVSS_{DBS}$. The former relies on the DDH (decisional Diffie-Hellman) assumption while the latter uses a bilinear pairing and thus relies on the DBS (decisional bilinear square) assumption \cite{heidarvand2008public}.\\

% \noindent\underline{$PVSS_{DDH}$}
% \begin{itemize}
% \item $\mathsf{ShareGen}(s) \rightarrow (\{\mathsf{Enc}(y_i, s_i)\}, \{s'_i\}, \pi)$ with $s'_i$ equal to $\mathsf{Dec}(x_i, \mathsf{Enc}(y_i, s_i))$ is the same as that of Schoenmakers PVSS except the fact that $v_i = g^{p(i)}$ is computed and sent directly by the dealer as opposed to $C_j$'s. The encryption and decryption proofs $\mathsf{DLEQ}(g, v_i, y_i, Y_i)$ and $\mathsf{DLEQ}(h, y_i, s'_i, Y_i)$ remain unchanged.
% \item $\mathsf{ShareVerify}(\{Y_i\}, \{s'_i\}, \pi) \rightarrow \{0, 1\}$ additionally requires a verifier to sample a random codeword $c^\perp = (c_1^\perp, ..., c_n^\perp)$ from $C^\perp$ (dual code of $C$ corresponding to the secret sharing instance) and run the following verification test given by
% \[
% \prod_{i = 1}^n v_i^{c_i^\perp} = g^{\sum_{i = 1}^n p(i) c_i^\perp} = g^{\langle c, c^\perp \rangle} = g^0 = 1
% \]
% where $\langle \cdot, \cdot \rangle$ denotes an inner product. It is in this way that $O(n)$ exponentiations are needed to verify $n$ shares.
% \item $\mathsf{Recon}(A, \{s'_i\}_{i \in A}) \rightarrow h^s$ is the same as that of Schoenmakers PVSS.
% \end{itemize}

% \noindent\underline{$PVSS_{DBS}$}\\
% $PVSS_{DBS}$ provides a different flavor to $PVSS_{DDH}$, as it uses a bilinear pairing (without loss of generality) $e: \mathbb{G} \times \mathbb{G} \rightarrow \mathbb{G}_T$ with $\mathbb{G} = \langle g \rangle = \langle h \rangle$ for two independent generators of $\mathbb{G}$ and $\mathbb{G}_T$ denoting a cyclic group of prime order $q$. Fundamentally similar to $PVSS_{DDH}$, the scheme necessitates appropriate algebraic modifications accordingly while the final shared secret is $e(h^s, h)$ rather than $h^s$.
% \begin{itemize}
% \item $\mathsf{ShareGen}(s) \rightarrow (\{\mathsf{Enc}(y_i, s_i)\}, \{s'_i\}, \pi)$ with $s'_i$ equal to $\mathsf{Dec}(x_i, \mathsf{Enc}(y_i, s_i))$ is the same as in $PVSS_{DDH}$ except that both encryption and decryption proofs of correctness are no longer necessary.
% \item $\mathsf{ShareVerify}(\{Y_i\}, \{s'_i\}, \pi) \rightarrow \{0, 1\}$ instead requires a verifier to essentially replace the encryption and decryption proofs with verifying two pairing equations, respectively. The encryption proof $\mathsf{DLEQ}(g, v_i, y_i, Y_i)$ is replaced by verifying the pairing equation $e(v_i, y_i) = e(g, Y_i)$. The decryption proof $\mathsf{DLEQ}(h, y_i, s'_i, Y_i)$ is replaced by verifying the pairing equation $e(s'_i, y_i) = e(h, Y_i)$. The same verification test
% \[
% \prod_{i = 1}^n v_i^{c_i^\perp} = 1
% \]
% is also run.
% \item $\mathsf{Recon}(A, \{s'_i\}_{i \in A}) \rightarrow e(h^s, h)$ outputs $e(h^s, h)$ as the shared secret after the corresponding Lagrange interpolation in the exponent outputs $h^s$.
% \end{itemize}
% \fi

% \iffalse
% \subsection{Albatross}
% \label{appendix:albatross}
% Albatross \cite{cascudo2020albatross} achieves its improvement over Scrape using the following techniques.\\

% \noindent\textbf{Packed Shamir Secret Sharing.} Packed Shamir secret sharing is a generalization of Shamir secret sharing that allows to secret-share a vector of $\ell$ elements from a field rather than a single element. The key point is that every share is still one element of the field and therefore the sharing has the same computational cost of $\theta(n)$ exponentiations as regular Shamir secret sharing. This is accomplished by having the dealer choose a polynomial $p$ of degree $t+\ell-1$ uniformly at random and use a set of $\ell$ distinct points for secret sharing $\ell$ secrets, e.g. $(s_0, s_1, ..., s_{\ell - 1}) = (p(0), p(-1), ..., p(-(\ell - 1)))$, and another set of $n$ distinct points on the same polynomial for the shares sent by the dealer to each participant, e.g. $(p(1), ..., p(n))$. Any subset of $t+\ell$ points can be used to reconstruct the secret polynomial via Lagrange interpolation and recover the $\ell$ secrets. Note that the usual Shamir secret sharing corresponds to when $\ell = 1$.\\

% \noindent\textbf{Linear Perfect $t$-resilient functions.} Instead of computing the final randomness from PVSS reconstructions as $\prod_{j \in \mathcal{C}} h^{s^{(j)}}$ like in Scrape, Albatross uses a $t$-resilient function for randomness extraction.

% A $\mathbb{Z}_q$-linear $t$-resilient function is a linear function $\mathbb{Z}_q^r \rightarrow \mathbb{Z}_q^u$ given by a matrix $M \in \mathbb{Z}_q^{u \times r}$ such that the output is uniformly distributed in $\mathbb{Z}_q^u$ as long as $r-t$ coordinates of the input are uniformly distributed in $\mathbb{Z}_q^{r-t}$, even if the other $t$ coordinates are completely controlled by the adversary. Such a function can only exist if $u \le r-t$.

% In the presence of some participant withholding its secret $s$, PVSS only allows us to recover $h^s$ (for some public generator of $h$ of the group) instead of the secret $s$. This would require us to apply $t$-resilient function in the exponent. So, given $h_1, \ldots, h_r$ where $h_i = h^{x_i}$ and $x_i$ is private, goal is to extract $(\hat{h_1},\ldots, \hat{h_u}) \in \mathbb{G}_q^u$ which is uniformly random. It is achieved by applying the $t$-resilient function given by matrix $M$ to the exponents, i.e., $\hat{h_i} = h^{y_i}$ where $\vec{x} \mapsto \vec{y} = M \cdot \vec{x}$. This can be evaluated efficiently with $O(n^2 \log n)$ exponentiations by choosing $M$ to be a certain type of Vandermonde matrix and adapting the Cooley-Tukey Fast Fourier transform algorithm to work in the exponent (FFTE) \cite{cascudo2020albatross} of the group.

% In Albatross, we assume $n$ participants, of which the static adversary corrupts at most $t$ participants where $t < \frac{n - 1}{2}$. We define $\ell = n - 2t > 0$. The output of the protocol will be $\ell^2$ elements of $\mathbb{G}_q$. Similar to Scrape, the protocol proceeds in five phases: Commit, Verify, Reveal, Recover, and Output.
% \begin{enumerate}
%     \item \textbf{Commit.} Every participant $P_j$ acts as dealer for packed PVSS and publishes encrypted shares and encryption proofs for recovering $\ell$ secrets $h^{s^{(j)}_{0}}, \ldots, h^{s^{(j)}_{\ell-1}}$.
%     \item \textbf{Verify.} Every participant executes the sharing verification phase on every shared secret. Since verification is public, this fixes the set $\mathcal{C}$ of the first $n - t = t + \ell$ participants who have correctly shared.
%     \item \textbf{Reveal.} Every participant $P_j \in \mathcal{C}$ opens the Shamir secret $(s^{(j)}_{0}, \ldots, s^{(j)}_{\ell-1})$. The other participants verify its consistency with the sharing posted before. The protocol proceeds to the Recover phase only if all the participants in $\mathcal{C}$ have not opened their secrets correctly. Otherwise, it proceeds to Case 1 of Output phase.
%     \item \textbf{Recover.} For each participant $P_a$ that do not open their secret during the Reveal phase, other participants publish the decrypted shares of the secret. Once $t+\ell$ valid shares are published, Lagrange interpolation is used to reconstruct the polynomial and recover the secrets $h^{s^{(a)}_{0}}, \ldots, h^{s^{(a)}_{\ell-1}}$. Then it proceeds to Case 2 of Output phase.
%     \item \textbf{Output.}
%         \begin{itemize}
%             \item \textit{Case 1.} When all the participants in $\mathcal{C}$ have opened their secrets correctly, we have a $(n-t) \times \ell$ matrix $S$ with rows indexed by the participants $P_a \in \mathcal{C}$ and each row corresponding to its $\ell$ opened secrets $(s^{(a)}_{0}, \ldots, s^{(a)}_{\ell-1})$. The final randomness $\mathcal{O}$ with $\ell^2$ elements is computed by each participant as $\mathcal{O} = h^U$, where $U = M \cdot S \in \mathbb{Z}_q^{\ell \times \ell}$.

%             \item \textit{Case 2.} Otherwise, we have a $(n-t) \times \ell$ matrix $T$ with rows indexed by the participants $P_a \in \mathcal{C}$ where the row corresponding to $P_a$ is $(h^{s^{(a)}_{0}}, \ldots, h^{s^{(a)}_{\ell-1}})$. The final $\ell \times \ell$ randomness matrix $\mathcal{O}$ is computed as $\mathcal{O} = M \diamond T$ by applying FFTE to each column $T^{(j)}$ of $T$ producing column $\mathcal{O}^{(j)}$ of $\mathcal{O}$.
%         \end{itemize}
% \end{enumerate}

% \subsection{SecRand}
% \label{appendix:secRand}
% SecRand \cite{guo2020secRand} uses Scrape PVSS (see Appendix \ref{appendix:scrapePVSS} for details) as a subprotocol. After initial setup using $\mathsf{PVSS.KeyGen}$, SecRand proceeds in four phases---Share Distribution, Share Verification, Aggregation, and Reconstruction. The Share Distribution and Share Verification phases proceed in a similar way as Commit and Verify phases of Scrape. However, since SecRand does not have a Reveal phase like Scrape, the participants are not required to publish commitments to their secret $\mathsf{Com}(s, r_0)$ during Share Distribution phase. The other two phases proceed as follows.

% \begin{enumerate}
%     \setcounter{enumi}{2}
%     \item \textbf{Aggregation.} After the Share Distribution and Share Verification phases, every participant $P_i$ would have a valid encrypted share of each of the $n$ secrets, $\mathsf{Enc}(pk_i, s_i^{(j)})$ for $1 \le j \le n$. $P_i$ decrypts these shares to recover $\tilde{s}_i^{(j)}$ (need not be $s_i^{(j)}$ as per Appendix \ref{appendix:pvss}) and calculates its group secret share as follows:
%     $$\tilde{s}_i = \prod_{j=1}^{n}\tilde{s}_i^{(j)}$$
%     $P_i$ then broadcasts $\tilde{s}_i$ along with a proof of correct decryption $\pi_i$.
%     \item \textbf{Reconstruction.} Every participant verifies the correctness of decryption using $\mathsf{PVSS.ShareVerify}$. Once $t + 1$ valid group secret shares are distributed, the complete group secret $\tilde{s} = h^s$ is reconstructed through $\mathsf{PVSS.Recon}$. The final beacon output is $\mathcal{O}_r = H(\tilde{s})$.
% \end{enumerate}
% \fi
% \iffalse
% \section{Threshold Encryption}
% \label{appendix:thresholdEnc}

%     Following the work of \cite{cortier2013distributed}, a $(t, n)$-threshold encryption scheme should provide the following properties:
%     \begin{itemize}
%         \item Completeness. For any $1 \le t \le n$ and for every admissible plaintext $m$, if the keys have been honestly generated with $\mathsf{DKG}(1^\lambda, t, n)$, the plaintext encrypted with $\mathsf{Enc}(pk, m)$ and a set of at least $t + 1$ honest participants have computed the correct decryption shares with $\mathsf{DecShare}(sk_i, c)$, then we require $\mathsf{Rec}(A, c, pk, \{pk_i\}_{i \in A}, \{d_i\}_{i \in A}) = m$.
%         \item Robustness. For any ciphertext $c$ and any two sets $A \neq A'$ of $t + 1$ nodes with valid decryption shares such that $\mathsf{Rec}(A, c, pk, \{pk_i\}_{i \in A}, \{d_i\}_{i \in A}) \neq 0$ and $\mathsf{Rec}(A', c, pk, \{pk_i\}_{i \in A'}, \{d_i\}_{i \in A'}) \neq 0$, it holds that $\mathsf{Rec}(A, c, pk, \{pk_i\}_{i \in A}, \{d_i\}_{i \in A}) = \mathsf{Rec}(A', c, pk, \{pk_i\}_{i \in A'}, \{d_i\}_{i \in A'})$.
%         \item IND-CPA against static corruptions. A $(t, n)$ threshold cryptosystem is said to be IND-CPA secure if for any polynomial time adversary $\mathcal{A}$ corrupting at most $t$ participants at the beginning of the protocol, $\mathcal{A}$, who acts on behalf of corrupted nodes, has negligible advantage in a game $\mathsf{Exp}^{\mathsf{cpa}}_{\mathcal{A}}$ played against challenger, who acts on behalf of the remaining participants. In other words,
%         $$|Pr[\mathsf{Exp}_{\mathcal{A}}^{\mathsf{cpa}}(\lambda) = 1] - 1/2| < \mathsf{negl}(\lambda)$$

%         The game $\mathsf{Exp}^{\mathsf{cpa}}_{\mathcal{A}}$ proceeds as follows:
%         \begin{enumerate}
%             \item The adversary $\mathcal{A}$ and the challenger run together $\mathsf{DKG}(1^\lambda, t, n)$, at the end of which the adversary learns the individual secret and public keys of all the corrupted nodes. It also obtains the group public key $pk$.
%             \item $\mathcal{A}$ then chooses two admissible messages $m_0$, $m_1$ of equal length and sends it to the challenger.
%             \item The challenger randomly chooses one of them $\beta \leftarrow \{0, 1\}$ and sends $\mathsf{Enc}(pk, m_{\beta})$ back to the adversary.
%             \item Finally, $\mathcal{A}$ outputs its guess $\beta' \in \{0,1\}$.
%         \end{enumerate}
%         The output of the game is 1 if $\beta' = \beta$ and 0 otherwise and the advantage of $\mathcal{A}$ is defined as $|Pr[\beta' = \beta] - 1/2|$.
%     \end{itemize}
% \fi

\subsection{Threshold ElGamal Cryptosystem}
\label{appendix:thrElGamal}
A $(t, n)$-threshold ElGamal cryptosystem \cite{desmedt1990Threshold, fouque2001threshold, cherniaeva2019homomorphic}, with an elliptic curve $E$ over $\mathbb{F}_p$ and its cyclic subgroup $\mathbb{G}_q$ with generator $G$, is implemented as follows.
\begin{itemize}
    \item $\mathsf{DKG}(1^\lambda, t, n) \rightarrow (sk_i, pk_i, pk)$ runs a typical DKG.
    \item $\mathsf{Enc}(pk, m) \rightarrow (A, B)$ outputs ciphertext $c = (A, B) = (r G, m G + r \cdot pk)$ given $m, r \in \mathbb{Z}_q$ and $pk = sk \cdot G$.
    \item $\mathsf{DecShare}(sk_i, c) \rightarrow D_i$ outputs decryption share $D_i = sk_i \cdot A$ for $c = (A, B)$ using individual secret key $sk_i$.
    \item $\mathsf{Rec}(\tilde{A}, c, pk, \{pk_i\}_{i \in \tilde{A}}, \{D_i\}_{i \in \tilde{A}}) \rightarrow m$ reconstructs the point $D = sk \cdot A$ from $\{D_i\}_{i \in \tilde{A}}$ (given a set $\tilde{A}$ of $t + 1$ honest nodes) via Lagrange interpolation and outputs $m = B - D$.
\end{itemize}

% \iffalse
% \section{Verifiable Random Function (VRF)}
% \label{appendix:vrf}
% A VRF \cite{micali1999verifiable,dodis2005verifiable} is a function that, given an input $x$ and a secret key $sk$, generates a unique, pseudorandom output $y$ as well as a proof $\pi$ verifying that the computation has been done correctly. Due to $\pi$, it is possible to repeatedly generate new pseudorandom outputs with one $sk$ and varying inputs in a verifiable manner whereas otherwise (e.g. using a classical pseudorandom function) one needs to divulge the secret key and sacrifice its reusability for public verification purposes. It can be represented by the following tuple of algorithms:
% \begin{itemize}
% \item $\mathsf{Prove}(sk, x) \rightarrow (F_{sk}(x), \pi_{sk}(x))$ generates the pseudorandom output $F_{sk}(x)$ and its proof of correctness $\pi_{sk}(x)$ given input $x$ and secret key $sk$.
% \item $\mathsf{Verify}(pk, x, y, \pi) \rightarrow \{0, 1\}$ outputs 1 if it is verified that $y = F_{sk}(x)$ using the proof $\pi$ and 0 otherwise.
% \end{itemize}

% Furthermore, a VRF satisfies the following three properties:
% \begin{enumerate}
% \item Provability. If $(y, \pi) = \mathsf{Prove}(sk, x)$, then the tuple is accepted by the $\mathsf{Verify}$ algorithm such that $\mathsf{Verify}(pk, x, y, \pi) = 1$.
% \item Uniqueness. There does not exist $(y_1, \pi_1) \neq (y_2, \pi_2)$ such that $\mathsf{Verify}(pk, x, y_1, \pi_1) = \mathsf{Verify}(pk, x, y_2, \pi_2) = 1$.
% \item Pseudorandomness. The output is indistinguishable from a random number from a uniform distribution except with negligible probability. This can be written as follows.
% \[
% Pr\left[b = b' \middle\vert \begin{array}{l}
% (x, st) \leftarrow \mathcal{A}^{\mathsf{Prove}(\cdot)}_{1}(pk);\\
% y_0 = F_{sk}(x);\\
% y_1 \leftarrow \{0, 1\}^{\ell_{VRF}};\\
% b \leftarrow \{0, 1\};\\
% b' \leftarrow \mathcal{A}^{\mathsf{Prove}(\cdot)}_{2}(y_b, st)
% \end{array}\right] \leq \frac{1}{2} + \mathsf{negl}(\lambda)
% \]
% for any probabilistic polynomial-time algorithm $\mathcal{A} = (\mathcal{A}_1, \mathcal{A}_2)$, which does not query the oracle on $x$.
% \end{enumerate}

% \subsection{Verifiable Unpredictable Function (VUF)}
% \label{appendix:vuf}
% A VUF \cite{micali1999verifiable,dodis2005verifiable} is a VRF except the last property of pseudorandomness is replaced by the following unpredictability property.
% \begin{itemize}
% \item Unpredictability. The output is unpredictable except with negligible probability. In other words:
% \[
% Pr\left[y = F_{sk}(x) \middle\vert (x, y) \leftarrow \mathcal{A}^{\mathsf{Prove}(\cdot)}(pk)\right] \leq \mathsf{negl}(\lambda)
% \]
% for any probabilistic polynomial-time algorithm $\mathcal{A}$, which does not query the oracle on $x$.
% \end{itemize}
% \fi

% \iffalse
% \subsection{Distributed Verifiable Random Function (DVRF)}
% \label{appendix:dvrf}
% A DVRF satisfies the following properties (some of which are inherited from what a VRF should satisfy).
% \begin{itemize}
% \item Provability (Robustness). If $(y, \pi)$ is output by the $\mathsf{Combine}$ algorithm, then it is accepted by the $\mathsf{Verify}$ algorithm.
% \item Uniqueness. There does not exist $(y_1, \pi_1) \neq (y_2, \pi_2)$ such that $\mathsf{Verify}(pk, \{pk_i\}, x, y_1, \pi_1) = \mathsf{Verify}(pk, \{pk_i\}, x, y_2, \pi_2) = 1$.
% \item Pseudorandomness. An adversary corrupting $t$ nodes cannot distinguish a DVRF output from a uniformly random value except with negligible probability.
% \item Consistency. $\mathsf{Combine}(A, \{(y_i, \pi_i)\}_{i \in A})$ should yield the same $y$ for any set $A$ of $t + 1$ nodes whose outputs of $\mathsf{PartialEval}(sk_i, x)$ are accepted by $\mathsf{PartialVerify}(pk_i, x, y_i, \pi_i)$.
% \end{itemize}
% \fi

\begin{table*}[h!]
\aboverulesep=0ex
\belowrulesep=0ex
% \footnotesize
\renewcommand{\arraystretch}{1}
\begin{threeparttable}
\caption{Committee-Based DRB}
\label{table:committee-based}
\begin{tabularx}{\textwidth}{|c|c|c|l|l|}
\cmidrule{4-5}
\multicolumn{3}{c|}{} & \multicolumn{2}{c|}{Step 2: Beacon Output Generation} \\
\cmidrule{4-5}
\multicolumn{3}{c|}{} & \multicolumn{1}{c|}{Fresh per-node entropy} & \multicolumn{1}{c|}{$\mathcal{O}_{r - 1}$ \& precommitted per-node entropy} \\
\cmidrule{1-5}
\multirow{5}{*}{\spheading[0.44\textwidth]{\mbox{Step 1: Committee Selection}}} & \multirow{3}{*}[-2.8cm]{Public} & RR & \begin{tabular}{@{}l@{}}\textbf{BRandPiper}\\\textit{Step 1}: Node $i \equiv r \pmod n$\\\textit{Step 2}: Share-aggregate-reconstruct\end{tabular} & \\
\cmidrule{3-5}
& & RS & \begin{tabular}{@{}l@{}}\textbf{Ouroboros}\\\textit{Step 1}: Follow-the-satoshi \cite{bentov2014proof,kiayias2017ouroboros}\\\textit{Step 2}: Share-reconstruct-aggregate\end{tabular} & \begin{tabular}{@{}l@{}}\textbf{HydRand}\\\textit{Step 1}: Node $i \equiv \mathcal{O}_{r - 1} \pmod{\tilde{n}}$\\\textit{Step 2}: $\mathcal{O}_r = H(\mathcal{O}_{r - 1} \mathbin\Vert h^{e_{\tilde{r}}})$\\\\\textbf{GRandPiper}\\\textit{Step 1}: Node $i \equiv \mathcal{O}_{r - 1} \pmod{\tilde{n}}$\\\textit{Step 2}: $\mathcal{O}_r = H(h^{e_{\tilde{r}}}, \mathcal{O}_{r - 1}, ..., \mathcal{O}_{r - t})$\end{tabular} \\
\cmidrule{3-5}
& & LS & \begin{tabular}{@{}l@{}}\textbf{RandHound}\\\textit{Step 1}: Node $\argmin_{i} H(C \mathbin\Vert pk_i)$\\\textit{Step 2}: Share-reconstruct-aggregate\\\\\textbf{SPURT}\\\textit{Step 1}: Node $i \equiv r \pmod n$\\\textit{Step 2}: Share-aggregate-reconstruct\end{tabular} & \\
\cmidrule{2-5}
& \multirow{2}{*}[-0.55cm]{Private} & VRF & \begin{tabular}{@{}l@{}}\textbf{NV++}\\\textit{Step 1}: $VRF_{sk}(\mathcal{O}_{r - 1} \mathbin\Vert nonce) < target$\\\textit{Step 2}: Threshold ElGamal\end{tabular} & \begin{tabular}{@{}l@{}}\textbf{Algorand}\\\textit{Step 1}: $VRF_{sk}(\mathcal{O}_{r - 1} \mathbin\Vert role) < target$\\\textit{Step 2}: $\mathcal{O}_r = VRF_{sk}(\mathcal{O}_{r - 1} \mathbin\Vert r)$\\\\\textbf{Ouroboros Praos}\tnote{1}\\\textit{Step 1}: $VRF_{sk}(\mathcal{O}_{r - 1} \mathbin\Vert slot \mathbin\Vert \mathsf{TEST}) < target$\\\textit{Step 2}: $\mathcal{O}_r = H(\mathcal{O}_{r - 1} \mathbin\Vert epoch \mathbin\Vert \rho_1 \mathbin\Vert ... \mathbin\Vert \rho_K)$\end{tabular} \\
\cmidrule{3-5}
& & Hash chain & & \begin{tabular}{@{}l@{}}\textbf{Caucus}\tnote{2}\\\textit{Step 1}: $H(h_r \oplus \mathcal{O}_{r - 1}) < target$\\\textit{Step 2}: $\mathcal{O}_r = h_r \oplus \mathcal{O}_{r - 1}$\end{tabular} \\
\cmidrule{1-5}
\end{tabularx}
\begin{tablenotes}[flushleft]
\footnotesize
\item Note that public committee selection mechanisms (Section \ref{subsubsection:public-committee-selection}) include RR (round-robin), RS (random selection), and LS (leader-based selection) while details regarding private committee selection can be found in Section \ref{subsubsection:private-committee-selection}. For details on the two columns under beacon output generation, see Sections \ref{subsubsection:fresh} and \ref{subsubsection:precommitted}.
\item[1] The protocol is an epoch-based variant of Algorand. While $|\mathcal{C}_r|$ is expected to be one in Algorand (with 1 final winner per lottery and 1 lottery per round), that in Ouroboros Praos is expected to be $K$ where each epoch consists of $K$ slots and thus $K$ per-slot lotteries. (Each epoch is a round.) Parameters $slot$ and $epoch$ denote the slot and epoch numbers, respectively, and $\rho_i = VRF_{sk_i}(\mathcal{O}_{r - 1} \mathbin\Vert slot_i \mathbin\Vert \mathsf{NONCE})$ is returned by the slot leader of $slot_i$. $\mathsf{TEST}$ and $\mathsf{NONCE}$ are strings.
\item[2] In Caucus, a VRF is replaced by a hash function combined with a hash chain, i.e. a list ($h_1, ..., h_m$) with $h_r = H(h_{r + 1})$ for all $r = 1, ..., m - 1$ where $h_m = s$ for some random seed. A hash chain provides the functionality of provably committing to private inputs as one publicizes one $h_r$ at a time (i.e. $h_r$ in round $r$). While each participant independently generates a private hash chain, one downside is that the hash chain needs to be periodically regenerated, as $m$ is finite.
\end{tablenotes}
\end{threeparttable}
\end{table*}

% \section{Distributed Verifiable Random Function (DVRF)}
\subsection{DDH-DVRF}
\label{appendix:ddh-dvrf}
DDH-DVRF (from the decisional Diffie-Hellman assumption) is described by the following DVRF algorithms.
\begin{itemize}
\item $\mathsf{DKG}(1^\lambda, t, n)$ runs a typical DKG.
\item $\mathsf{PartialEval}(sk_i, x)$ outputs $(y_i, \pi_i)$ where $y_i = H(x)^{sk_i}$ and $\pi_i = \mathsf{DLEQ}(g, g^{sk_i}, H(x), H(x)^{sk_i})$ denoting the non-interactive Chaum-Pedersen protocol (see Appendix \ref{appendix:dleq}).
\item $\mathsf{PartialVerify}(pk_i, x, y_i, \pi_i)$ is equivalent to $\mathsf{DLEQ}\text{-}\mathsf{Verify}(g, pk_i, H(x), y_i, \pi_i)$ (Appendix \ref{appendix:dleq}) and verifies the correctness of the $\mathsf{PartialEval}$ algorithm using $\pi_i$.
\item $\mathsf{Combine}(A, \{(y_i, \pi_i)\}_{i \in A})$ outputs $(y, \pi)$ where $y = \prod_{i \in A} y_i^{\lambda_{0, i, A}}$ and $\pi = \{(y_i, \pi_i)\}_{i \in A}$. Details related to Lagrange coefficients $\lambda_{0, i, A}$ are included in Appendix \ref{appendix:lagrange}.
\item $\mathsf{Verify}(pk, \{pk_i\}, x, y, \pi)$ verifies all partial proofs via $\mathsf{PartialVerify}$ for all $i \in A$ from $\pi$ and checks $y = \prod_{i \in A} y_i^{\lambda_{0, i, A}}$.
\end{itemize}

\subsection{GLOW-DVRF}
\label{appendix:glow-dvrf}
Providing a compact proof $\pi$, GLOW-DVRF uses a bilinear pairing $e: \mathbb{G}_1 \times \mathbb{G}_2 \rightarrow \mathbb{G}_T$ similar to BLS (Appendix \ref{appendix:bls}) such that the setup includes hash functions $H_1: \{0, 1\}^* \rightarrow \mathbb{G}_1$ and $H_2: \mathbb{G}_1 \rightarrow \{0, 1\}^{y(\lambda)}$. While resembling DDH-DVRF, the following algebraic modifications are made due to pairings.
\begin{itemize}
\item $\mathsf{DKG}(1^\lambda, t, n)$ is adapted so that $pk_i$ resides in $\mathbb{G}_1$ while $pk$ resides in $\mathbb{G}_2$. This is achieved by letting $(pk_i, pk) = (g_1^{sk_i}, g_2^{sk})$ for $g_1 \in \mathbb{G}_1$ and $g_2 \in \mathbb{G}_2$. The purpose of this is to facilitate a compact proof in the final $\mathsf{Verify}$ step.
\item $\mathsf{PartialEval}(sk_i, x)$ outputs $(y_i, \pi_i)$ where $y_i = H_1(x)^{sk_i}$ and $\pi_i = \mathsf{DLEQ}(g_1, g_1^{sk_i}, H_1(x), H_1(x)^{sk_i})$.
\item $\mathsf{PartialVerify}(pk_i, x, y_i, \pi_i)$ is equivalent to $\mathsf{DLEQ}\text{-}\mathsf{Verify}(g_1, pk_i, H_1(x), y_i, \pi_i)$ and verifies the correctness of the $\mathsf{PartialEval}$ algorithm using $\pi_i$.
\item $\mathsf{Combine}(A, \{(y_i, \pi_i)\}_{i \in A})$ outputs $(y, \pi)$ where $\pi = \prod_{i \in A} y_i^{\lambda_{0, i, A}}$ and $y = H_2(\pi)$. Note that $\pi$ is a group element.
\item $\mathsf{Verify}(pk, \{pk_i\}, x, y, \pi)$ verifies $y = H_2(\pi)$ and a pairing equation $e(\pi, g_2) = e(H_1(x), pk)$.
\end{itemize}

\subsection{Dfinity-DVRF}
\label{appendix:dfinity-dvrf}
Dfinity-DVRF is given by the following DVRF algorithms.
\begin{itemize}
\item $\mathsf{DKG}(1^\lambda, t, n)$ is adapted so that both $pk_i$ and $pk$ reside in $\mathbb{G}_2$. This is achieved by letting $(pk_i, pk) = (g_2^{sk_i}, g_2^{sk})$ for $g_2 \in \mathbb{G}_2$. The purpose of this is to facilitate the check of some pairing equation in both $\mathsf{PartialVerify}$ and $\mathsf{Verify}$.
\item $\mathsf{PartialEval}(sk_i, x)$ outputs $(y_i, \pi_i)$ where $y_i = H_1(x)^{sk_i}$ and $\pi_i = \text{$\perp$}$. The reason for a null proof is that a pairing equation check is used in $\mathsf{PartialVerify}$ (i.e. the differentiator from GLOW-DVRF) with no need for any auxiliary information.
\item $\mathsf{PartialVerify}(pk_i, x, y_i, \pi_i)$ checks a pairing equation $e(y_i, g_2) = e(H_1(x), pk_i)$.
\item $\mathsf{Combine}(A, \{(y_i, \pi_i)\}_{i \in A})$ equals that in GLOW-DVRF.
\item $\mathsf{Verify}(pk, \{pk_i\}, x, y, \pi)$ equals that in GLOW-DVRF.
\end{itemize}

\subsection{Other Cryptographic Primitives}
% \iffalse
% \subsection{Commitment Scheme}
% \label{appendix:commitment}
% A cryptographic commitment \cite{blum1983coin} to message $m$ can be abstractly seen as a secure box (locked with a padlock) whose content is $m$. Initially, the sender $P$ commits to $m$ by putting it inside the box, locking it, and sending it to the receiver $V$ such that $P$ can later open the commitment (i.e. reveal $m$ to $V$) by sending $V$ the key that unlocks the padlock. These two messages can be represented by the following.
% \begin{enumerate}
% \item $C = \mathsf{Com}(m, r_0)$ is a commitment to message $m$ with fresh randomness $r_0$.
% \item $\mathsf{Open}(m, r_0)$ reveals the opening information necessary to verify the validity of $C$ with respect to $m$ and $r_0$.
% \end{enumerate}

% Obviously, such secure box needs to be secure, satisfying the following two properties.
% \begin{itemize}
% \item \textit{Binding property} requires that it is not possible for $P$ to change $m$ after $\mathsf{Com}(m, r_0)$ is given to $V$.
% \item \textit{Hiding property} requires that it is not possible for $V$ to learn $m$ before $\mathsf{Open}(m, r_0)$ is given to $V$ by $P$.
% \end{itemize}
% For further details (e.g. perfectly vs computationally binding and hiding), refer to \cite{damgaard1998commitment}.
% \fi

\subsubsection{Lagrange Interpolation}
\label{appendix:lagrange}
Given a non-empty reconstruction set $A \subset \mathbb{Z}_q$, the \textit{Lagrange basis polynomials} are given by $\lambda_{j, A}(x) = \prod_{k \in A \setminus \{j\}} \frac{x - k}{j - k} \in \mathbb{Z}_q[X]$ such that the \textit{Lagrange coefficients} $\lambda_{i, j, A} = \lambda_{j, A}(i) \in \mathbb{Z}_q$ enable the equality $p(i) = \sum_{j \in A} p(j) \lambda_{i, j, A}$ for any polynomial $p \in \mathbb{Z}_q[X]$ of degree at most $|A| - 1$. The process of computing this equality is called \textit{Lagrange interpolation}.

\subsubsection{BLS Signature}
\label{appendix:bls}
Introduced by Boneh, Lynn, and Shacham in 2003, the BLS signature scheme \cite{boneh2001short} consists of the following tuple of algorithms given a key pair $(sk, pk)$.
\begin{itemize}
\item $\mathsf{Sign}_{sk}(m) \rightarrow H_1(m)^{sk}$ outputs a digital signature $\sigma = H_1(m)^{sk}$ given secret key $sk$ and message $m$ where $H_1$ is a hash function such that $H_1: \{0, 1\}^* \rightarrow \mathbb{G}_1$.
\item $\mathsf{Verify}_{pk}(m, \sigma) \rightarrow \{0, 1\}$ verifies $\sigma$ given signature $\sigma$, message $m$, and public key $pk$ via $e(\sigma, g_2) = e(H_1(m), pk)$.
\end{itemize}
Note that BLS uses a bilinear pairing $e: \mathbb{G}_1 \times \mathbb{G}_2 \rightarrow \mathbb{G}_T$ with $\mathbb{G}_1 = \langle g_1 \rangle$, $\mathbb{G}_2 = \langle g_2 \rangle$, $\mathbb{G}_T$ denoting a cyclic group of prime order $q$, and the following requirements.
\begin{itemize}
\item Bilinearity. $e(g_1^x, g_2^y) = e(g_1, g_2)^{x y}$ for all $x, y \in \mathbb{Z}^*_q$.
\item Non-degeneracy. $e(g_1, g_2) \neq 1$.
\item Computability. $e(g_1, g_2)$ can be efficiently computed.
\end{itemize}

The threshold variant \cite{boldyreva2003threshold} of BLS (i.e. threshold BLS) requires $\mathsf{Sign}_{sk}(m)$ to be computed by $t + 1$ out of $n$ nodes. This is achieved via DKG such that $sk$ denotes the implied group secret key whereas each node broadcasts its partial signature $H_1(m)^{sk_i}$, $t + 1$ of which from the set $A$ of honest nodes are combined to generate
\[
H_1(m)^{sk} = \prod_{i \in A} \left(H_1(m)^{sk_i}\right)^{\lambda_{0, i, A}}
\]
via Lagrange interpolation in the exponent.

\subsubsection{NIZK of Discrete Logarithm Equality (DLEQ)}
\label{appendix:dleq}
Also known as the Chaum-Pedersen protocol \cite{chaum1992wallet}, the $\Sigma$ protocol \cite{damgaard2002sigma} for proving that the two discrete logarithms are equal without revealing the discrete logarithm value itself can be turned into a NIZK by applying the Fiat-Shamir heuristic \cite{fiat1986prove}. Namely, the prover can non-interactively prove the knowledge of $\alpha$ such that $(h_1, h_2) = (g_1^\alpha, g_2^\alpha)$ via $\pi_{DLEQ} = \mathsf{DLEQ}(g_1, h_1, g_2, h_2)$ with group elements in $\mathbb{G}_q$.\\

\noindent\underline{$\mathsf{DLEQ}(g_1, h_1, g_2, h_2)$}\\
\textit{Input:} $g_1, h_1, g_2, h_2 \in \mathbb{G}_q$, $\alpha \in \mathbb{Z}_q$\\
\textit{Output:} $\pi = (e, s)$
\vspace{-\topsep}
\begin{enumerate}
\item $A_1 = g_1^w, A_2 = g_2^w$ for $w \xleftarrow{R} \mathbb{Z}_q$
\item $e = H(h_1, h_2, A_1, A_2)$
\item $s = w - \alpha \cdot e \pmod q$
\item $\pi = (e, s)$
\end{enumerate}

\noindent\underline{$\mathsf{DLEQ}\text{-}\mathsf{Verify}(g_1, h_1, g_2, h_2, \pi)$}\\
\textit{Input:} $g_1, h_1, g_2, h_2 \in \mathbb{G}_q$, $\pi = (e, s)$\\
\textit{Output:} $b \in \{0, 1\}$
\vspace{-\topsep}
\begin{enumerate}
\item $A'_1 = g_1^s h_1^e, A'_2 = g_2^s h_2^e$
\item $e' = H(h_1, h_2, A'_1, A'_2)$
\item $b = \begin{cases}
1 & \text{if $e' = e$}\\
0 & \text{otherwise}
\end{cases}$
\end{enumerate}

\subsubsection{NIZK of Correct ElGamal Encryption (CE)}
\label{appendix:ce}
Via $\pi_{CE} = \mathsf{CE}(G, Q, A, B)$ \cite{cherniaeva2019homomorphic} where $G \in \mathbb{G}_q$ and $(Q, A, B) = (x G, r G, m G + r Q)$, the prover can non-interactively prove the knowledge of $(m, r)$ and thus prove the legitimacy of an ElGamal encryption (e.g. as opposed to exploiting its malleability). Note that the additive notation is used to handle points on an elliptic curve.\\

\noindent\underline{$\mathsf{CE}(G, Q, A, B)$}\\
\textit{Input:} $G, Q, A, B \in \mathbb{G}_q$, $m, r \in \mathbb{Z}_q$\\
\textit{Output:} $\pi = (e, z_1, z_2)$
\vspace{-\topsep}
\begin{enumerate}
\item $T = s_1 G + s_2 Q, E = s_2 G$ for $s_1, s_2 \xleftarrow{R} \mathbb{Z}_q$
\item $e = H(A, B, T, E)$
\item $z_1 = s_1 + m \cdot e \pmod q, z_2 = s_2 + r \cdot e \pmod q$
\item $\pi = (e, z_1, z_2)$
\end{enumerate}

\noindent\underline{$\mathsf{CE}\text{-}\mathsf{Verify}(G, Q, A, B, \pi)$}\\
\textit{Input:} $G, Q, A, B \in \mathbb{G}_q$, $\pi = (e, z_1, z_2)$\\
\textit{Output:} $b \in \{0, 1\}$
\vspace{-\topsep}
\begin{enumerate}
\item $T' = z_1 G + z_2 Q - e B, E' = z_2 G - e A$
\item $e' = H(A, B, T', E')$
\item $b = \begin{cases}
1 & \text{if $e' = e$}\\
0 & \text{otherwise}
\end{cases}$
\end{enumerate}

\end{document}