\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix-2020-09}
\usepackage[backend=bibtex,sortcites]{biblatex}
\addbibresource{bib.bib}
% Language and font encodings
% \usepackage[english]{babel}
% \usepackage[utf8]{inputenc}

% Sets page size and margins
% \usepackage[letterpaper,margin=1.5in]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
% \usepackage{hyperref}
\usepackage{seqsplit}
\usepackage{indentfirst}
\usepackage{tabu}
\usepackage{lipsum}
\usepackage{array}
\usepackage{tocloft}
\usepackage{float}
\usepackage[font=small,labelfont=bf]{caption}
\usepackage{etoolbox}
\usepackage{setspace}
\usepackage{braket}
% start table
\usepackage{tabularx,booktabs,multirow}
% \usepackage{dingbat}
\usepackage{diagbox}
\newcolumntype{C}{>{\centering\arraybackslash}X} % centered version of "X" type
\setlength{\extrarowheight}{1pt}
\newcommand{\spheading}[2][7em]{ % \spheading[<width>]{<stuff>}
    \rotatebox{90}{\parbox{#1}{\raggedright #2}}}
\usepackage{pifont} % http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}
\usepackage{threeparttable}
% end table
\AtBeginEnvironment{quote}{\singlespace\vspace{1em}\small}
\AtEndEnvironment{quote}{\vspace{1em}\endsinglespace}
\renewcommand{\arraystretch}{1.5}
\tabulinesep = 2mm

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{notes}{Notes}
\renewcommand\qedsymbol{$\blacksquare$}

\newcommand{\todo}[1]{\textcolor{red}{\textbf{TODO:} #1}}
\newcommand{\joenote}[1]{\textcolor{blue}{\textbf{JOE:} #1}}
\newcommand{\kevinnote}[1]{\textcolor{green}{\textbf{JOE:} #1}}
\newcommand{\aathiranote}[1]{\textcolor{purple}{\textbf{JOE:} #1}}

\title{\Large \bf A Survey on Distributed Randomness}
\author{
{\rm Kevin Choi}\\
New York University
\and
{\rm Aathira Manoj}\\
New York University
}
% \date{Spring 2021}

\begin{document}
\maketitle
\tableofcontents

\section{Introduction}
Generating periodic trustworthy randomness is crucial to applications ranging from sampling ballots for recounts in electronic voting \cite{adida2008helios} and choosing winning numbers in gambling and lottery services \cite{bonneau2015bitcoin} to leader election in proof-of-stake blockchains \cite{gilad2017algorand, kiayias2017ouroboros}, blockchain sharding \cite{al2017chainspace, kokoris2018omniledger, luu2016secure}, and selecting parameters for cryptographic protocols \cite{baigneres2015trap, lenstra2015random}. The process of generating reliable randomness is nontrivial, as obtaining access to good sources of randomness, even in terms of entropy alone, can be difficult and prone to errors.
% Randomness beacon
\todo{This needs re-writing to cast beacons as an ideal concept first, then describe some approximations. Beacons are not necessarily third-party}
\todo{Mention that this paper is not focusing on other beacons e.g. stock market}
\todo{Need a clearer transition of what a distributed randomness beacon is} \joenote{beacon or protocol? I would argue it's a distributed randomness protocol that is used as a beacon.}

\textbf{Randomness Beacons.} The concept of randomness beacon was first formalized by Rabin \cite{rabin1983Rabin} to describe an ideal service that emits fresh random numbers at regular intervals that no party can manipulate. Because no such ideal beacon exists, various solutions ranging from  centralized approaches, relying on a single source or organization to distributed approaches, decentralizing the randomness generation among a set of nodes, are used to approximate it. 

\textbf{Centralized Beacons.} While centralized approaches like relying on a trusted third party like NIST \cite{fischer2011public} or random.org \cite{haahr2010random} might be the simplest way to realize a beacon, it carries drawbacks typically associated with centralized services, in particular, risk of tampering, risk of benefit from prior knowledge of randomness and inability of the end-user to verify that the numbers they are getting from beacon are random. Users have to trust that the system is providing genuinely random numbers. For these reasons, it is strongly desirable to construct a beacon with no trusted parties or central point of failure.

\textbf{Biasable External Beacons.} The other alternative is to construct a beacon using publicly available external sources of entropy such as stock-market data \cite{clark2010use} or PoW blockchains like Bitcoin \cite{nakamoto2019bitcoin} as formalized in \cite{bonneau2015bitcoin}. However, such beacons are vulnerable to malicious insiders. 

Beacons realized using stock-market data are susceptible to manipulation from high-frequency traders through unnatural sales or purchases, particularly near the closing time of the market. To add to this, the extent to which the financial exchanges are in fact trusted parties that could manipulate or halt the beacon output also remains unclear.

Even though the decentralized nature and the large amount of computational work expended on maintaining a PoW blockchain makes them good sources of entropy, the security of such beacons are heavily dependent on the extent to which the miners can be bribed to withhold/discard competitor blocks. Delegating trust to  miners instead of a centralized authority becomes even more undesirable when the miners themselves are stakeholders in the output of the beacon.

\textbf{Distributed Randomness Beacons.} 
A natural approach to further distribute and decentralize trust is to rely on a set of mutually-distrustful nodes and use distributed protocols to generate randomness. The distributed randomness protocol can publish verifiable and unbiased random numbers periodically and be used as a beacon. We call such a beacon a Distributed Randomness Beacon (DRB). In this paper, we focus on distributed randomness protocols that can be used to realize a DRB.

\textbf{Contribution.} The goal of the paper is to systematize the current progress on the problem of generating reliable distributed randomness and devise a theoretical framework and generalization encompassing all distributed randomness protocols in the landscape. To aid comparison and discussion of properties and potential drawbacks and benefits, we provide an overview of these protocols along with the various cryptographic building blocks used to construct them. Drawing from a scattered body of knowledge, we identify two key components of a practical DRB's design --- selection of entropy providers and beacon output generation, which can be decoupled from each other. This enables a more insightful analysis of existing protocols which can also be extended to future protocols with similar design. Finally, we provide new insights and discussion on various techniques which can be used to improve existing protocols.

\textbf{Paper organization.} We organize the paper as follows. Preliminaries including a strawman DRB leveraging perfect synchrony (an ideal assumption), commit-reveal, our system model, and the definition of an ideal DRB are described in Section \ref{section:preliminaries}. Then from Section \ref{section:vdf} to \ref{section:dvrf}, protocols in the landscape are introduced in decreasing order of number of nodes providing \textit{marginal entropy} (i.e. randomness that is independently generated at a node level and becomes contributed to a beacon output during the newest round of a DRB) with the exception of those that are based on verifiable delay functions (which merit a separate section, namely Section \ref{section:vdf}, due to their idiosyncratic nature). Accordingly, Section \ref{section:commit-reveal-punish} and \ref{section:commit-reveal-recover} review protocols in which all nodes must provide marginal entropy while erroneous behaviors by some nodes are successfully counteracted by financial punishment and threshold secret sharing or threshold encryption, respectively. Section \ref{section:subset-based} illustrates protocols that include in the beginning of each round an extra step of subset selection, enabling only a subset of nodes to provide marginal entropy for the sake of efficiency (overall computational and communication complexity). In Section \ref{section:dvrf}, we furthermore have protocols that do not require any marginal entropy to generate a beacon output.

\section{Preliminaries}
\label{section:preliminaries}
We delineate the necessary preliminaries in this section, starting with the introduction of a strawman ``rock-paper-scissors'' DRB protocol assuming a perfectly synchronous network (with zero latency in message delivery between the message sender and the receiver) as well as that of the classical commit-reveal. Identifying problems in both, we define the security of an ideal DRB and describe our system model (including threat model) relevant in all protocols portrayed in this paper (unless stated otherwise).

\subsection{Strawman Protocol Assuming Perfect Synchrony}
Sourcing a joint random number from $n$ participants assuming perfect synchrony is straightforward. Consider the following ``rock-paper-scissors'' protocol where each participant $i$ for $i = 1, ..., n$ broadcasts its entropy share (i.e. independently generated randomness) $e_i \in \mathbb{N}$ to every other participant at the same time as per simultaneity observed in real life (say) in rock-paper-scissors. Naturally, its protocol output $\mathcal{O}$ can be given by
\[
\mathcal{O} = \sum_{i = 1}^n e_i
\]
where applying this mechanism $\tilde{r}$ times at $\tilde{r}$ chronological timestamps would yield a DRB in the form of $\{\mathcal{O}_r\}_{r = 1, ..., \tilde{r}}$.

While simple and agreeable, such rock-paper-scissors DRB is indeed a strawman solution in a non-ideal setting where the perfect synchrony assumption is never true. In fact, situations can change dramatically in a practical setting where participants can go offline (perhaps temporarily) due to network failure, messages can be delayed either non-significantly or significantly, and Byzantine attackers can try to predict or bias the randomness to their benefit.

Consider the following simple scenario without perfect synchrony: three participants $\{P_1, P_2, P_3\}$ coordinate to produce $\mathcal{O} = e_1 + e_2 + e_3$ where each $P_i$ sends $e_i$, and suppose $P_3$ already obtains the knowledge of $e_1$ and $e_2$ (due to non-zero message latency) before sending $e_3$ to $P_1$ and $P_2$ as the last step of the protocol. Then $P_3$ is able to set the output $\mathcal{O}$ to be whichever desirable value $\widetilde{\mathcal{O}}$, as it can choose $e_3 = \widetilde{\mathcal{O}} - e_1 - e_2$. Effectively, this protocol becomes centralized by $P_3$.

\subsection{Commit-Reveal}
\label{subsection:commit-reveal}
A classical improvement to the above issue, commit-reveal provides an intuitive way to source a joint random number from a group of participating nodes by introducing a cryptographic commit step before revealing. It runs as follows.
\begin{enumerate}
\item \underline{Commit.} Each participant $P_i$ broadcasts its cryptographic commitment $C_i = \mathsf{Com}(e_i, r_i)$ (with fresh randomness $r_i$) to its entropy share $e_i$ rather than $e_i$ itself. Note that $\mathsf{Com}(x, r)$ denotes a cryptographic commitment to $x$ with hiding and binding properties (see Appendix \ref{appendix:commitment}).
\item \underline{Reveal.} Once all participants have shared their corresponding commitments, each participant $P_i$ then opens the commitment by revealing the pair $(e_i, r_i) = \mathsf{Open}(e_i, r_i)$. In turn, $P_i$ verifies the received pair $(e_j, r_j)$ for $j \neq i$ by checking the equality $C_j = \mathsf{Com}(e_j, r_j)$. Given that these checks pass, the final output $\mathcal{O}$ can canonically be given by
\[
\mathcal{O} = \sum_{i = 1}^n e_i
\]
all of which can be repeated to prolong a DRB. If any of the preceding checks does not pass, however, the protocol aborts.
\end{enumerate}

Note that due to the additional commit step, it becomes impossible for one participant to centralize the process and set the final randomness to be whichever desirable value. Nonetheless, the problem of biasing still exists, as the last participant $P_k$ to reveal its share can in fact compute and check $\mathcal{O}$ earlier than others and hence can decide not to reveal $(e_k, r_k)$ if $\mathcal{O}$ is not to its liking. This is called the \textit{last revealer attack}.

\subsection{System Model}
Before defining the security of an ideal DRB (e.g. which should not be subject to the last revealer attack), we describe our system model first. Namely, we consider a system model with $\mathcal{P} = \{P_1, P_2, ..., P_n\}$ comprising $n$ participants (called nodes), also often denoted by $\mathcal{P} = \{1, 2, ..., n\}$ for the purpose of algebraic formulations without loss of generality. Out of $n$, up to $t$ faulty nodes (deemed \textit{Byzantine}) engage in incorrect behaviors during a protocol run, and an adversary $\mathcal{A}$ that controls such $t$ nodes is called \textit{$t$-limited}. Otherwise, nodes that are \textit{honest} abide by the specified protocol.

Given a standard public key infrastructure such that all nodes know each others' public keys, we assume the nodes are connected via point-to-point secure (providing authenticity) communication channels. All messages exchanged by honest nodes are digitally signed by the sender, and the recipient always validates each message before proceeding. By default, we assume a \textit{synchronous} network, in which there exists some known finite message delay bound $\Delta$. This means that an adversary can delay a message by at most $\Delta$. We call a network \textit{asynchronous} if there is no such $\Delta$ (though we know a message is delivered eventually) and \textit{partially synchronous} if there exists such $\Delta$ that is however unknown. Another equivalent definition of partial synchrony \cite{dwork1988consensus} requires that there exists an unknown time $GST$ (global stabilization time) after which known $\Delta$ is enforced such that the network effectively oscillates between synchrony and asynchrony.

Moreover, we assume a computationally bounded adversary $\mathcal{A}$ runs in PPT (probabilistic polynomial time) and that $\mathcal{A}$ cannot break standard cryptographic constructions such as a hash function, digital signatures, the discrete log problem, etc. The three ways in which $\mathcal{A}$ can deviate from a protocol are omitting a message (i.e. \textit{withholding attack}), sending invalid messages, and colluding to coordinate an attack based on private information shared among Byzantine nodes. Additionally, $\mathcal{A}$ has the power to perform a \textit{grinding attack}, in which $\mathcal{A}$ privately precomputes and iterates through as many combinations of inputs to an algorithm as possible in order to derive a desirable output. By default, we assume a \textit{static} adversary that chooses nodes to be corrupted before a protocol run whereas an \textit{adaptive} adversary can choose nodes to be corrupted at any time during a protocol run (although we assume a model where nodes remain corrupted once corrupted).

Our computational model is parametrized by a security parameter $\lambda$. We call a function $negl(\lambda)$ \textit{negligible} if for all $c > 0$ there exists a $\lambda_0$ such that $negl(\lambda) < \frac{1}{\lambda^c}$ for all $\lambda > \lambda_0$. The group elements $g, h \in \mathbb{G}$ are generators of $\mathbb{G}$ while $p, q$ denote primes such that $q \mid p - 1$ (unless stated explicitly). The notation $tuple[0]$ denotes the first element of $tuple$. Furthermore, we model any hash function $H(\cdot)$ as a random oracle. In the context of a distributed randomness beacon, we use $r$ to denote round number and $\mathcal{O}_r$ to denote the \textit{beacon output} (i.e. the distributed randomness output) in round $r$.

\subsection{Ideal Distributed Randomness Beacon}
Clearly, we should prevent anyone from tampering with (e.g. predicting, biasing, or delaying) each beacon output of a DRB in any way. Apart from this, the randomness should be verifiable by any third party. Based on these requirements, the overall security properties of an ideal DRB are given by the following.

\begin{definition}[Ideal distributed randomness beacon]
A distributed randomness beacon is \textit{ideal} or \textit{secure} if it satisfies the following four properties.
\begin{enumerate}
\item Bias Resistance (or Unbiasability). No PPT adversary $\mathcal{A}$ can bias $\mathcal{O}_r$, i.e. fix $c$ bits of $\mathcal{O}_r$ with probability greater than $\frac{1}{2^c} + negl(\lambda)$.
\item Unpredictability. The protocol satisfies \textit{$d$-unpredictability} for $d \in \mathbb{N}$, by which we mean the probability of $\mathcal{A}$ predicting the honest beacon output for any round greater than or equal to $r + d$ (where $r$ denotes the current round) is negligible.
\item Liveness. A la game-based security, we can define the liveness property by requiring that the advantage of $\mathcal{A}$ in attacking liveness denoted by $Pr[\mathcal{O}_r = \text{$\perp$}]$ (i.e. the probability that the honest beacon output at the end of round $r$ is null) is negligible, given a DRB that runs among honest participants and $\mathcal{A}$.
\item Public Verifiability. Any third party should be able to verify the beacon outputs based on public information. In other words, suppose the advantage of $\mathcal{A}$ in attacking public verifiability is given by
\[
\left\lvert 1 - Pr\left[b = b' \middle\vert \begin{array}{l}
y_0 = \mathcal{O}_r;\\
y_1 \leftarrow \mathcal{A}(priv_r, pub_r);\\
b \leftarrow \{0, 1\};\\
b' \leftarrow V(y_b, pub_r)
\end{array}\right]
\right\rvert
\]
where the protocol runs among honest participants and $\mathcal{A}$ (which has access to private information $priv_r$ in round $r$ as a $t$-limited participant), $pub_r$ denotes public information emitted in round $r$, and $V$ is a third party verifier. Then this advantage is negligible.
\end{enumerate}
\end{definition}

We next begin our discussion of various approaches to realizing an ideal DRB generally in decreasing order of number of nodes providing marginal entropy. The reasoning behind this is that while it is the most intuitive to require every node's marginal entropy (a la commit-reveal) for the sake of deriving joint randomness that all nodes can agree on, the narrative is often that a novel dose of cryptography can help eliminate the need for everyone's proactive generation of marginal entropy while maintaining the security of a DRB and therefore lead to better efficiency and scalability. We start with protocols based on verifiable delay functions.

\section{VDF-Based Protocols}
\label{section:vdf}
One way to prevent the last revealer attack is to add a delay function after collecting entropy, making it slow to compute the final beacon output. As long as the delay is suitably long, none of the participants would be able to determine the final output of the beacon and manipulate or withhold their shares to bias it. A verifiable delay function (VDF) \cite{boneh2018verifiable} can be used to accomplish this. \\\\
\textbf{Verifiable Delay Function (VDF)}\\
A VDF is a function that is slow to compute and easy to verify. It has the following properties which makes it suitable to be used to add delay:
\begin{itemize}
    \item It takes a specified number of sequential steps to evaluate which cannot be parallelized.
    \item The output can be efficiently and publicly verified without computing the VDF.
    \item For every input $x$, there exists a unique output $y$ only which can be successfully verified. In other words, one cannot come up with an accepting proof for a wrong output.
\end{itemize}
A VDF can be described via a set of three algorithms:
\begin{itemize}
\item $Setup(\lambda, T) \rightarrow pp$ is a randomized algorithm that takes a security parameter $\lambda$ and a time bound $T$  and outputs public parameters $pp$ sampled from some parameter space $PP$.
\item $Eval(pp, x) \rightarrow (y, \pi)$ takes public parameters $pp\in PP$, an input $x$ and outputs $y$ and a proof $\pi$.
\item $Verify(pp, x, y, \pi) \rightarrow \{accept, reject\}$ outputs $accept$ if $y$ is the correct evaluation of the VDF on input $(pp, x)$ and $reject$ otherwise.
\end{itemize}
 The two well-regarded VDF proposals, one due to Pietrzak \cite{pietrzak2018simple} and the other due to Wesolowski \cite{wesolowski2019efficient}, make use of the serial nature of exponentiation in a group of unknown order to implement a VDF. See Appendix \ref{appendix:vdf} for details.

VDFs can be used to extend naive commit-reveal scheme to prevent the last revealer attack. Additionally, VDFs can also be employed for constructing randomness beacons from public sources of randomness such as stock prices or proof-of-work blockchains (e.g. Bitcoin \cite{nakamoto2019bitcoin}, Ethereum \cite{wood2014ethereum}), or to construct an entirely new protocol (like RandRunner \cite{schindler2021randrunner}) altogether. These three approaches are summarized in the following sections.
\joenote{is this last approach out of scope?}

\subsection{Extending Commit-Reveal}
The work of \cite{lenstra2015random} proposes a solution to the last revealer attack in commit-reveal schemes using the Sloth function (a VDF precursor involving modular square roots in modulo prime) via Unicorn, a protocol that could in fact be extended to Unicorn++ (i.e. Unicorn except a VDF is utilized in place of Sloth). In doing so, Unicorn++ desirably achieves an exponential gap between computation and verification times unlike Unicorn. Besides the tool used (VDF vs Sloth), Unicorn++ and Unicorn share the same fundamental concept. Namely, each participant can skip the commit step and post their shares directly. It runs as follows.
\begin{enumerate}
    \item \textbf{Share:} Every participant $P_i$ broadcasts its share of randomness $r_i$. Once a consensus has been achieved on the shares, they are combined such that  $seed = H(r_1,\ldots, r_n)$.
    \item \textbf{Evaluate:} $seed$ is passed through a VDF via $VDF.Eval$ with a chosen delay parameter $T$ to generate the evaluation $y$ along with a proof $\pi$. The final beacon output is calculated as $\mathcal{O} = H(y) $, which is then posted and can be efficiently verified using $\pi$ through $VDF.Verify$.
\end{enumerate}
As long as $T$ is longer than the time period during which the values may be submitted including the bounded network delay (for synchronous communication model), \todo{need to tie this to the underlying network assumptions} even the last participant to submit their $r_i$ cannot predict the final beacon output because by the time a participant computes $VDF.Eval$, the Sharing phase would be over and would no longer be able to manipulate their shares. Such a beacon is unbiasable (and unpredictable) by an adversary that controls $n-1$ of the participants and uses only two rounds of communication when implemented over a public blockchain. \joenote{Why? how is this proved?} This stands in contrast to other threshold based secret sharing schemes (discussed later) which require multiple rounds of communication and an honest majority.

\subsection{Extending Public Randomness}
\joenote{this section might be better left out or treated separately, it's too informal and doesn't compare well to the other protocols}
Public sources of randomness such as stock prices or PoW bockchains are susceptible to manipulation from insiders (high frequency traders and miners respectively). This is feasible only if the beacon output can be computed quickly. As proposed in \cite{bunz2017proofs}, using a VDF with suitably long delay to compute the beacon output, similar to applying VDF to commit-reveal, would prevent a malicious actor from determining the beacon output from a given source before it becomes stale. The length of delay parameter which would be sufficient to prevent attacks, remains an informal conjecture due to the lack of a complete game-theoretic model capturing miner incentives in Nakamoto-style consensus protocols.

\subsection{RandRunner}
In the VDF-based schemes discussed so far, the rate at which random numbers are generated is limited by the delay parameter $T$ and require consensus on the inputs to VDF. RandRunner \cite{schindler2021randrunner} tackles these issues by building a deterministic chain outputs (no consensus on ordering required) using a VDF design that allows the participant that sets up the VDF to quickly compute it (using a secret trapdoor) and broadcast the output. Only if the participant fails to do when required does other participants step in and eventually obtain the same result by evaluating the VDF without the trapdoor. This results in much lower communication overhead and shorter intervals between random outputs when the network is not under attack. Trapdoor VDFs, initially described in \cite{wesolowski2019efficient} can be used to realize this. Randrunner uses \emph{strongly unique trapdoor VDFs}, which ensures that the result obtained via the trapdoor and by evaluation are always equal.\\\\
\textbf{Strongly Unique Trapdoor VDFs}\\
A Strongly Unique Trapdoor VDF has the following properties:
\begin{itemize}
    \item Any participant who knows the trapdoor can efficiently evaluate the VDF, and those who do not would need to take preset sequential steps to evaluate VDFs.
    \item It provides uniqueness even when the public parameters for the VDF are generated by the adversary. This is called strong uniqueness. 
\end{itemize}
A Strongly Unique Trapdoor VDF can be described by the algorithms $TVDF = (Setup,VerifySetup, TrapdoorEval, Eval, Verify)$. It extends a traditional VDF with the following algorithms:
\begin{itemize}
    \item $VerifySetup(\lambda, pp) \rightarrow (accept, reject)$ is used to verify the validity of the public parameters $pp$.
    \item $TrapdoorEval(pp,x,T,sk) \rightarrow (y, \pi)$ takes an input $x$ and $T$ along with trapdoor $sk$ and outputs $y$ and a proof $\pi$ such that the algorithm takes less than time $T$ to complete unlike $Eval$.
\end{itemize}
See Appendix \ref{appendix:tvdf} for details.  

Wesolowski’s VDF \cite{wesolowski2019efficient} does not achieve strong uniqueness because knowing the trapdoor allows an adversary to forge ``valid'' proofs for different invalid output values, thus breaking uniqueness and sequentiality properties. As a result, RandRunner uses Pietrzak's VDF \cite{pietrzak2018simple}. RandRunner starts with a one-time Setup and Bootstrapping phase. It is followed by Execution phase which generates random outputs every round. The phases proceed as follows.
\begin{enumerate}
\item \textbf{Setup and Bootstrapping Phase:} Each participant $i$ executes $TVDF.Setup$ to compute its public parameters $pp_i$ and the corresponding secret trapdoor $sk_i$ and broadcasts $pp_i$. At the end every participant should have the same set of public parameters $\mathcal{P} = \{ pp_1, pp_2, \ldots pp_n \}$.  Each participant then verifies the exchanged parameters by executing $TVDF.VerifySetup$ for all $pp_i \in \mathcal{P}$. This ensures that the assumptions for uniqueness property of Pietrzak’s VDF \cite{pietrzak2018simple} are fulfilled, even if the parameters are generated adversarially. The protocol is then bootstrapped with an initial value $\mathcal{O}_0$ broadcast to all the participants which is used to select the leader for the first round and serves as the input to the first (leader’s) VDF being evaluated.

\item \textbf{Execution Phase:} The execution of the protocol proceeds in rounds. Every round $r$ has a unique leader whose duty is to advance the protocol into the next round. A leader can be selected either in a round-robin style (i.e. taking turns in some permuted order based on $\mathcal{O}_0$) or in a way that involves randomized sampling (i.e. using the previous round’s randomness as seed). The implications of each will be discussed in Section \ref{subsubsection:public-subset-selection}. The execution can proceed in two ways depending on the honesty of the leader.
\begin{itemize}
    \item \textbf{Honest Leader (Common Case):} The leader advances the protocol into next round by using $TVDF.TrapdoorEval$ with its trapdoor secret key $sk_{l_r}$ to compute the output of VDF $y_r$ along with the proof $\pi_r$ and broadcasts it to everyone. As soon as such a message is received, the other participants checks the correctness of the received values using $TVDF.Verify$. If verified successfully, the beacon output for the round is computed as $\mathcal{O}_r = H(y_r)$, where $H$ is a hash function.
    \item \textbf{Dishonest Leader:} To deal with dishonest leaders, at the start of each round $r$, every non leader node starts computing the round’s VDF
    output using $TVDF.Eval$ using the public parameters of the leader $pp_{l_r}$ in the background and shares the output. Even though computing the VDF without the trapdoor takes at least $T$ sequential steps, it allows recovery in case the leader behaves maliciously. The strong uniqueness property guarantees that the resulting values are always equal to the ones computed by the leader.
\end{itemize}
\end{enumerate}

When the network is in good shape and the leaders are not malicious, RandRunner generates fresh randomness rapidly with only $O(n)$ communication complexity. Adversarial leaders and network delay increases the round duration, but is upper bounded by $T$. Communication complexity then depends on how the participants communicate with each other: $O(n^2)$ for reliable broadcast with low latency and $O(n \log n)$ for gossip based protocols with higher latency. Since the output of each round is deterministic and can be computed independently (even though with delay $T$), RandRunner retains liveness even when network connectivity breaks down completely. Assuming that the initial seed is not biased, the deterministic nature of RandRunner also prevents an adversary from manipulating the beacon outputs. 

However, RandRunner produces pseudorandom numbers (and not uniform random numbers) requiring periodic refreshes of initial seed and trails in terms of the quality of randomness when compared to other commit-reveal and VDF based schemes. Also, because of the leader based nature of RandRunner, an adversary (if leader) can always predict future outputs up to some extent and its advantage increases as long as a continuous sequence of adversarial nodes are selected as leaders. Assuming a $t$-limited having relative computational advantage of $\alpha$ with respect to honest nodes, RandRunner provides $d$-unpredictability where $d = t \alpha$ if honest nodes make progress faster than adversarial nodes. This is reduced to standard majority assumption $n > 2t$ only when $\alpha = 1$. If $\alpha > 1$, the fraction of honest nodes compared to adversarial nodes must also increase.
% secure against covert adversary

\section{Commit-Reveal-Punish}
\joenote{I would put this right after commit-reveal}
\label{section:commit-reveal-punish}
Instead of assuming that the adversary is limited in the maximum number of participants  that it can corrupt by $t$ and rest of the participants follow the protocol exactly and only deviate from it if corrupted by the adversary, a more realistic approach is to assume that all the participants are rational profit-maximizing entities, colluding or withholding to increase their profits. 

Commit-Reveal-Punish schemes assume that all participants are rational. To incentivize such a participant into joining the service, we assume an intrinsic value associated with the system, called \emph{jackpot} tied to the required deposits needed to join such a service. An escrow is used to collect initial deposits from the participants as part of their commitment, which can be slashed and/or redistributed if undesired behavior is detected. Such an escrow can be realized, for example, as a smart contract in Ethereum \cite{youcai2017randao, david2020economically} or by using timed commitments \cite{boneh2000timed} in Bitcoin implemented using ``transaction scripts'' and ``time-locks'' \cite{andrychowicz2014secure}.  Commit-Reveal-Punish schemes achieve unpredictability and unbiasability by using the escrow to either force every participant to reveal their shares \cite{youcai2017randao, andrychowicz2014secure, bentov2014use} or by using threshold secret sharing schemes to allow the shared secret to be recovered by a subset of participants \cite{david2020economically}. 

These two approaches are summarized in the following sections.
\subsection{Enforcing Every Reveal}
RANDAO \cite{youcai2017randao} extends a basic commit-reveal using an escrow realized using a smart contract in Ethereum. Similar to a commit-reveal scheme, it proceeds in three phases---Commit, Reveal, and Aggregate. During Commit phase, in addition to committing to their selected secrets, the participants are also required to send $m$ coins as deposit to the escrow contract. Failure to reveal the secret during Reveal phase by a participant results in their corresponding deposit of $m$ coins being taken away and redistributed among the rest of the participants. Finally, if none of the participants withhold, all the revealed secrets are combined and broadcast. \cite{andrychowicz2014secure, bentov2014use} use similar concept of monetarily penalizing a participant that aborts to realize secure multiparty lotteries in Bitcoin, which can also be extended to generate randomness. 

To ensure that honest participants are fully compensated when a participant fails to reveal, all these protocols require a high initial deposit of $O(n^2)$ coins per participant, where the jackpot and the number of participants are both $O(n)$. This makes withholding highly unprofitable as the $O(n^2)$ initial deposit is redistributed among the remaining honest participants (each receiving $O(n)$ coins as compensation). 

Zero-Collateral Lotteries \cite{miller2017zero} provides an alternative to realize multi-party lotteries without any deposits but comes at the cost of limited scalability, as they require participants to actively interact on-chain in $O(\log n)$ rounds. However, generating randomness from this lottery scheme would require non-trivial extensions to the protocol, as a lottery randomly outputs a winner whereas a DRB randomly outputs a value.\joenote{why is it non-trivial to take the value mod number of participants?}
\todo{I think there are more follow-up citations here}

\subsection{Rational Threshold Randomness}
Economically Viable Randomness (EVR) \cite{david2020economically} provides an alternative which only requires constant deposits (for tolerating $O(n)$ illicit profit with $n$ participants), allows a subset of participants to reconstruct the shared randomness and yet maintains the trustworthiness of the randomness produced. The escrow is used to ensure unpredictability and unbiasability of the protocol in the following ways: 
\begin{itemize}
    \item \textbf{Unpredictability:} It introduces a informing mechanism to prevent collusion among participants. If the escrow is notified of collusion, it rewards the informer and slashes the deposits of all other participants (``collective punishment''). This makes informing more profitable than colluding. Realizing this, entities are discouraged to collude, fearing another entity would frame.
    \item \textbf{Unbiasability/Robustness:} Any withholding of shares or failure to reconstruct the final random output is disincentivized by the escrow collectively punishing everybody by slashing all the deposits.
\end{itemize}

Unlike earlier commit-reveal-punish schemes, collective punishment is inevitable in EVR when informing happens (unpredictability breaks) as it is impossible to detect who colluded. Even though collective punishment is not necessary when participants fail to recover the final output, EVR enforces it to allow reconstruction to be done off-chain, without the involvement of escrow. 

EVR uses Escrow-DKG \cite{david2019rational}, which is an extension of Distributed Key Generation (DKG) protocol \cite{gennaro1999secure, gennaro3revisiting}. DKG allows a set of $n$ participants to collectively generate a pair of private and public keys, $(x,X = g^x )$, in such a way that $X$ is publicly known while $x$ is shared by $n$ servers via a Verifiable Secret Sharing (VSS) scheme \cite{feldman1987practical, pedersen1991non}.\\\\
\textbf{Verifiable Secret Sharing (VSS)}\\
A $(t, n)$-secret sharing scheme \cite{shamir1979share, blakley1979safeguarding} allows a dealer to share a secret $s = p(0)$ for some $p \in \mathbb{Z}_q[X]$ among a set of $n$ participants each holding $p(i)$ for $i = 1, ..., n$ in such a way that in the reconstruction phase any subset of $t+1$ or more honest participants can compute the secret $s$ via \textit{Lagrange interpolation} (Appendix \ref{appendix:lagrange}), but subsets of size $t$ or fewer cannot. However, a malicious dealer can provide incorrect shares. A Verifiable Secret Sharing (VSS) scheme solves this by providing the following additional property:
\begin{itemize}
    \item Every participant can verify that the share they've received from the dealer is a valid piece of the secret without revealing the secret.
\end{itemize}
VSS can be described by the following algorithms.
\begin{itemize}
    \item $Setup(\lambda) \rightarrow pp$ generates the public parameters $pp$ and is an implicit input to all other algorithms.
    \item $ShareGen(s) \rightarrow (\{s_i\}, C)$ is executed by the dealer with secret $s$ to generate secret shares $\{s_i\}$ (each of which is sent to node $i$ correspondingly) as well as commitment $C$ to the secret sharing polynomial of degree $t$.
    \item $ShareVerify(s_i, C) \rightarrow \{0, 1\}$ verifies the correctness of the share $s_i$ using $C$.
    \item $Recon(A, \{s_i\}_{i \in A}) \rightarrow s$ reconstructs the shared secret $s$ via Lagrange interpolation from a set $A$ of $t + 1$ nodes whose shares are passed by the $ShareVerify$ algorithm.
\end{itemize}
See Appendix \ref{appendix:vss} for details.\\\\
\textbf{Distributed Key Generation (DKG)}\\
DKG protocol allows a set of $n$ participants to collectively generate the keys required for a threshold cryptosystem (i.e. the group public key, the individual secret keys, and the corresponding public keys) without the help of a trusted party. However, a DKG protocol is more than a secret sharing protocol and has the following properties:
\begin{itemize}
    \item It typically uses multiple instances of VSS, with each participant acting as a dealer for its corresponding share of secret. 
    \item Unlike secret sharing protocols where the secret shares are not reusable after everyone has learned the group secret, DKG shares can be used repeatedly for an unlimited number of time without ever recovering the group secret explicitly.
\end{itemize}
A DKG is described by the following algorithm:
\begin{itemize}
    \item $DKG(1^{\lambda}, t, n) \rightarrow (\vec{SK}, \vec{PK}, pk)$ is a distributed key generation algorithm that takes a input security parameter $1^\lambda$, the number of participants $n$ and the threshold parameter $t$ and outputs a group public key $pk$, the individual secret keys $\vec{SK} = \{sk_1, sk_1, \ldots, sk_n\}$, and the corresponding public keys $\vec{PK} = \{pk_1, pk_2, \ldots, pk_n\}$
\end{itemize}
 See Appendix \ref{appendix:dkg} for details.\\\\
\textbf{Escrow-DKG}\\
Escrow-DKG \cite{david2019rational}, is variant of DKG in the Joint-Feldman
family \cite{gennaro1999secure, gennaro3revisiting}. However, it differs from traditional DKG in its underlying model as follows:
\begin{itemize}
    \item Whereas traditional DKG protocols assume a $t$-limited adversary, Escrow-DKG makes it a priori possible that an adversary can corrupt more than $t$ servers. However, it assumes the participants are rational in a setting where collusion of more than $t$ nodes would be financially punished such that, effectively, we have a $t$-limited adversary.
    \item It assumes a trusted escrow service that substitutes and enhances the broadcast channel usually assumed in traditional protocols.
    \item While runs of traditional DKG protocols always succeed, Escrow-DKG might fail.
\end{itemize}
Escrow-DKG is usually used to generate keys for secret sharing. EVR adapts it to generate random numbers with the algorithms $EDKG = (EscrowEnroll, Commit, Reveal, EscrowVerify)$. $EDKG.EscrowEnroll$ is used by participant to register with the escrow by submitting a deposit along with the commitment to a secret. $EDKG.Commit$ proceeds in a similar way as $VSS.ShareGen$. $EDKG.Reveal$ reconstructs the shared secret using valid shares via Lagrange interpolation. $EDKG.EscrowVerify$ is used by the escrow to verify the consistency of the recovered secret with the published shares. See Appendix \ref{appendix:edkg} for details.

In EVR, a smart contract $\mathcal{G}$ plays the role of the escrow. It proceeds in five phases---Register, Setup, Commit, Inform, and Reveal.
\begin{enumerate}
    \item \textbf{Register:} Every participant registers themselves with $\mathcal{G}$ by executing $EDKG.EscrowEnroll$ and depositing 1 coin per secret share.
    \item \textbf{Setup:}  Based on the number of coins collected (denoted by $n$), $\mathcal{G}$ sets the parameters of the following.
    \begin{itemize}
        \item $EDKG.Commit$: the total number of participants registered $n$ and threshold parameter $t = \frac{2n}{3}$.
        \item EVR: the bound on the illicit profit that EVR can sustain $P= n-t = \frac{n}{3}$ and the informing reward $\ell = n$.
    \end{itemize}
    \item \textbf{Commit:} The registered participants execute $EDKG.Commit$ to share their secrets. Detection of any misbehavior during Commit results in $\mathcal{G}$ aborting the protocol and returning the deposits.
 \item \textbf{Inform:} If Commit completes successfully, it enters the Inform phase where any participant who knows the group secret $x$ by colluding can inform $\mathcal{G}$ and get high informing reward ($\ell$) for it. The reward comes from the participants’ deposits, which are all confiscated in this case. Otherwise, it enters into the Reveal phase.
    \item \textbf{Reveal:} The participants distribute their shares and reconstruct $x$ using $EDKG.Reveal$ off-chain. The reconstructed secret is verified by $\mathcal{G}$ by executing $EDKG.EscrowVerify$. Participants get their deposits back if successfully verified. In case the participants fail to reconstruct and publish $x$ in a timely manner, $\mathcal{G}$ confiscates the deposits of all the participants.
\end{enumerate}
Given $n$ total coins deposited during Register, EVR assumes that no participant owns more than $n/3$ of the coins, either deposited to escrow or externally (which is impractical in real world) and sets a bound on the maximum illicit profit that EVR can sustain (denoted by $P$). With these limits in place, EVR makes any malicious behavior unprofitable as follows. 

Since nothing can be gained from failing Commit, rational participants do not fail it. Hence, the malicious behavior of participants is limited to withholding shares to abort the protocol during Reveal or colluding to learn the secret before Reveal. With a threshold $t$, $n-t$ withholding participants can abort the protocol and can cause all $n$ coins being slashed by the escrow. Setting $P$ to $n-t$ makes withholding unprofitable to those participants. Setting the informing reward ($\ell$) to $n$ (taken from the deposits) makes informing more profitable than any illicit profit, preventing participants from colluding fearing another would inform. The high informing reward and limited coins owned by participants also makes coalitions enforced via external contracts impossible.

Even though EVR works well within the given bounds, enforcing them in real world can be tricky especially when the participants are pseudo-anonymous.

\joenote{Could use a much more intuitive explanation}
\section{Commit-Reveal-Recover Variants}
\label{section:commit-reveal-recover}
\joenote{Positive note-this is the kind of intuitive explanation/transition that the paper needs at every turn!}
Extending the basic commit-reveal paradigm, commit-reveal-recover variants defend against the last revealer attack by providing a mechanism to recover or reconstruct the secret in case some participants refuse to reveal. This is achieved by using techniques based on threshold secret sharing or threshold encryption. These protocols assume $t$-limited adversary and require the cooperation of at least $t + 1$ nodes to reconstruct the secret such that two desirable properties are achieved simultaneously: there is no need for all $n$ nodes to reveal while $t$ Byzantine nodes cannot collude to preemptively reconstruct the secret to their benefit. Guaranteeing availability as a result, the protocols allow the honest participants to reconstruct the secret by themselves even if all the corrupted participants decide to withhold.

\subsection{Threshold Secret Sharing based}
Threshold Secret Sharing based schemes use a $(t,n)$-threshold scheme to share a secret among a set of $n$ participants in such a way that any subset of $t+1$ or more participants can reconstruct it. To allow not only the participants but any external party to verify the correctness of the sharing and reconstruction, most threshold secret sharing schemes use Publicly Verifiable Secret Sharing (PVSS)  \cite{schoenmakers1999simple, cascudo2017scrape} instead of VSS as a subprotocol. Scrape \cite{cascudo2017scrape}, Albatross \cite{cascudo2020albatross}, and SecRand \cite{guo2020secRand} use PVSS whereas RandShare \cite{syta2017scalable} uses VSS (although it could be adapted to use PVSS as well).\\\\
\textbf{Publicly Verifiable Secret Sharing (PVSS)}\\
A Publicly Verifiable Secret Sharing (PVSS) scheme extends VSS by providing the following property:
\begin{itemize}
    \item Along with the participants verifying their own shares, any external party can verify the correctness of sharing and reconstruction of a secret with the help of zero knowledge proofs posted by the dealer and the reconstructing participants respectively.
\end{itemize}
A PVSS scheme can be realized by the algorithms $PVSS = (Setup, KeyGen, Enc, Dec, ShareGen, ShareVerify, Recon)$. To provide public verifiability, PVSS extends VSS by using keys generated by $PVSS.KeyGen$ for encryption and decryption of shares using the algorithms $PVSS.Enc$ and $PVSS.Dec$ respectively. Unlike VSS, $PVSS.ShareGen$ generates encrypted shares along with auxiliary proofs needed to verify correctness of sharing. $PVSS.ShareVerify$ verifies the overall correctness (including the consistency of encrypted and decrypted shares) using these proofs. $PVSS.Recon$ recovers the shared secret. See Appendix \ref{appendix:pvss} for details.

Commit-reveal-recover variants based on threshold secret sharing involving $n$ participants as entropy providers starts with the sharing phase, where every participant selects a randomly chosen secret and distribute valid PVSS/VSS shares of the secret to all the other participants. At the end of the sharing phase, $n$ secrets and $n(n-1)$ shares would be distributed and each participant would have a share of each of the $n$ secrets. In an ideal scenario, all the participants reveal their committed secrets and all the $n$ secrets can be aggregated to compute the final randomness for the round, without ever needing to use the shares. However, in the presence of withholding participants, protocols either proactively or reactively use the shares to reconstruct the final secret. The reconstruction is done using Lagrange interpolation, which recovers the unique secret given any subset of $t+1$ valid shares of it with $O(t^2)$ computations. Based on this, we can further divide the schemes into the following subcategories:

\subsubsection{Commit-Reveal-Recover}
It extends the naive commit-reveal scheme by an additional recovery phase for force-opening and reconstructing only those secrets that that were withheld during the reveal phase. Given that, optimistically, no force-open will be required and the communication complexity and the duration of each round is kept in check. However, as with all schemes based on threshold secret sharing, it comes at the cost of additional data that needs to be shared to allow reconstruction. Force-opens requires further communication (and data sharing) between the participants expanding the duration of each round, which may not be desirable in some cases. Scrape adopts this technique in its random number generation by having every dealer publish a commitment to the secret, which is opened in the Reveal phase, in addition to the encrypted shares and the verification information needed for PVSS scheme.\\

\textbf{Scrape}\\

\joenote{is this a one-round protocol? General note-need a framework for one round vs. two round protocols?}
\joenote{too much whitespace with this blank line after scheme name}
The main building block of Scrape is a PVSS scheme that requires only $O(n)$ exponentiations to verify $n$ shares (see Appendix \ref{appendix:scrapePVSS} for details). This makes it scalable when compared to schemes that use Schoenmakers PVSS (see Appendix \ref{appendix:schoenmakersPVSS}) which require $O(n t)$ exponentiations, making them quadratic when $t = n/2$ (where $t$ is the threshold). The initial setup for Scrape requires generating public keys $pk_i$ for each of the $n$ participants using $PVSS.KeyGen$. 
  The protocol then proceeds in five phases---Commit, Verify, Reveal, Recover, and Aggregate.
\begin{enumerate}
\item \textbf{Commit:} Every participant $P_j$ executes $PVSS.ShareGen(s^{(j)})$ as the Dealer D and publishes the encrypted shares $Enc(pk_i, s^{(j)}_i)$ for $1 \le i \le n$ and verification information $\pi_D^{(j)}$, also learning the random secret $h^{s^{(j)}}$. $P_j$ also publishes a commitment to the secret exponent $\mathsf{Com}(s^{(j)}, r_j)$ (with fresh randomness $r_j \leftarrow \mathbb{Z}_q$).
\item \textbf{Verify:} For every set of published encrypted shares and the verification information $\pi_D^{(j)}$, all participants run the verification phase $PVSS.ShareVerify$ corresponding to verification of correct encryption. Let $\mathcal{C}$ be the set of all participants who published commitments and valid shares.
\item \textbf{Reveal:} Once $t+1$ participants have distributed their commitments and valid shares, every participant $P_j$, $j \in \mathcal{C}$ opens its commitment, and shares $\mathsf{Open}(s^{(j)}, r_j)$.
\item \textbf{Recover:} For every participant $P_a \in \mathcal{C}$ that does not publish $\mathsf{Open}(s^{(a)}, r_a)$ in the Reveal phase, other participants $P_j$ for $1 \leq j \leq n$ reconstructs $h^{s^{(a)}}$ (not $s^{(a)}$) by running the reconstruction phase of the PVSS scheme $PVSS.Recon$, which requires each participant to publish their decrypted shares $s_j^{(a)}$ and the corresponding proof of correct decryption $\pi_j^{(a)}$ that pass $PVSS.ShareVerify$.

\item \textbf{Aggregate:} The final randomness for the round is computed as $\mathcal{O}_r = \prod_{j \in \mathcal{C}} h^{s^{(j)}}$.
\end{enumerate}
Note that what a participant $j$ can decrypt during the Recover phase is not really the Shamir share $s^{(j)}$, but rather $h^{s^{(j)}}$ . However these values are enough to reconstruct $h^s$ which acts as a uniformly random choice in the group by the participant who chose $s$. \\

\textbf{Albatross}\\

\joenote{this overview is at a good level of detail, but start with spelling out exactly what the difference in properties/performance is}
Albatross extends Scrape to provide an improved amortized computational complexity at the cost of suboptimal corruption tolerance. An execution of Albatross with $n$ participants, out of which up to $t = n/2 - \theta(n)$ may be corrupt (as compared to $t = n/2$ in Scrape), generates $\theta(n^2)$ uniformly random values at the end of each round (vs one uniformly random value in Scrape), requiring in the worst case an amortized cost per participant of $\theta(\log n)$ exponentiations per random value (as compared to $\theta(n^2)$ exponentiations per participant per random value required in Scrape). This is achieved via two techniques: first, packed Shamir secret sharing based PVSS to share $\ell$ secrets instead of 1 without increasing the computational cost; second, the use of linear $t$-resilient functions to extract more uniform randomness from a vector of group elements from which an adversary may control some of the values . 

Similar to Scrape, Albatross also has Commit, Verify, Reveal, and Recover phases. However, unlike Scrape, each participant shares $\ell$ secrets instead of 1, resulting in $n \times \ell$ total secrets shared at the end of Commit phase. Verify, Reveal, and Recover phases proceed in a similar way as Scrape. After a subset of $(n-t) \times \ell$ secrets are revealed/recovered, instead of aggregating them to produce a single random output like in Scrape, we use a linear t-resilient function to extract final randomness of $\ell^2$ elements. See Appendix \ref{appendix:albatross} for more details about the protocol.\\

\subsubsection{Share-Reconstruct-Aggregate}
The other alternative is to skip the reveal phase altogether and proactively reconstruct each secret from the shares distributed during the sharing phase. Reconstructing each secret would require the cooperation of $t+1$ participants to gather the shares, after which Lagrange interpolation can be used to reconstruct the polynomial and recover the secret. However, this increases the communication complexity, as $n (t + 1)$ shares need to be broadcast due to $n$ Lagrange interpolations every round, irrespective of adversarial corruption. RandShare \cite{syta2017scalable} uses this technique.\\

\textbf{RandShare}\\

RandShare is run between all the $n$ participants and uses VSS as a subprotocol, extended by adopting the concept of barrier, a specific point in the protocol execution only after which the protocol is guaranteed to complete successfully. In RandShare, the barrier is reached when the first honest node reveals the shares he holds. Because the secret sharing threshold of $t + 1$, where $t$ is the number of dishonest participants, the dishonest participants cannot recover the honest participants’ secrets before the barrier. The protocol output cannot be changed after the barrier point, and all honest participants eventually output the previously fixed value, regardless of the adversary’s behavior.\\
RandShare proceeds in four phases---Share Distribution, Share Verification and Consensus, Share Reconstruction, and Aggregation, which are as follows.

\begin{enumerate}
    \item \textbf{Share Distribution:} Each participant $P_j$ executes the distribution phase $VSS.ShareGen(s^{(j)})$ as the dealer, publishing the polynomial commitments and securely sending the shares $s_i^{(j)}$ to all other participants $P_i$, $1\le i\le n$.
    \item \textbf{Share Verification and Consensus:} To tolerate up to $t$ Byzantine nodes, a Byzantine agreement protocol is run in combination with share verification algorithm $VSS.ShareVerify$. The Byzantine agreement procedures ensure that all honest participants have a consistent view of the secrets that will be recovered after the barrier or if the protocol run has already failed. Achieving Byzantine agreement requires at least $2t+1$ successful verification messages for each share. This ensures that at least $t+1$ honest participants have verified each secret and each honest participant will be able to recover every other participant’s secret value. Let $\mathcal{C}$ be the set of participants who have published commitments and valid shares. 
    \item \textbf{Share Reconstruction:} If a Byzantine agreement has been reached on at least $t+1$ secrets ($|\mathcal{C}| \ge t+1$), each of these secrets $s^{(j)}$ where $j \in \mathcal{C}$ is recovered by collecting at least $t+1$ shares of the secret and reconstructing it using $VSS.Recon$. Otherwise, the protocol fails.
    \item \textbf{Aggregation:} Final randomness is computed as $\mathcal{O}_r = \sum_{j \in C}s^{(j)}$.
    
\end{enumerate}

\subsubsection{Share-Aggregate-Reconstruct}
Instead of Scrape's process of revealing, reconstructing, and adding up all the secrets, or RandShare's process of reconstructing each secret and adding them up, SecRand directly computes the final output through Lagrange interpolation of aggregated decrypted shares from $t + 1$ participants. In short, one Lagrange interpolation suffices in SecRand's share-aggregate-reconstruct whereas $O(n)$ Lagrange interpolations are required in both commit-reveal-recover (Scrape) and share-reconstruct-aggregate (RandShare). This provides SecRand with a higher and more stable performance than Scrape against an adversary's malicious behavior of withholding its secret and also reduces the communication complexity as only $t + 1$ aggregated decrypted shares are exchanged to compute the final random output.\\

\textbf{SecRand}\\

SecRand is also run among all $n$ participants and uses Scrape PVSS (see Appendix \ref{appendix:scrapePVSS} for details) as a subprotocol. Setup is done using $PVSS.KeyGen$ and the public keys $pk_i$ of each participant is registered. 

SecRand proceeds in four phases---Share Distribution, Share Verification, Aggregation, and Reconstruction. The Share Distribution and Share Verification phases proceed in a similar way as Commit and Verify phases of Scrape. However, since SecRand does not have a Reveal phase like Scrape, the participants are not required to publish commitments to their secret $\mathsf{Com}(s, r)$ during Share Distribution phase. The other two phases proceed as follows:
\begin{enumerate}
    \setcounter{enumi}{2}
    \item \textbf{Aggregation:} After the Share Distribution and Share Verification phases, every participant $P_i$ would have a valid encrypted share of each of the $n$ secrets, $Enc(pk_i, s_i^{(j)})$ for $1 \le j \le n$. $P_i$ decrypts these shares to recover $\tilde{s}_i^{(j)}$ (need not be $s_i^{(j)}$) and calculates its group secret share as follows: 
    $$ gs_i = \prod_{j=1}^{n}\tilde{s}_i^{(j)} $$
    $P_i$ then broadcasts its group secret share $gs_i$ along with a proof of correct decryption $\pi_i$.
    \item \textbf{Reconstruction:} Every participant verifies the correctness of decryption using $PVSS.ShareVerify$. Once $t+1$ valid group secret shares are distributed, the complete group secret $gs$ is reconstructed through $PVSS.Recon$. The final random output for the round, $\mathcal{O}_r = H(gs)$, where $H$ is a hash function.
\end{enumerate}

\subsection{Threshold Encryption based}
\joenote{Should this be a new section?}
\joenote{does this need its own appendix?}
Even though the discussed threshold secret sharing schemes provides all the desirable security guarantees for a DRB, it comes at a high communication cost ($O(n^4)$ in the worst case when $t$ secrets need to be reconstructed) and requires each participant to share $O(n)$ data every round to guarantee reconstruction of each of the $n$ secrets. Threshold Encryption schemes brings down the reconstruction cost and the amount of data that needs to be shared every round by establishing a global public key to encrypt the shared secret such that only a subset of size greater than $t$ participants can decrypt it. It requires a DKG protocol to be run during initial setup to provide every decrypting participant $P_i$ with individual secret keys $sk_i$ and publishing the corresponding public keys $pk_i$ and a global public key $pk$. The global public key is used by any sender to encrypt a message. The individual secret and public keys will later enable any set of $t + 1$ participants to non-interactively decrypt ciphertexts computed under the global public key. 

A $(t, n)$-threshold encryption scheme is composed of the following algorithms:
\begin{itemize}
    \item $DKG(1^\lambda, t, n) \rightarrow (\vec{SK}, \vec{PK}, pk)$ runs a typical DKG with threshold $t$ and generates the global public key $pk$, individual secret keys $\vec{SK}$, and individual public keys $\vec{PK}$.
    \item $Enc(pk, m) \rightarrow C$ encrypts the message $m$ with $pk$ and outputs the ciphertext $C$.
    \item $ShareDec(pk, sk_i, pk_i, C) \rightarrow \mu_i$ generates the decryption share $\mu_i$ for ciphertext $C$ using the individual keys $(sk_i, pk_i)$ and the global public key $pk$.
    \item $Rec(pk, \vec{PK}, C, \vec{\mu} )\rightarrow \{m, \mathsf{reject}\}$ is a recovery algorithm that takes $pk$, a ciphertext $C$ and a subset of $t+1$ valid decryption shares $\vec{\mu} = \{\mu_1, \mu_2,\ldots, \mu_{t+1}\}$ together with the public keys $\vec{PK} = \{pk_1, pk_2,\ldots, pk_{t+1}\}$ and outputs the message $m$ or $\mathsf{reject}$.
\end{itemize}
See Appendix \ref{appendix:thresholdEnc} for more details.
 
 HERB \cite{cherniaeva2019homomorphic} uses threshold ElGamal encryption \cite{desmedt1990Threshold}, though it can be replaced with any other threshold homomorphic encryption scheme. See Appendix \ref{appendix:elGamal} for details on threshold ElGamal Encryption. \\
 
\textbf{HERB}\\

In HERB, each participant can play two roles: entropy providers and key holders. Entropy providers are active only for ciphertext generation whereas key holders participate in all protocol stages. The protocol proceeds in three phases---Setup, Publication, and Disclosure, where Setup is only done once at the beginning. They proceed as follows:
\begin{enumerate}
    \item \textbf{Setup}: All the key holders together run $DKG(1^\lambda, t, n)$ to generate a global public key $pk$ and individual public and secret keys ($pk_i$, $sk_i$) for $1 \le i \le n$.
    
    \item \textbf{Publication}: Each entropy provider $e_j$ generates a random share $M_j$ and encrypts it using $ThrEnc.Enc$ to generate the ciphertext share $C_j$. $C_j$ is published along with a proof of correct encryption $\pi_{CE_{j}}$ needed to ensure non-malleability of encrypted shares. The shares are then verified and agreed upon by the participants (refer to Appendix \ref{appendix:ce} for details on NIZK of Correct Encryption for ElGamal). Let $QUAL$ denote a set of valid $C_j$'s. The size of $QUAL$ depends on the system parameters. When enough encrypted shares are published, they are homomorphically combined into a common ciphertext $C$ corresponding to the plaintext $M$.
    
    \item \textbf{Disclosure}: The key holders $k_i$ use $ThrEnc.ShareDec$ to generate their decryption share $D_i$ and publish it along with a proof of correct decryption $\pi_{DLEQ_{i}}$, which is then verified by the other participants (refer to Appendix \ref{appendix:dleq} for details). When $t+1$ decryption shares are published and verified, participants use $ThrEnc.Rec$ to reconstruct the final random number $M$ for the round.
\end{enumerate}
HERB achieves a communication complexity of $O(n^3)$ without using a public blockchain ($O(n^2)$ with it) and requires each key holders to share constant amounts of data each round. The bottleneck lies in communication cost for achieving consensus on the $QUAL$ set. Optimizations such as Avalanche \cite{rocket2018snowflake} can be used to improve it to $O(n^2)$ leading to an overall lower communication complexity than threshold secret sharing schemes. Main disadvantage of HERB lies on its dependence on DKG for setup as every new key holder would require a rerun of DKG to establish the keys. When compared to DVRF based schemes (discussed later in Section \ref{section:dvrf}), HERB falls behind in terms of communication complexity. But it makes up for it in terms of quality of randomness produced in each round (uniform randomess vs pseudorandomness). Also, HERB allows the entropy providers to be independent of key holders. This makes it possible to collect entropy from a large and flexible set of sources while allowing the key holders set to be much smaller and sampled to contain at most $t$ malicious nodes.


\section{Subset-Based Protocols}
\label{section:subset-based}
Naturally, involving all participants in every beacon output generation process of a DRB such that each participant has to actively generate and communicate its per-node entropy every round is not the most scalable way to generate joint randomness in terms of overall communication complexity\joenote{confusing/run-on sentence}. Hence, a natural optimization is to involve only a subset of participants or a round leader (i.e. subset of size one) in beacon output generation such that those in the subset would be the only ones actively providing entropy contributing to a round's beacon output while those not in the subset would play a more passive role.

In this section, we consider DRB protocols that are subset-based. Hereafter, we refer to such a subset as an \textit{entropy-providing subset} and those in the subset as \textit{entropy providers}. As these subset-based protocols often offer various ways to generate a beacon\joenote{confusing} output due to their dynamic nature (e.g. as the subset of entropy providers changes every round), we can bucket each protocol run into two stages: subset selection, followed by beacon output generation. As the names suggest, the process of subset selection necessitates a mechanism to finalize the per-round entropy providers while that of beacon output generation necessitates a mechanism to derive some joint randomness ($\mathcal{O}_r$ in round $r$) from those entropy providers.

From a different perspective, these two stages could be seen as two dimensions that describe the landscape's DRB protocols. Refer to Table \ref{table:subset-based} to interpret the 11 protocols broached in this section in a nutshell.

\subsection{Step 1. Subset Selection}
The first step of a subset-based DRB protocol involves selecting an entropy-providing subset of participating nodes every round in a way that is agreeable by all nodes. We classify subset selection mechanisms in the landscape into two: public and private.

\subsubsection{Public Subset Selection}
\label{subsubsection:public-subset-selection}
In a public subset selection, only public information is needed to derive an agreeable subset that provides entropy every round. A first example is \textit{round-robin} (RR), in which nodes simply take turns being selected such that there is no notion of hierarchy among nodes. While RR can work with subsets of any size in theory as long as the exact mechanism is clearly defined by the protocol in advance, it is canonical that RR usually refers to the selection of subset of size one (i.e. a leader) corresponding to node $i \equiv r \pmod n$ given round $r$ and $n$ number of nodes. Hence, protocols like BRandPiper \cite{bhat2020randpiper} (in which the round leader is the only active entropy provider) adopt RR as their leader selection mechanism. In the case of BRandPiper, it is in fact imperative that the leader is selected via RR due to its innate fairness property \cite{azouvi2018winning} (also known as chain quality \cite{garay2015bitcoin} in the blockchain context) where all nodes, by RR's definition, take equal leadership across any $n$ rounds.

A second example is \textit{random selection} (RS), which uses a public source of randomness (e.g. most commonly the previous round's beacon value) to derive the entropy-providing subset. While RR is a simple deterministic algorithm, RS is a randomized one and thus allows for more protocol-level variations, some of which are exemplified in the following examples.
\begin{itemize}
\item HydRand \cite{schindler2020hydrand} and GRandPiper \cite{bhat2020randpiper}. Given the previous beacon value $\mathcal{O}_{r - 1}$, the subset (of size one, i.e. the leader) for round $r$ corresponds to node $i \equiv \mathcal{O}_{r - 1} \pmod{\tilde{n}}$ where $\tilde{n}$ denotes the number of nodes eligible for leadership.
\item Ouroboros \cite{kiayias2017ouroboros}. The follow-the-satoshi algorithm \cite{bentov2014proof,kiayias2017ouroboros}\joenote{I would omit this from the paper or reduce to one sentence. It's just another variant of random selection, the satoshi details don't matter} outputs the next slot leaders of an epoch (i.e. predefined collection of consecutive slots) given the previous beacon value as input by tracking the owners of specific ``satoshis'' or units of currency in order to derive a subset for the subsequent round. Note that we regard Ouroboros' epoch as one round in the context of DRB although Ouroboros' concept of a slot corresponds to a round in the blockchain context.
\end{itemize}

That RS is randomized incurs a side effect where some nodes may, in theory, never be selected and therefore may never be able to contribute their entropy to the beacon output even if actively participating in the protocol. A more realistic concern is that an adversary can attempt to bias, via grinding attack\joenote{not introduced yet}, the beacon output in order to bias the next entropy-providing subset to its benefit (which may in turn help the adversary bias the next beacon output again and so on). This is a notable tradeoff given RS, and thus protocols adopting RS need to take this facet into consideration.

On the other hand, this is not an issue in RR, as its subset selection is naturally deterministic in a way that is independent of the preceding beacon output. Nonetheless, a tradeoff of RR is that DoS attack becomes a possibility since each subset is known in advance for every round publicly. To be noted is this interplay where we either, when choosing between RR and RS, gain unbiasability (due to determinism) at the cost of DoS attack or gain DoS attack defense (due to randomization) at the cost of grinding attack.\todo{this section should talk about adaptive corruption}

A third example, \textit{leader-based selection} (LS) is a hybrid method that in fact exhibits both determinism and randomization. It runs in two steps: the first step involves electing a leader (either by RR or RS) while the second step involves a manual selection\joenote{why manual?} of the entropy-providing subset by the leader from the first step. It is precisely in this way that the mechanism is deterministic from the leader's perspective while randomized from the perspective of others.

One requirement, due to the power delegated to the per-round leader, is that the size of the chosen subset needs to be greater than $t$ (assuming a network with at most $t$ Byzantine nodes) so that a malicious leader wouldn't be able to game the system by choosing a malicious subset. Some examples of LS include the following.
\begin{itemize}
\item RandHound \cite{syta2017scalable}. As instantiated in RandHerd \cite{syta2017scalable}, RandHound's leader election (i.e. the first step of LS) involves a lottery where each node generates a lottery ticket $t_i = H(C \mathbin\Vert pk_i)$ given a public configuration parameter $C$ (assuming its randomness) such that the owner of $min(t_i)$ becomes the leader (originally called client). Note that this lottery is a public one such that it only involves public parameters $C$ and $pk_i$, in which case anyone can derive the leader without any private input. Essentially, this first step of LS is an instance of RS. While the second step of LS for RandHound involves a manual subset selection by the leader as expected, one protocol-level caveat is that RandHound adopts a form of sharding (involving PVSS groups) such that the leader is required to select more than a threshold number of nodes in each shard (PVSS group), which in turn guarantees more than a threshold number of chosen entropy providers across all shards.
\item SPURT \cite{das2021spurt}. Unlike RandHound, SPURT adopts RR as its first part of LS such that nodes simply take turns being a round leader. Then the round leader chooses the subset of entropy providers manually.
\end{itemize}

The motivation for LS (as opposed to RR or RS) is clear\joenote{It's not clear ot me, you need to spell out what the advantage is} only if the underlying DRB protocol is already a leader-based one utilizing the concept of a leader as a facilitator of communication among nodes in order to lower the overall communication complexity. Otherwise, it naturally suffers from the same attacks impacting RR and RS (i.e. DoS attack and grinding attack, respectively) during the leader election step of LS while also potentially suffering from liveness issues related to leader failure (non-Byzantine or Byzantine). Hence, LS is generally less commonly used in practice.\joenote{Practice? are any of these used in practice?}

\subsubsection{Private Subset Selection}
In a private subset selection, also known as private lottery, each node needs to input some private information (e.g. secret key) in order to check whether or not it has been selected into the entropy-providing subset (i.e. has won the lottery). The general formulation of a private lottery can be given by
\todo{include private input in the description}
\[
f_{priv}(\cdot) < target
\]
where $f_{priv}(\cdot)$ is a lottery function (i.e. pseudorandom function) that takes some private input and $target$ is indicative of the lottery's ``difficulty level'' (a la Proof of Work difficulty) such that a protocol can tinker with $target$ to make the lottery arbitrarily easy or hard to win. The idea is that each node calculates $f_{priv}(\cdot)$ as per its private input and checks if the above inequality is satisfied, in which case it is considered to have won the lottery and becomes included in the subset of entropy providers.

As it may be possible for an adversary to perform a grinding attack by brute-forcing many values of $priv$ until a desirable function output is achieved (i.e. desirable both in terms of satisfying the lottery inequality and also the actual beacon output generation step that follows the lottery step, to be discussed later, given $priv_1$ and $priv_2$ that both satisfy the lottery), one crucial requirement is that the private input should be provably committed in the past and thus be ungrindable\joenote{not defined yet} at the time of computation of the lottery function. Three examples of the above private lottery formulation exist in the landscape: a VRF-based lottery, Caucus' \cite{azouvi2018winning} lottery involving a hash chain, and RandChain's \cite{han2020randchain} mining-based lottery.

\joenote{Section heading: VRF-based approach?}
In Algorand \cite{gilad2017algorand} (as well as Ouroboros Praos \cite{david2018ouroboros} and a protocol by Nguyen-Van et al. \cite{nguyen2019scalable}), a VRF (whose details are included in the Appendix) is used as part of its sortition algorithm\joenote{define sortition?} each round to process a lottery. (While there exist more than one version of Algorand's sortition algorithm, we consider its first version, as the versions don't differ on a fundamental level.) Quite naturally, one's private input to $VRF_{sk}(\cdot)$ is its secret key such that the lottery is given by
\[
VRF_{sk}(\mathcal{O}_{r - 1} \mathbin\Vert role) < target
\]
where $\mathcal{O}_{r - 1}$ denotes randomness from the previous round (while $role$ is some parameter specific to Algorand\joenote{Is role needed for a conceptula explanation?}). As both $\mathcal{O}_{r - 1}$ and $role$ are already public and ungrindable at the time of computation, Algorand makes sure $sk$ is likewise ungrindable by requiring that $sk$ is in fact the node's secret key from some threshold number of rounds ago. While the size of the entropy-providing subset is expected to be one in Algorand (such that there is 1 expected winner per lottery and 1 lottery per round), that in Ouroboros Praos is expected to be $K$ where each epoch consists of $K$ consecutive slots (such that there is 1 expected winner per lottery but $K$ per-slot lotteries per round, which is an epoch), as the protocol provides an epoch-based variant of Algorand. Fundamentally the same as that of Algorand, the per-slot lottery of Ouroboros Praos is given by
\[
VRF_{sk}(\mathcal{O}_{r - 1} \mathbin\Vert slot \mathbin\Vert \mathsf{TEST}) < target
\]
where $slot$ denotes the slot number and $\mathsf{TEST}$ is a string such that there would be $K$ expected entropy providers (each corresponding to a slot) in a round.\joenote{this is so similar, I would merge the two into one desciption}

In Caucus, a VRF is replaced by a hash function combined with a hash chain, i.e. a list ($h_1, ..., h_m$) with $h_r = H(h_{r + 1})$ for all $r = 1, ..., m - 1$ where $h_m = s$ for some random seed. Effectively, a hash chain provides the functionality of provable commitment to some private input as one can publicize one $h_r$ at a time (e.g. $h_r$ in round $r$) such that doing so is equivalent to committing to $h_{r + 1}$ in a provable way (as $h_{r + 1}$ would be publicized later to commit to $h_{r + 2}$ and so on). Consequently, each participant of Caucus independently generates a private hash chain comprising its $m$ private inputs such that the lottery is given by
\[
H(h_r \oplus \mathcal{O}_{r - 1}) < target
\]
where $\mathcal{O}_{r - 1}$ likewise denotes randomness from the previous round.

\joenote{I think this might be best to leave out of the paper, or mention in a smaller section on proof-of-work. The model is very different and if this is included, why not Bitcoin and everything else?}
In RandChain, the logic is slightly different in that a node's private information that is input to the lottery function is not something it already has generated and knows. It is quite the opposite: via mining, each node tries to guess and find its own private information (i.e. solution to the mining puzzle) and satisfy the lottery inequality before others do. This view of interpreting mining as a form of private lottery is due to RandChain's network setting that is more competitive (a la blockchain settings) than collaborative (in which nodes cooperate to derive joint randomness). As a result, the lottery given by
\[
H(pk \mathbin\Vert S_i) < target
\]
involves a timely search of the private input $S_i$ that solves the mining puzzle where $S_i$ is an output of applying, for $i$ number of times, some function $g$ to $S_0 = H(pk \mathbin\Vert h^-)$ with $h^-$ denoting the previous block hash. While $g$ can correspond to a simple, parallelizable nonce-incrementing process as in Proof of Work, RandChain lets this $g$ be a VDF, realizing a non-parallelizable variant of Proof of Work called Sequential Proof of Work (whose details are included in the Appendix and can be of independent interest).

Note the importance of competition in the security of RandChain's DRB. Without competition, the act of mining is in fact precisely the act of performing a grinding attack, which can lead to biasing of the randomness output. With competition, nodes are incentivized to broadcast and publicize a solution as soon as they find one, forcing them to commit to the first solution they find as their private input.

\subsection{Step 2. Beacon Output Generation}
Once given a subset of entropy-providing nodes, the issue then shifts to one dealing with the actual entropy generation process culminating in a beacon output. While a typical commit-reveal-recover run among the subset of entropy providers may be sufficient to realize a DRB, there can be other variations coupled with different tradeoffs as well. Largely, we classify these variations into two: one that requires \textit{fresh} (independently generated on the spot) per-node entropy and one that combines previous randomness (i.e. beacon output) with \textit{precommitted} (independently generated but precommitted, hence ungrindable) per-node entropy.

\subsubsection{Fresh Per-Node Entropy}
The fresh per-node entropy generation process for subset-based protocols fundamentally resembles the aforementioned commit-reveal-recover variants such that each node independently generates and contributes its entropy to the beacon output every round and there exists a countermeasure based on PVSS or threshold encryption in case some nodes fail during a protocol run. Some protocols involving fresh per-node entropy each round and their implementation details are included in the following examples.\joenote{this is good-don't go into every detail. But do specify the high-level goals/challenges. Why do it one way and not another?}
\begin{itemize}
\item Ouroboros and RandHound. As each slot leader is a participant in the entropy-providing subset, all slot leaders of an epoch in Ouroboros perform a RandShare-style share-reconstruct-aggregate using PVSS. Similar is the chosen subset in RandHound while facilitated by a round leader.
\item SPURT and BRandPiper. The entropy providers of SPURT and BRandPiper, on the other hand, perform a SecRand-style share-aggregate-reconstruct to generate a beacon output every round. BRandPiper's beacon output generation process is quite idiosyncratic, however. While there exists one entropy provider per round, it allows $n$ secrets (one from each node) to be combined each round such that it provides the ideal 1-unpredictability property as opposed to $t$-unpredictability (as in HydRand or GRandPiper). The trick is that every time a node becomes the round leader, it generates $n$ fresh secrets that are to be combined with others' secrets in the next $n$ rounds, respectively, and it distributes them to other participants via PVSS in advance. Effectively, each beacon output is a result of share-aggregate-reconstruct.
\item NV (a protocol by Nguyen-Van et al. \cite{nguyen2019scalable}). Similar to HERB, the entropy providers of NV contribute their fresh entropy using ElGamal although they use its classical, non-threshold version due to the protocol's centralized Requester model in which a third party called Requester requests some joint randomness from a group of participating nodes. As a result, each entropy provider generates and encrypts its entropy and sends it to the Requester, which then decrypts all the messages received from entropy providers and outputs their sum as the randomness output. Naturally, this Requester model can easily be turned into a non-Requester one once the entropy providers are made to essentially perform HERB-style threshold encryption and decryption to generate a beacon output. In this case, the protocol's aforementioned VRF-based subset selection mechanism would be its main novelty compared to HERB.
\end{itemize}

\subsubsection{Combining Previous Output and Precommitted Per-Node Entropy}
There is room to optimize and lower a protocol's communication complexity if it's not a requirement that entropy providers need to generate fresh per-node entropy every single round. The canonical attempt at an optimization involves utilizing the beacon output from the previous round $\mathcal{O}_{r - 1}$ as a source of entropy. Nonetheless, the caveat in doing so is that grinding attack may become a possibility once $\mathcal{O}_{r - 1}$ becomes public, which is why we need to require per-node entropy to be precommitted before combining it with $\mathcal{O}_{r - 1}$ to output $\mathcal{O}_r$. Preventing grindability while taking advantage of the accessibility of $\mathcal{O}_{r - 1}$ as a source of entropy, such requirement can be observed in many subset-based protocols in the landscape and is indeed a commonality among them even if their implementation details may seem unrelated on the surface. We provide some examples as follows.
\begin{itemize}
\item HydRand and GRandPiper. Each round, an entropy provider (which is the round leader for both HydRand and GRandPiper) commits its entropy that becomes opened in the next round the same node is selected as the leader again. In other words, the round leader's precommitted entropy $e_{\tilde{r}}$ from the last round $\tilde{r}$ it was a leader is the one that becomes combined with $\mathcal{O}_{r - 1}$ in the form of $h^{e_{\tilde{r}}}$ (due to details related to PVSS recovery) to generate
\[
\mathcal{O}_r = H(\mathcal{O}_{r - 1} \mathbin\Vert h^{e_{\tilde{r}}})
\]
where $h$ is a generator of $\mathbb{G}_q$ of prime order $q$. While GRandPiper's beacon output is technically
\[
\mathcal{O}_r = H(h^{e_{\tilde{r}}}, \mathcal{O}_{r - 1}, ..., \mathcal{O}_{r - t})
\]
for a system parameter $t$ up to which the protocol tolerates a number of Byzantine nodes, it is fundamentally the same as HydRand's. Common in both is the fact (due to which the ungrindability of $h^{e_{\tilde{r}}}$ is achieved) that one honest node must be present in any $t + 1$ consecutive rounds due to the requirement that a leader cannot gain another leadership in the next $t$ rounds. Also notably common is the use of PVSS recovery in case a round leader fails to open its precommitted entropy.
\item Algorand and Ouroboros Praos. In VRF-based schemes that use a VRF for beacon output generation (e.g. recall that NV uses a VRF for subset selection but not for beacon output generation), the secret key $sk$ of the round leader often corresponds to precommitted per-node entropy as long as the assumption that nodes cannot switch their $sk$ at the time of VRF's computation holds. Algorand's beacon output is therefore given by
\[
\mathcal{O}_r = VRF_{sk}(\mathcal{O}_{r - 1} \mathbin\Vert r)
\]
combining the previous output $\mathcal{O}_{r - 1}$ with the precommitted entropy $sk$. Note that the input to the VRF in beacon output generation is different from that in subset selection, as the VRF output in subset selection is always going to be less than $target$ by design. Ouroboros Praos (we take its epoch as a round for DRB similar to Ouroboros) provides an epoch-based variant where each slot leader is construed to be one entropy provider out of $K$ (denoting the number of slots in an epoch). Hence, the beacon output given by
\[
\mathcal{O}_r = H(\mathcal{O}_{r - 1} \mathbin\Vert epoch \mathbin\Vert \rho_1 \mathbin\Vert ... \mathbin\Vert \rho_K)
\]
involves all VRF outputs from all respective slot leaders, where $epoch$ denotes the epoch number and $\rho_i = VRF_{sk_i}(\mathcal{O}_{r - 1} \mathbin\Vert slot_i \mathbin\Vert \mathsf{NONCE})$ is returned by the slot leader of $slot_i$. Note the presence of the string $\mathsf{NONCE}$, which is different from $\mathsf{TEST}$ used in the private lottery portion of Ouroboros Praos.
\joenote{what's the impact of the difference between these two approaches? If nothing, just merge into a simpler general description}
\item Caucus. Each new reveal ($h_r$ in round $r$) of one's precommitted hash chain in Caucus corresponds to an entropy provider's precommitted entropy. The beacon output is given by
\[
\mathcal{O}_r = h_r \oplus \mathcal{O}_{r - 1}
\]
such that it naturally follows its subset selection mechanism $H(h_r \oplus \mathcal{O}_{r - 1}) < target$.
\item RandChain. Unique due to its competitive (rather than collaborative) network setting, RandChain forces participants to publish their first solution to the SeqPoW mining puzzle at the time of discovery. Effectively, this causes the first solution $S_i = g^i(S_0)$ with $g(S_j) = SeqPoW.Solve(pp, pk, S_j)[0]$ for $j \geq 0$ from the Appendix to be the entropy provider's precommitted entropy. The beacon output is given by
\begin{align*}
\mathcal{O}_r &= H_2(pk \mathbin\Vert g^i(S_0))\\
&= H_2(pk \mathbin\Vert g^i(H(pk \mathbin\Vert h^-)))\\
&= H_2(pk \mathbin\Vert g^i(H(pk \mathbin\Vert H(H_2^{-1}(\mathcal{O}_{r - 1})))))
\end{align*}
where $i$ represents the effort of mining such that $i$ is the smallest natural number allowing the output of applying $g$ to the initial seed $S_0 = H(pk \mathbin\Vert h^-)$ for $i$ number of times to solve the SeqPoW mining puzzle, $H_2$ is a hash function different from $H$, $h^- = H(H_2^{-1}(\mathcal{O}_{r - 1}))$ denotes the previous block hash, and $H_2^{-1}(\mathcal{O}_{r - 1})$ denotes the preimage $x$ chosen to yield $\mathcal{O}_{r - 1} = H_2(x)$ in round $r - 1$ (while not hinting at an inverse of the hash function $H_2$). It is in this way that RandChain's mining-based randomness generation scheme can also be interpreted as one that combines the previous beacon output $\mathcal{O}_{r - 1}$ with some ungrindable (due to the competitive network assumption) entropy $S_i$ by the SeqPoW miner that finds such $i$.
\end{itemize}

\section{Protocols With No Marginal Entropy}
\label{section:dvrf}
\subsection{DRB Based On Distributed Verifiable Random Function}
\joenote{is marginal entropy defined?}
While DRB protocols can have all nodes or some subset of nodes contribute entropy to the beacon output every round, it is possible to devise a protocol where no node produces any marginal entropy to prolong a beacon.\joenote{mention advantages/disadvantages} Guaranteeing randomness entirely via pseudorandomness rather than any per-node entropy on a marginal basis, such a protocol can be based on the concept of distributed VRF \cite{hanke2018dfinity,galindo2020fully} (DVRF, also known as threshold VRF or TVRF \cite{cascudomt})\joenote{is this defined anywhere?}, which is a distributed version of VRF. The idea is that a DKG allows $n$ nodes to share a global secret key $sk$ such that up to $t$ Byzantine nodes can be tolerated without compromising the protocol while any $t + 1$ honest nodes can cooperate to compute a VRF output (as well as its proof) as if the computation involves one node with the knowledge of $sk$.\\

\noindent\textbf{Beacon output of a DVRF-based DRB.} With DVRF-related details included in the Appendix, each beacon output of a DVRF-based DRB is given by
\begingroup\makeatletter\def\f@size{8}\check@mathfonts
\[
\mathcal{O}_r = DVRF.Combine(A, \{DVRF.PartialEval(sk_i, f(\mathcal{O}_{r - 1}))\}_{i \in A})[0]
\]\endgroup
where $sk_i$ denotes each node's secret key after a DKG, $A$ denotes the set of $t + 1$ nodes whose outputs of $DVRF.PartialEval(\cdot)$ pass the $DVRF.PartialVerify(\cdot)$ test, and $f$ denotes some premeditated (mostly uncomplicated) function of the previous beacon output $\mathcal{O}_{r - 1}$ on which nodes compute a DVRF.

Equivalently, suppose there exists one imaginary node with the knowledge of $sk$ (which should not happen in a typical DVRF or a DKG to begin with) computing a VRF. Then
\[
\mathcal{O}_r = VRF_{sk}(f(\mathcal{O}_{r - 1}))
\]
yields a computationally equivalent output to when a DVRF is computed among $n$ nodes. As $f$ typically takes a form resembling $f(\mathcal{O}_{r - 1}) = H(r \mathbin\Vert \mathcal{O}_{r - 1})$, it can be seen that there is no need for any generation of marginal entropy by the participants. Simultaneously, the precise reason for the security of the above DVRF formulation is that no one node (or up to $t$ number of nodes) can gain knowledge of $sk$ to be able to compute and predict future beacon outputs.\\

\noindent\textbf{Understanding a chain of unique signatures from a DVRF perspective.} 
\joenote{this whole paragraph could be a footnote or appendix. The signature/VRF/VUF discussion is tangential to the plot}.
Due to the known fact that the hash of a VUF equals a VRF, i.e. $VRF.Prove(sk, x) = (VRF_{sk}(x), \pi_{sk}(x)) = (H(VUF_{sk}(x)), VUF_{sk}(x))$, a unique digital signature (which is a VUF \cite{dodis2005verifiable}) can be made into a DVRF by just taking a threshold signature variant of it and hashing the output. Adopting the BLS signature scheme \cite{boneh2001short} as the underlying unique signature scheme, protocols like Dfinity \cite{hanke2018dfinity} and drand \cite{drand} (though with slightly different trivial details) offer a DRB via the recursion given by
\[
\mathcal{O}_r = H(Sign_{sk}(r \mathbin\Vert \mathcal{O}_{r - 1}))
\]
where $Sign_{sk}(\cdot)$ is part of the BLS signature scheme (whose details are included in the Appendix) and $sk$ is the implied global secret key derived from a DKG among participants such that the actual computation of $\mathcal{O}_r$ involves combining of partial signatures (which use $sk_i$), reminiscent of how a DVRF is computed via combining of partial evaluations.

In fact, note that $H(Sign_{sk}(\cdot))$ is equivalent to $VRF_{sk}(\cdot)$, which is (as aforementioned under the DVRF framework) equivalent to
\[
DVRF.Combine(A, \{DVRF.PartialEval(sk_i, \cdot)\}_{i \in A})[0]
\]
combining $t + 1$ partial evaluations from $t + 1$ nodes in set $A$. Hence, it is in this way that hashing of a threshold signature (unique like BLS) is really a DVRF, in which case the threshold signature rather becomes the DVRF's proof $\pi$.\\

\noindent\textbf{Variations on a chain of unique signatures.} In addition to a chain of BLS signatures given by Dfinity and drand, there have been a few relevant variations in the landscape, such as RandHerd \cite{syta2017scalable}, DDH-DVRF, and GLOW-DVRF \cite{galindo2020fully}.
\begin{itemize}
\item RandHerd. Two modifications are made in RandHerd. First, a form of ``sharding'' is performed where nodes are randomly configured into groups via some initial configuration seed (which is derived from a one-time run of RandHound in the original paper) such that each group emits a group leader while one of the group leaders (e.g. that of the first group) is deemed a cothority (collective authority) leader.\joenote{need to specify the benefits (quantitatively) and drawbacks of this approach} Nonexistent in Dfinity or drand, this results in the notion of hierarchy among nodes and thus has the effect of reducing communication and computational overhead of the protocol overall, as there is no need for nodes to broadcast every relevant message to every other node. Second, the underlying signature scheme used is the Schnorr signature scheme instead of BLS, due to which algebraic modifications are made to the protocol accordingly. As a result, each beacon output in RandHerd is essentially a threshold Schnorr signature on message (as per the original protocol) $m = t_r$ where $t_r$ denotes the timestamp at the beginning of round $r$. As $m$ can technically be chosen by the leader, one simple modification can involve setting $m = r \mathbin\Vert \mathcal{O}_{r - 1}$ a la Dfinity or drand in order to remove any potential bias that can be introduced by the leader. Otherwise, we assume that $t_r$ is not a source of entropy but rather a system parameter.
\item DDH-DVRF. The following tuple of DVRF algorithms differentiates DDH-DVRF.\joenote{need a high level explanation. Hard to follow this and no ``why'' is evident}
    \begin{enumerate}
    \item $DKG(1^\lambda, t, n)$ runs a typical DKG (a la Joint-Feldman or Joint-Pedersen).
    \item $PartialEval(sk_i, x)$ outputs $(y_i, \pi_i)$ where $y_i = H(x)^{sk_i}$ and $\pi_i = DLEQ(g, g^{sk_i}, H(x), H(x)^{sk_i})$ denoting the Chaum-Pedersen protocol (whose details are included in the Appendix) non-interactively proving that the discrete log involving the first two parameters to $DLEQ(\cdot)$ is equal to that involving the last two parameters without revealing the discrete logarithm value itself.
    \item $PartialVerify(pk_i, x, y_i, \pi_i)$ is equivalent to $DLEQ\text{-}Verify(g, pk_i, H(x), y_i, \pi_i)$ (from the Appendix) and verifies the correctness of the $PartialEval$ algorithm using the $DLEQ$ proof $\pi_i$.
    \item $Combine(A, \{(y_i, \pi_i)\}_{i \in A})$ outputs $(y, \pi)$ where $y = \prod_{i \in A} y_i^{\lambda_{0, i, A}}$ and $\pi = \{(y_i, \pi_i)\}_{i \in A}$. Details related to Lagrange coefficients $\lambda_{0, i, A}$ are included in the Appendix. Note that $\pi$ is linear in the size of $A$ and hence is not a compact proof (which motivates GLOW-DVRF).
    \item $Verify(pk, \{pk_i\}, x, y, \pi)$ verifies all the partial proofs via $PartialVerify(pk_i, x, y_i, \pi_i)$ for all $i \in A$ from $\pi$ and also verifies $y = \prod_{i \in A} y_i^{\lambda_{0, i, A}}$.
    \end{enumerate}
\item GLOW-DVRF. \joenote{Same not -} Providing a compact proof $\pi$, GLOW-DVRF uses a bilinear pairing $e: \mathbb{G}_1 \times \mathbb{G}_2 \rightarrow \mathbb{G}_T$ similar to BLS such that the setup includes different hash functions $H_1: \{0, 1\}^* \rightarrow \mathbb{G}_1$ and $H_2: \mathbb{G}_1 \rightarrow \{0, 1\}^{y(\lambda)}$. While the following tuple of algorithms generally resembles that of DDH-DVRF, algebraic modifications are made accordingly to reflect the fact that a pairing is used.
    \begin{enumerate}
    \item $DKG(1^\lambda, t, n)$ is adapted so that $pk_i$ resides in $\mathbb{G}_1$ while $pk$ resides in $\mathbb{G}_2$. This is achieved by letting $(pk_i, pk) = (g_1^{sk_i}, g_2^{sk})$ for $g_1 \in \mathbb{G}_1$ and $g_2 \in \mathbb{G}_2$. The purpose of this is to facilitate a compact proof in the final $Verify$ step involving a pairing equation.
    \item $PartialEval(sk_i, x)$ outputs $(y_i, \pi_i)$ where $y_i = H_1(x)^{sk_i}$ and $\pi_i = DLEQ(g_1, g_1^{sk_i}, H_1(x), H_1(x)^{sk_i})$.
    \item $PartialVerify(pk_i, x, y_i, \pi_i)$ is equivalent to $DLEQ\text{-}Verify(g_1, pk_i, H_1(x), y_i, \pi_i)$ and verifies the correctness of the $PartialEval$ algorithm using the $DLEQ$ proof $\pi_i$.
    \item $Combine(A, \{(y_i, \pi_i)\}_{i \in A})$ outputs $(y, \pi)$ where $\pi = \prod_{i \in A} y_i^{\lambda_{0, i, A}}$ and $y = H_2(\pi)$. Note that $\pi$ is a group element and thus a compact proof.
    \item $Verify(pk, \{pk_i\}, x, y, \pi)$ verifies $y = H_2(\pi)$ and a pairing equation $e(\pi, g_2) = e(H_1(x), pk)$.
    \end{enumerate}
\end{itemize}

For comparison, Dfinity, with its setup equal to that of GLOW-DVRF due to the use of a pairing, can in fact be written as follows.
\begin{enumerate}
\item $DKG(1^\lambda, t, n)$ is adapted so that both $pk_i$ and $pk$ reside in $\mathbb{G}_2$. This is achieved by letting $(pk_i, pk) = (g_2^{sk_i}, g_2^{sk})$ for $g_2 \in \mathbb{G}_2$. The purpose of this is to facilitate the check of some pairing equation in both $PartialVerify$ and $Verify$.
\item $PartialEval(sk_i, x)$ outputs $(y_i, \pi_i)$ where $y_i = H_1(x)^{sk_i}$ and $\pi_i = \text{$\perp$}$. The reason for a null proof is that a pairing equation check is used in $PartialVerify$ (which is the differentiator from GLOW-DVRF) with no need for any auxiliary information.
\item $PartialVerify(pk_i, x, y_i, \pi_i)$ checks a pairing equation $e(y_i, g_2) = e(H_1(x), pk_i)$.
\item $Combine(A, \{(y_i, \pi_i)\}_{i \in A})$ is equal to that in GLOW-DVRF.
\item $Verify(pk, \{pk_i\}, x, y, \pi)$ is equal to that in GLOW-DVRF.
\end{enumerate}

\section{Discussions}
\subsection{Grinding Attack}
\todo{definition of grinding attack}
While grinding attack is not a threat in commit-reveal-recover variants (like Scrape and HERB) or protocols with no marginal entropy (like drand and RandHerd), it is indeed a valid concern in a class of subset-based protocols involving either random selection (RS) and private lottery in terms of subset selection mechanism or combining of precommitted per-node entropy with $\mathcal{O}_{r - 1}$ in terms of beacon output generation mechanism. The main idea is that an adversary can perform a grinding attack to produce a biased entropy-providing subset, a biased beacon output, or both unless a countermeasure is given by a DRB. In the worst case, it may even be a possibility that $\mathcal{O}_r$ can be adversarially generated (if ever) via grinding such that the entropy-providing subset for the next round would likewise be adversarially selected, resulting in a vicious cycle.

To prevent this, the broached subset-based protocols offer the following (aforementioned but summarized here) mechanisms to counteract any potential grinding attack.
\begin{itemize}
\item HydRand and GRandPiper. \joenote{reader will have forgotten these by now. need to refresh what the attack is/how the out put is computed each round.} The per-node entropy $h^{e_{\tilde{r}}}$ from $\mathcal{O}_r = H(\mathcal{O}_{r - 1} \mathbin\Vert h^{e_{\tilde{r}}})$ is precommitted in round $\tilde{r}$ during the node's previous leadership. Another key is that a leader cannot regain leadership in the next $t$ rounds such that there must be at least one honest node among any $t + 1$ consecutive rounds in a way that ``resets'' any grinding attack attempt within any window of $t + 1$ rounds. While the property of $t$-unpredictability is derived from this very fact also, it should be noted that the $t$-limited adversary assumption must hold in the first place in order for such line of reasoning to make sense.
\item Private lottery schemes (Algorand, Ouroboros Praos, Caucus, NV, and RandChain). Recall that the private input $priv$ from $f_{priv}(\cdot)$ should be ungrindable. For VRF-based protocols, Caucus, and RandChain, this respectively corresponds to $sk$, $h_r$ (in round $r$), and solution to the mining puzzle, all of which are also used for beacon output generation except in NV. In fact, grinding attack in NV is more limited in scope, as it can lead to a biased entropy-providing subset but not a biased beacon output due to the fact that a VRF is used in subset selection whereas a HERB-style threshold encryption (if considering a variant of NV's original Requester model) is used in its beacon output generation. Indeed, this separation demonstrates that the mechanisms used for subset selection and beacon output generation can be modular and different. In other words, it is not a requirement that the same private lottery tool (e.g. VRF) must be used to generate a beacon output even if this happens in most protocols due to convenience.
\item RandHound. While the public lottery (for leader election) is set in a way that is ungrindable, it is worth noting that RandHound's entropy-providing subset size requirement offers an additional defense against grinding attack on the beacon output, as the presence of at least one honest entropy provider nullifies any grinding attack attempt in a commit-reveal-recover variant like RandHound's share-reconstruct-aggregate.
\item Ouroboros. Although Ouroboros also takes advantage of share-reconstruct-aggregate, it does not have an explicit subset size requirement, as the set of unique slot leaders (i.e. entropy providers) in an epoch can range anywhere from 1 to $K$ (denoting the number of total slots in an epoch) in size in theory. This can facilitate grindability. Take a case where Ouroboros' follow-the-satoshi subset selection algorithm outputs only one entropy provider from an epoch (i.e. round $r$), for an extreme example. In that case, the sole entropy provider can not only predict and bias $\mathcal{O}_r$, but also grind on $\mathcal{O}_r$ to bias future rounds (up to an arbitrary number of rounds in theory). In practice, the combination of Ouroboros' blockchain setting based on Proof of Stake (such that an adversary should have to own a lot of coins) and a large $K$ is what makes such cases highly unlikely.
\end{itemize}

Evidently, it is important to discern any potential grinding attack vectors as well as their impact in order to promote a secure DRB, and the above demonstrates that the two common countermeasures---inclusion of fresh entropy from at least one honest node, making sure that the precommitted entropy at a node level is indeed precommitted, or both---often offer a sufficient defense against grinding attack.

\subsection{Withholding Attack}
On the other hand, there exists an attack without much countermeasure, namely withholding attack (i.e. a general form of the last revealer attack where a node withholds a message). Any leader-based protocol can be vulnerable to this attack due to heavy reliance on a leader's availability while any protocol leveraging a private lottery can also be vulnerable due to its nature where the lottery winner has to announce itself as a winner in the first place or can withhold this announcement if desirable.\\

\noindent\textbf{Protocols with a leader.} For instance, take RandHound, RandHerd, SPURT, and RandRunner, all of which are leader-based. With the exception of RandRunner, these protocols suffer from the leader unavailability issue in case the leader withholds its message for whichever reason (Byzantine or non-Byzantine) such that their liveness is affected and a beacon output can be aborted (depending on implementation). In worse cases like RandHound and RandHerd, this can create a bias if the leader aborts after seeing $\mathcal{O}_r$. In RandRunner, a beacon output will not be aborted but delayed at worst due to the usage of VDFs. In any case, assuming that a leader would be available every round can be a naive one, and there needs to be some fallback in case a leader withholds (e.g. HydRand's PVSS recovery).\\

\noindent\textbf{Protocols with a private lottery.} The issue is more fundamental with private lottery schemes like Algorand (where the leader can withhold after privately computing $\mathcal{O}_r$, creating a bias). The crux is that private lottery winners are indeed private such that there is no way to detect once a winner withholds its leadership (perhaps maliciously), i.e. there is no accountability. This is an unavoidable tradeoff to the two notable benefits of a private lottery: resilience to DoS attack (due to its property of delayed unpredictability \cite{azouvi2018winning} where one cannot predict the eligibility of honest nodes until they reveal) and independent participation (i.e. nodes do not have to know other participants in advance in order to participate).

Some possible remedies include the following. First, we can require all participants to post their private lottery outputs every single round even if they lose the lottery, in which case any lack of message at any point would be indicative of some withholding. Naturally, this is costly in terms of communication complexity and thus not the most practical. Second, a technique called SSLE (single secret leader election) \cite{boneh2020single} can be used to guarantee one winner per round, enabling detection of any withholding attack. In a nutshell, SSLE allows a setup where exactly one leader from a group is randomly chosen such that the identity of the leader will only be known to the chosen leader until it publicly reveals its identity. Note that the guarantee of one winner as opposed to the expectation of one winner is what separates SSLE from schemes like Algorand. It does not prevent withholding attack by itself, however.

\subsection{Adaptive Security or Lack Thereof}
* Adaptive security: either revelation of leadership coupled with entropy provision OR the size of subset (that adversary needs to adaptively corrupt) is big

* Adaptive insecurity:

1) gap between revelation of leadership/membership and entropy provision

2) leader can withhold

3) prediction possible due to asymmetry in computation power, e.g. RandRunner

\subsection{Quality vs Efficiency}
% Mt. Random's Tier 1 (fresh randomness per node) > 2 (one VRF, not biasable) > 3 (many VRFs, biasable via withholding) -- from quality of randomness perspective
The protocols that we have seen so far provide a range of efficiency and quality trade-offs under different setups, assumptions and adversarial models. PVSS/VSS based protocols offers uniform randomness, but comes at  quartic communication complexity. 
VRF based protocols require very little communication and computation but the output is biasable by withholding. DVRF based protocols get rid of the bias by allowing a set of participants greater than a threshold to recover the output. VDF based protocols require high computational cost (sequential squarings) but generates uniform pseudorandom outputs with quadratic communication cost. While these protocols can be used on their own, they can also be combined in a modular to build a distributed randomness beacon. Mt. Random \cite{cascudomt}, a multi-tiered randomness beacon that combines PVSS and (D)VRF techniques is one such example. 

\joenote{should there be a separate section on protocols that combine other protocols?}
Mt. Random has three tiers running independently and in parallel, each based on a different technique and providing different trade-off between complexity and quality of randomness. Tier 1 provides uniform randomness via PVSS based protocols but comes at quartic communication cost in the worst case. Mt. Random  brings down the cost per beacon output by producing large batches of output at a time and gradually releasing it in sub-batches by using an extension of Albatross called GULL (Gradually UnLeashed aLbatross) \cite{cascudomt}. It is possible to substitute GULL with any of the Commit-Reveal-Recover variants from Section \ref{section:commit-reveal-recover}. Tier 2 provides uniform pseudorandomness via DVRF based protocols and requires quadratic communication cost in the worst case. Mt. Random uses DDH based version of drand, but could be substituted with any of the DVRF based protocols from Section \ref{section:dvrf} or VDF based protocols from Section \ref{section:vdf}. The seeds for DVRF/VDF are periodically refreshed by using outputs from Tier 1, making them more secure than their stand alone versions. Tier 3 provides biased pseudorandomness using VRF based protocols at quadratic communication cost in the worst case (though it could be adjusted based on the required quality of randomness). The output of this tier is biased because a participant can withhold their shares to bias the final output and unlike Tier 2, the withheld shares can't be reconstructed. Mt. Random uses a variation of Ouroboros Praos where every participant computes and broadcasts their VRF outputs (and requires no subset selection via private lottery). Even though this makes detecting malicious participants (and maybe punishing them) easier, the beacon output for the round would still remain biased. Randomness from either Tier 1 or Tier 2 is used to seed the VRF. 

Mt. Random illustrates a framework in which PVSS and (D)VRF protocols can be combined in a multi-tiered fashion where higher tiers generate random outputs faster than lower tiers albeit with losses in randomness quality. It is possible to extend the framework to other primitives/building blocks or use an altogether different framework to combine different protocols. This remains to be explored further.

\todo{conclusions, open problems}

\printbibliography
\appendix
\section*{Appendix}
\addcontentsline{toc}{section}{Appendix}
\renewcommand{\thesection}{\arabic{section}}
\section{Verifiable Delay Function (VDF)}
\label{appendix:vdf}
A VDF \cite{boneh2018verifiable} can be described via a set of three algorithms:
\begin{itemize}
\item $Setup(\lambda, T) \rightarrow pp$ is a randomized algorithm that takes a security parameter $\lambda$ and a time bound $T$  and outputs public parameters $pp$ sampled from some parameter space $PP$.
\item $Eval(pp, x) \rightarrow (y, \pi)$ takes public parameters $pp\in PP$, an input $x$ and outputs $y$ and a proof $\pi$.
\item $Verify(pp, x, y, \pi) \rightarrow \{accept, reject\}$ outputs $accept$ if $y$ is the correct evaluation of the VDF on input $(pp, x)$ and $reject$ otherwise.
\end{itemize}

A VDF must satisfy the following three properties:
\begin{itemize}
\item $\epsilon$-evaluation time. $Eval(pp, x)$ runs in time at most $(1 + \epsilon) T$, for all $x$ and all $pp$ output by $Setup(\lambda, T)$.
\item Sequentiality. A parallel algorithm $\mathcal{A}$, using at most $poly(\lambda)$ processors, that runs in time less than $T$ cannot compute the function. Specifically, for a random $x$ and $pp$ output by $Setup(\lambda, T)$, if $(y, \pi) = Eval(pp, x)$ then $Pr[\mathcal{A}(pp, x) = y]$ is $\mathsf{negl(\lambda)}$.
\item Uniqueness. For an input $x$ and $T$, exactly one $y$ will be accepted by $Verify$ with negligible error probability. Specifically, let $\mathcal{A}$ be an efficient algorithm that given $pp$ as input, outputs $(x, y, \pi)$ such that $Verify(pp, x, y, \pi) = accept$. Then $Pr[Eval(pp, x) \neq y]$ is $\mathsf{negl(\lambda)}$.
\end{itemize}
For sequentiality, computing $y$ using $Eval(pp,x)$ requires $T$ sequential squarings even on a parallel computer with $poly(\lambda)$ processors. Computing proof $\pi$ increases the running time to $(1+\epsilon)T$, as needed for $\epsilon$-evaluation time. Pietrzak \cite{pietrzak2018simple} and Wesolowski's \cite{wesolowski2019efficient} proposals differ in the way $\pi$ is generated and quickly verified. They give two different public-coin succinct arguments for proving that the output $y$ is correct and can be made non-interactive using the Fiat-Shamir Heuristic \cite{amos1986prove}. 

Both of the proof system has its own strengths. Wesolowski's proof system has shorter proofs (1 group element versus $\log T$ elements) and faster verification time (2 exponentiations versus $2 \log T$). Pietrzak's proof system allows for more efficient computation of the proof requiring only $O(\sqrt{T} \cdot \log T)$ multiplications (vs $O(T/\log (T))$), is more secure and applies in a more general setting.

\subsection{Trapdoor VDF}
\label{appendix:tvdf}
Trapdoor VDFs \cite{wesolowski2019efficient, schindler2021randrunner} are an extension and modification of traditional VDFs in which the $Setup$ algorithm in addition to the public parameters $pp$ also outputs a trapdoor (secret key) $sk$ to the participant invoking the algorithm.  The parameter $pp$ is published whereas $sk$ is kept secret. Furthermore, the algorithm $TrapdoorEval$ provides an alternate way to evaluate the VDF efficiently, i.e. within time $\phi{(poly{(\lambda)})}$ to participants which know the trapdoor $sk$. Participants without this knowledge can still use the $Eval$ algorithm to compute the output in $(1+\epsilon)T$ sequential steps.
Trapdoor VDFs can be described by a set of four algorithms as follows.
\begin{itemize}
    \item $Setup(\lambda) \rightarrow (pp, sk)$ is a randomized algorithm that takes a security parameter $\lambda$ and outputs public parameters $pp$ and a trapdoor secret key $sk$.
    \item $VerifySetup(\lambda, pp) \rightarrow (accept, reject)$ returns $accept$ if the validity of $pp$ can be successfully checked, returns $reject$ otherwise.
    \item $Eval(pp, x, T) \rightarrow (y, \pi)$ takes an input $x$ and time parameter $T$ and outputs $y$ and a proof $\pi$.
    \item $TrapdoorEval(pp,x,T,sk) \rightarrow (y, \pi)$ takes an input $x$ and $T$ along with trapdoor $sk$ and outputs $y$ and a proof $\pi$ such that the algorithm takes less than time $T$ to complete unlike $Eval$.
    \item $Verify(pp, x, T, y, \pi) \rightarrow \{accept, reject\}$ outputs $accept$ if $y$ is the correct evaluation of the VDF on input $x$ and $T$.
\end{itemize}

Due to the introduction of trapdoors and strong uniqueness, in contrast to traditional VDFs, trapdoor-VDF must satisfy the following properties:

\begin{itemize}
    \item $\epsilon$-evaluation time. $Eval(pp, x, T)$ runs in time at most $(1 + \epsilon) T$, for all $x$ and all $pp$ output by $Setup(\lambda)$.
    \item Sequentiality without trapdoor. A parallel algorithm $\mathcal{A}$, using at most $poly(\lambda)$ processors, that runs in time less than $T$ cannot compute the function without the knowledge of a secret trapdoor. Specifically, for a random $x$ and all $pp$ output by $Setup(\lambda)$, if $(y, \pi)$ is the output of $Eval(pp, x, T)$ or $TrapdoorEval(pp,x,T,sk)$, then the probability that $\mathcal{A}$ can compute $y$ in less than $T$ steps is negligible.
    \item Strong uniqueness. For each input $x$ and all public parameters $pp$, exactly one $y$ will be accepted by $Verify$ with negligible error probability even if the public parameters have been adversarially generated. Specifically, let $\mathcal{A}$ be an efficient algorithm that outputs $(pp, x, T, y, \pi)$ such that $Verify(pp, x, T, y, \pi) = accept$. Then $Pr[Eval(pp, x, T) \neq y]$ is negligible.
\end{itemize}

\section{Verifiable Secret Sharing (VSS)}
\label{appendix:vss}
VSS can be described by the following algorithms.
\begin{itemize}
    \item $Setup(\lambda) \rightarrow pp$ generates the public parameters $pp$ and is an implicit input to all other algorithms.
    \item $ShareGen(s) \rightarrow (\{s_i\}, C)$ is executed by the dealer with secret $s$ to generate secret shares $\{s_i\}$ (each of which is sent to node $i$ correspondingly) as well as commitment $C$ to the secret sharing polynomial of degree $t$.
    \item $ShareVerify(s_i, C) \rightarrow \{0, 1\}$ verifies the correctness of the share $s_i$ using $C$.
    \item $Recon(A, \{s_i\}_{i \in A}) \rightarrow s$ reconstructs the shared secret $s$ via Lagrange interpolation from a set $A$ of $t + 1$ nodes whose shares are passed by the $ShareVerify$ algorithm.
\end{itemize}

VSS schemes have two security requirements:
\begin{itemize}
    \item Secrecy. If the dealer is honest, then the probability of an adversary learning
    any information about the dealer’s secret in the sharing phase is $\mathsf{negl}(\lambda)$.
    \item Correctness. If the dealer is honest, then the honest nodes output the secret
    $s$ at the end of the reconstruction phase with a high probability of $1 - \mathsf{negl}(\lambda)$.
\end{itemize}
Feldman-VSS \cite{feldman1987practical} and Pedersen-VSS \cite{pedersen1991non} are the most commonly used implementations of the above interface.

\subsection{Feldman-VSS}
\label{appendix:feldmanVSS}
The following summarizes a simple VSS scheme proposed by Paul Feldman for sharing a secret $s$ among $n$ participants where any subset of $t+1$ among them can reconstruct the group secret.
\begin{itemize}
    \item $ShareGen(s) \rightarrow (\{s_i\}, C)$ with $s \in \mathbb{Z}_q$ involves the dealer sampling $t$ random coefficients $a_1, \ldots, a_t \in \mathbb{Z}_q$ and constructing a $t$ degree polynomial $p(x) = s + a_1x+ a_2x^2 +\ldots+a_tx^t$.\\
    The shares are computed as $s_i = p(i)$ in mod $q$ for $1\le i \le n$ and shared privately with each participant.\\
    The commitments to the secret $C_0 = g^s$ as well as coefficients $C_j = g^{a_j}$ for $j = 1,\ldots,t$ are also broadcast by the dealer.
    
    \item $ShareVerify(s_i, C) \rightarrow \{0, 1\}$ involves each participant $P_k$  checking if:
    $$g^{s_k} = \prod_{j = 0}^{t } C_j^{k^j} = C_0 C_1^k C_2^{k^2} \cdots C_{t }^{k^{t }}$$
     If it does not hold for some $k$, then participant $P_k$ broadcasts an accusation against the dealer, who has to respond by broadcasting the correct $s_k$. \\
     Correct reconstruction is achieved by filtering out shares that do not satisfy $ShareVerify$.
    \item $Recon(A, \{s_i\}_{i \in A}) \rightarrow s$ outputs the secret $s$ by performing  Lagrange interpolation involving Lagrange coefficients $\lambda_i = \prod_{j \neq i} \frac{j}{j - i}$ in mod $q$ with a subset of valid $t+1$ shares:
    $$s = p(0) = \sum_{i = 1}^{t+1} s_i \lambda_i$$
\end{itemize}

The verifiability in Feldman-VSS comes from inclusion of commitments to the coefficients. These commitments enable participants to verify the validity of the shares that they receive from the dealer.

\subsection{Pedersen-VSS}
\label{appendix:pedersenVSS}
Reminiscent of Pedersen commitment, Pedersen-VSS is a variation that couples the commitment to the coefficient of secret polynomial with another randomly chosen polynomial. By removing the assumption that $g^s$ is known beforehand as part of the commitment to the coefficients, it results in a secret sharing scheme which is unconditionally secure for the dealer. It can be summarized as follows:

\textbf{Setup:} In addition to parameters $p,q,g$ inherent to Feldman-VSS, it uses an element $h$ in the subgroup of $\mathbb{Z}^*_p$ generated by $g$. It is assumed that the adversary cannot find the discrete logarithm of $h$ relative to the base $g$.

\begin{itemize}
\item $ShareGen(s) \rightarrow (\{s_i\}, C)$ with $s \in \mathbb{Z}_q$ involves the dealer sampling two random polynomials $p(x) = a_0 + a_1x+ \ldots+a_tx^t$ and $p'(x) = b_0 + b_1x +\ldots+b_tx^t$  where $a_i, b_i \in \mathbb{Z}_q$ and the secret $s = a_0 = p(0)$.\\
The shares are computed as $(s_i = p(i), s'_i = p'(i))$ in mod $q$ for $1 \le i \le n$ and are shared with each participant privately.\\
Also distributed from the dealer are coupled commitments to coefficients of $p$ and $p'$, i.e. $C_j = g^{a_j} h^{b_j}$ for $j = 0, ..., t$.
\item $ShareVerify(s_i, C) \rightarrow \{0, 1\}$ involves each participant $P_k$ with shares $(s_k, s'_k)$ and the public polynomial coefficient commitments checking if:
$$g^{s_k} h^{s'_k} = \prod_{j = 0}^{t} C_j^{k^j}$$
Similar to Feldman-VSS, any accusation of incorrect sharing against dealer by a participant $P_k$ would require the dealer to broadcast the correct values of shares $(s_k, s'_k)$.
\item $Recon(A, \{s_i\}_{i \in A}) \rightarrow s$ outputs the secret $s$ by performing Lagrange interpolation involving Lagrange coefficients $\lambda_i = \prod_{j \neq i} \frac{j}{j - i}$ in mod $q$ with a subset of valid $t+1$ shares (of polynomial $p(x)$):
    $$s = p(0) = \sum_{i = 1}^{t+1} s_i \lambda_i$$
\end{itemize}

Effectively, what Pedersen-VSS is able to achieve is the decoupling of $g^{s}$ from the published commitment for verifying the correctness of sharing ( $g^{a_i} h^{b_i}$). In other words, the verification process in which the participants verify their shares does not (even information-theoretically) leak any information regarding the initial secret $s$, a fact that is not true with Feldman-VSS. This would be useful later on, when VSS is used as a subprotocol for distributed key generation (DKG), where an adversary is otherwise able to bias the outcome.

\section{Distributed Key Generation (DKG)}
\label{appendix:dkg}
A DKG protocol allows a set of $n$ participants to collectively generate a group public key, the individual secret keys, and the corresponding public keys without the help of a trusted third party. It does so by allowing every participant to become a dealer with VSS and post some related information. The global implicit secret key is the sum of the secrets dealt by a set of participants who have shared correctly, and the public information is used to derive the public keys. DKG is described by the following algorithm:
\begin{itemize}
    \item $DKG(1^{\lambda}, t, n) \rightarrow (\vec{SK}, \vec{PK}, pk)$ is a distributed key generation algorithm that takes a input security parameter $1^\lambda$, the number of participants $n$ and the threshold parameter $t$ and outputs a group public key $pk$, the individual secret keys $\vec{SK} = \{sk_1, sk_1, \ldots, sk_n\}$, and the corresponding public keys $\vec{PK} = \{pk_1, pk_2, \ldots, pk_n\}$
\end{itemize}

A DKG protocol should satisfy the following security requirements:
\begin{itemize}
    \item Correctness
        \begin{enumerate}
        \item All subsets of $t+1$ shares provided by honest participants define the same unique secret key $x$.
        \item All honest participants have the same value of public key $y=g^x$, where $x$ is the unique secret guaranteed above.
        \item $x$ is uniformly distributed in $\mathbb{Z}_q$, and thus $y$ is uniformly distributed in $\mathbb{G}_q$ (subgroup of $\mathbb{Z}^*_p$ generated by $g$).
        \end{enumerate}
        
    \item Secrecy. No information on $x$ can be learned by the adversary except for what is implied by the value $y = g^x$.
\end{itemize}

One of the best known DKG schemes is Joint-Feldman \cite{pedersen1991threshold}, proposed by Torben Pryds Pedersen. As discussed in \cite{gennaro1999secure}, Joint-Feldman does not guarantee uniform randomness or secrecy of the shared secret key. Hence a malicious adversary can bias the public global key. Joint-Pedersen, proposed in the same paper combines discrete logarithm and Pedersen's commitments to guarantees uniform randomness by increasing the number of communication rounds by one.  Nevertheless, it has been shown that the public key biasability should not be a problem for applications that use DKG as a subprotocol for distributed randomness.
\subsection{Joint-Feldman}
\label{appendix:jointFeldman}
In Joint-Feldman DKG scheme, each participant use Feldman-VSS to share a randomly chosen secret. The protocol is implemented as follows:
\begin{itemize}
    \item $DKG(1^{\lambda}, t, n) \rightarrow (\vec{SK}, \vec{PK}, pk)$  proceeds in two phases---Sharing and Reconstruction.
    \begin{enumerate}
        \item In Sharing phase, each participant $P_i$ runs Feldman-VSS by choosing a random polynomial over $\mathbb{Z}_q$ of degree $t$, $p_i(z) = \sum_{j = 0}^{t} a_{ij} z^j$ and sending a subshare $s_{ij} = p_i(j)$ mod $q$ to each participant $P_j$ privately. \\
        To satisfy the verifiability portion of VSS, $P_i$ also broadcasts $C_{ik} = g^{a_{ik}}$ for $k = 0, \ldots, t$. Let the commitment corresponding to the secret be denoted by $y_i = C_{i0}$.
        
        Each participant $P_j$ also verifies the shares he receives from other participants by performing verification steps of Feldman-VSS on each subshare. If the verification for an index $i$ fails, $P_j$ broadcasts a complaint against $P_i$. If $P_i$ receives more than $t$ complaints, then $P_i$ is disqualified. Otherwise, $P_i$ reveals the subshare $s_{ij}$ for every $P_j$ that has broadcast a complaint. We call $QUAL$ the set of non-disqualified participants.
        
        \item Reconstruction phase calculates the keys based on $QUAL$.
        The group public key is calculated as $pk = \prod_{i \in QUAL} y_i$ where the individual public keys are $pk_i = y_i$. Each participant $P_j$'s share of the group secret is  computed as $sk_j = \sum_{i \in QUAL} s_{ij}$ mod $q$.  Though not computed explicitly, the group secret key $sk$ is equal to both $\sum_{i \in QUAL} a_{i0}$ mod $q$ and the Lagrange interpolation involving the shares $\{sk_j\}_{j \in QUAL}$.
    \end{enumerate}
\end{itemize}

\subsection{Joint-Pedersen}
\label{appendix:jointPedersen}
The biasability of Joint-Feldman comes from the fact that the decision on who will be part of $QUAL$ is made after the adversary has seen the $y_i$'s of all the participants. This happens because $y_i = C_{i0}$ is published as part of the commitment (required to prove correctness of sharing). Joint-Pedersen solves this by decoupling the output $y_i$ from the commitments for proving correctness by using Pedersen-VSS. This results in $QUAL$ and the secret $x$ being determined first, and an additional run of Feldman-VSS to recover $y_i$'s. It is implemented as follows:
\begin{itemize}
    \item $DKG(1^{\lambda}, t, n) \rightarrow (\vec{SK}, \vec{PK}, pk)$ involves two phases---Sharing and Reconstruction. However, the Reconstruction phase requires an additional run of Feldman-VSS to recover the public keys. 
    \begin{enumerate}
    \item Sharing phase involves each participant $P_i$ running Pedersen-VSS by choosing two random polynomials over $\mathbb{Z}_q$ of degree $t$, $p_i(z) = \sum_{j = 0}^{t} a_{ij} z^j$ and $p'_i(z) = \sum_{j = 0}^{t} b_{ij} z^j$ and sending subshares ($s_{ij} = p_i(j)$, $s'_{ij} = p'_i(j)$) in mod $q$ to each participant $P_j$ privately and broadcasting the commitments $C_{ik} = g^{a_{ik}} h^{b_{ik}}$ for $k = 0, \ldots, t$ to prove correctness. Note that unlike Joint-Feldman, publishing $C_{ik}$ does not reveal any information about $y_i = g^{a_{i0}}$.\\
    Each participant $P_j$ verifies the shares he receives from other participants by performing share verification step of Pedersen-VSS on each subshare. If the verification for an index $i$ fails, $P_j$ broadcasts a complaint against $P_i$.
    If $P_i$ receives more than $t$ complaints, then $P_i$ is disqualified. Otherwise, $P_i$ reveals the subshare $(s_{ij}, s'_{ij})$ for every $P_j$ that has broadcast a complaint. We call $QUAL$ the set of non-disqualified participants.
    
    \item Reconstruction is a two-part process. The first part involves calculating each participant's share of group secret and implicitly recovering the group secret based on $QUAL$, like in Joint-Feldman. Each participant $P_j$'s share of the group secret is calculated as $sk_j = \sum_{i \in QUAL} s_{ij}$ mod $q$.  The group secret key $sk$ is equal to the Lagrange interpolation involving the shares $\{sk_j\}_{j \in QUAL}$. 
    
    The second part of Reconstruction phase involves extracting $pk$ by an additional run of Feldman-VSS because unlike Joint-Feldman,  we do not have the corresponding shares $y_i = g^{a_{i0}}$'s required its calculation.  Each participant $P_i \in QUAL$ exposes $y_i = g^{a_{i0}}$ as follows:
        \begin{enumerate}
            \item Each participant $P_i \in QUAL$ broadcasts the commitment to the coefficient of the secret polynomial $p_i(z)$ as $A_{ik} = g^{a_{ik}}$ for $k = 0, \ldots, t$. Let $y_i = A_{i0}$.
            \item Each $P_j$ verifies the values broadcast by each other participant $P_i$ are consistent with the shares $s_{ij}$ shared earlier in a similar way as Feldman-VSS. If the verification fails, $P_j$ broadcasts a complaint against $P_i$ by posting the shares $s_{ij}$ and $s'_{ij}$.
            \item For any participant $P_i$ that receives at least one valid complaint, all the other participants run the reconstruction phase of Pedersen-VSS to recover the secret polynomial $p_i(z)$. 
            \item Finally, the group public key is calculated as $pk = \prod_{i \in QUAL} y_i = \prod_{i \in QUAL} g^{a_{i0}}$ where $y_i$ is individual public key $pk_i$ for participant $P_i$.
        \end{enumerate}
    \end{enumerate}
\end{itemize}

\subsection{Escrow-DKG}
\label{appendix:edkg}
Escrow-DKG \cite{david2019rational} extends DKG to a model where the participants are not expected to follow some predetermined set of instructions and instead are driven to maximize their profit. It does so by introducing a transparent escrow service that takes participants' deposits and can burn or redistribute them. It proceeds in similar phases as Joint-Feldman. However, any complaint of undesired behavior by a participant against another participant is arbitrated by the escrow and can result in deposits being slashed. The protocol fails once a complaint has been filed. The modification of Escrow-DKG used in EVR , with $n$ participants and threshold $t$, can be described by the following algorithms:
\begin{itemize}
    \item $EscrowEnroll(d, pk, H(C_{0})) \rightarrow \{0,1\}$ is used by a participant with public encryption key $pk$ to register with the escrow with deposit $d$ and hash of commitment to her partial secret $C_{0}$. In case of Feldman-VSS, $C_{0} = g^{s}$. It returns the success of enrollment.
    
    \item $Commit (s) \rightarrow (\{Enc(pk_i, s_{i})\}, C)$ is used by a participant with secret $s$ to generate encrypted subshares and commitments by executing $VSS.ShareGen(s)$. For Feldman-VSS, it outputs commitment to the coefficients of $t$ degree random polynomial $C_j = g^{a_j}$ for $0\le j \le t$ and subshares for every other participant $P_i$ encrypted using their public key $Enc(pk_i, s_{i})$. \\
    Each participant verifies the consistency of the subshares with the commitments. The escrow also checks if the published $C_{0}$ matches with $H(C_{0})$ for participant $P_i$. Any complaint is arbitrated by the escrow and can result in deposits being slashed.
    
    \item $Reveal(A, \{x_i\}_{i \in A}) \rightarrow (x, X)$ takes a subset of $t+1$ individual key shares and reconstructs the shared group secret $x$ using $VSS.Recon$. In Feldman-VSS, each participant $P_i$ calculates their secret key share as $x_i = \sum_{j=1}^{n} s_j$ in mod $q$ and the group secret $x$ is reconstructed by Lagrange interpolation on $t+1$ such shares. Additionally, it also outputs its corresponding public key $X = \prod_{i=1}^{n} C_{i0}$ for verification.
    
    \item $EscrowVerify(x, X)\rightarrow\{0,1\}$ is used by the escrow to verify that the published secret $x$ is indeed the one that corresponds to $X$.
\end{itemize}

\section{Publicly Verifiable Secret Sharing (PVSS)}
\label{appendix:pvss}
PVSS can be described by the following algorithms.
\begin{itemize}
    \item $Setup(\lambda) \rightarrow pp$ generates the public parameters $pp$ and is an implicit input to all other algorithms.
    \item $KeyGen(\lambda) \rightarrow (sk_i, pk_i)$ generates the PVSS key pair used for encryption and decryption for node $i$.
    \item $Enc(pk_i, m) \rightarrow c$ and $Dec(sk_i, c) \rightarrow m'$ are subalgorithms used when the dealer sends an encrypted share to node $i$ and when node $i$ decrypts the encrypted share, respectively. Both $Enc$ and $Dec$ may optionally output a proof of correctness (e.g. $\pi_{DLEQ}$).
    \item $ShareGen(s) \rightarrow (\{Enc(pk_i, s_i)\}, \{s'_i\}, \pi)$ with $s'_i = Dec(sk_i, Enc(pk_i, s_i))$ is a two-part process. First, the dealer with secret $s$ generates secret shares $\{s_i\}$, encrypts them to generate $\{Enc(pk_i, s_i)\}$, and sends each of them to node $i$ along with an optional encryption proof of correctness. Second, node $i$ decrypts the received encryption from the dealer to generate $s'_i$ and broadcasts it for reconstruction along with an optional decryption proof of correctness. At the protocol level, this yields $\{s'_i\}$ as a result. Note that it is possible that $s'_i \neq s_i$. In fact, $s'_i = h^{s_i}$ for some group generator $h$ is standard in the landscape due to certain PVSS implementation details (to be delineated afterwards). Note that $\pi$ incorporates optional encryption and decryption proofs of correctness as well as any auxiliary proof necessary to enable a certain PVSS implementation.
    \item $ShareVerify(\{Enc(pk_i, s_i)\}, \{s'_i\}, \pi) \rightarrow \{0, 1\}$ verifies if the sharing is correct overall. Again, verifying $\pi$ should involve verifying the optional proofs for encryption and decryption as well as any auxiliary proof necessary for proving correctness.
    \item $Recon(A, \{s'_i\}_{i \in A}) \rightarrow s'$ reconstructs the shared secret $s'$ via Lagrange interpolation (in the exponent) from a set $A$ of $t + 1$ nodes whose contributions are passed by the $ShareVerify$ algorithm. Typically, $s' = h^s$ in the landscape.
\end{itemize}

PVSS is a secure VSS scheme providing the following additional guarantee:
\begin{itemize}
    \item Public Verifiability. If the $ShareVerify$ algorithm returns 1, then the scheme is valid in a publicly verifiable manner with high probability $1 - \mathsf{negl}(\lambda)$.
\end{itemize}

\subsection{Schoenmakers PVSS}
\label{appendix:schoenmakersPVSS}
One of the most common PVSS schemes used in practice is one by Schoenmakers \cite{schoenmakers1999simple}. As typical, the setup involves $g, h \in \mathbb{G}_q$ for $\mathbb{G}_q$ of prime order $q$. Additionally, each participant $P_i$ generates a private key $x_i \in \mathbb{Z}^*_q$ and registers $y_i = h^{x_i}$ as its public key.

\begin{itemize}
\item $ShareGen(s) \rightarrow (\{Enc(y_i, s_i)\}, \{s'_i\}, \pi)$ with $s'_i$ equal to $Dec(x_i, Enc(y_i, s_i))$ first involves production of $\{Enc(y_i, s_i)\}$ by the dealer with secret $s$. Namely, the dealer picks a random polynomial $p$ of degree $t$ with coefficients in $\mathbb{Z}_q$
\[
p(x) = \sum_{i = 0}^{t} a_i x^i
\]
where $s = p(0) = a_0$ and computes $Y_i = Enc(y_i, s_i) = y_i^{p(i)}$, which is sent to each node $i$ along with information needed to prove its correctness: $C_j = g^{a_j}$ for $0 \leq j \leq t$ such that $X_i = \prod_{j = 0}^{t} C_j^{i^j} = g^{p(i)}$ and $DLEQ(g, X_i, y_i, Y_i)$. Upon receiving $Y_i$, node $i$ computes $s'_i = Dec(x_i, Y_i) = Y_i^{1 / x_i} = h^{p(i)}$ and generates information needed to prove its correctness: $DLEQ(h, y_i, s'_i, Y_i)$.
\item $ShareVerify(\{Y_i\}, \{s'_i\}, \pi) \rightarrow \{0, 1\}$ verifies the encryption proof of correctness $DLEQ(g, X_i, y_i, Y_i)$ where $X_i$'s are computed from $C_j$'s as well as the decryption proof of correctness $DLEQ(h, y_i, s'_i, Y_i)$.
\item $Recon(A, \{s'_i\}_{i \in A}) \rightarrow h^s$ performs the following Lagrange interpolation in the exponent
\[
\prod_{i \in A} (s'_i)^{\lambda_{0, i, A}} = h^{\sum_{i \in A} p(i) \lambda_{0, i, A}} = h^{p(0)} = h^s
\]
where $\lambda_{0, i, A}$ denotes the Lagrange coefficients. Note that, unlike VSS, the scheme does not require the knowledge of the values $p(i)$ by the participants. The private keys $x_i$ are not exposed as well and thus can be reused.
\end{itemize}

\subsection{Scrape PVSS}
\label{appendix:scrapePVSS}
Following the work of \cite{cascudo2017scrape}, we define a $[n, k, d]$ code $C$ to be a linear error correcting code over $\mathbb{Z}_q$ of length $n$, dimension $k$, and minimum distance $d$. Its dual code $C^\perp$ is the vector space consisting of vectors $c^\perp \in \mathbb{Z}_q^n$ such that $\langle c, c^\perp \rangle = 0$ for all $c \in C$. Scrape's PVSS verification relies on the following lemma.
\begin{lemma}
If $v \in \mathbb{Z}_q^n \setminus C$ and $c^\perp$ is chosen uniformly at random in $C^\perp$, then $Pr\left[\langle v, c^\perp \rangle = 0\right]$ is exactly $\frac{1}{q}$.
\end{lemma}

Assuming that $n < q$, we harness Reed-Solomon codes $C$ of the form
\[
C = \{(p(1), p(2), ..., p(n)) : p(x) \in \mathbb{Z}_q[x], \deg p(x) \leq k - 1\}
\]
where $p(x)$ ranges over all polynomials in $\mathbb{Z}_q[x]$ of degree at most $k - 1$. Then $C$ represents a $[n, k, n - k + 1]$ code while $C^\perp$ is a $[n, n - k, k + 1]$ code given by
\[
C^\perp = \{(\mu_1 f(1), ..., \mu_n f(n)) : f(x) \in \mathbb{Z}_q[x], \deg f(x) \leq n - k - 1\}
\]
where $\mu_i = \prod_{j = 1, j \neq i}^n \frac{1}{i - j}$.

Overall, Scrape PVSS is an optimization to Schoenmakers PVSS requiring $O(n)$ exponentiations to verify $n$ shares as opposed to $O(n t)$ exponentiations, leveraging the above coding theory related to Reed-Solomon codes. The idea is that the dealer, instead of committing to each polynomial coefficient via $C_j$, computes and distributes $v_i = g^{p(i)}$ directly, in which case each verifier needs to sample a random codeword $c^\perp = (c_1^\perp, ..., c_n^\perp)$ from $C^\perp$ and run a verification test involving all $v_i$'s at once.

Scrape PVSS comes in two flavors: $PVSS_{DDH}$ and $PVSS_{DBS}$. The former relies on the DDH (decisional Diffie-Hellman) assumption while the latter uses a bilinear pairing and thus relies on the DBS (decisional bilinear square) assumption \cite{heidarvand2008public}.\\

\noindent\underline{$PVSS_{DDH}$}
\begin{itemize}
\item $ShareGen(s) \rightarrow (\{Enc(y_i, s_i)\}, \{s'_i\}, \pi)$ with $s'_i$ equal to $Dec(x_i, Enc(y_i, s_i))$ is the same as that of Schoenmakers PVSS except the fact that $v_i = g^{p(i)}$ is computed and sent directly by the dealer as opposed to $C_j$'s. The encryption and decryption proofs $DLEQ(g, v_i, y_i, Y_i)$ and $DLEQ(h, y_i, s'_i, Y_i)$ remain unchanged.
\item $ShareVerify(\{Y_i\}, \{s'_i\}, \pi) \rightarrow \{0, 1\}$ additionally requires a verifier to sample a random codeword $c^\perp = (c_1^\perp, ..., c_n^\perp)$ from $C^\perp$ (dual code of $C$ corresponding to the secret sharing instance) and run the following verification test given by
\[
\prod_{i = 1}^n v_i^{c_i^\perp} = g^{\sum_{i = 1}^n p(i) c_i^\perp} = g^{\langle c, c^\perp \rangle} = g^0 = 1
\]
where $\langle \cdot, \cdot \rangle$ denotes an inner product. It is in this way that $O(n)$ exponentiations are needed to verify $n$ shares.
\item $Recon(A, \{s'_i\}_{i \in A}) \rightarrow h^s$ is the same as that of Schoenmakers PVSS.
\end{itemize}

\noindent\underline{$PVSS_{DBS}$}\\
$PVSS_{DBS}$ provides a different flavor to $PVSS_{DDH}$, as it uses a bilinear pairing (without loss of generality) $e: \mathbb{G} \times \mathbb{G} \rightarrow \mathbb{G}_T$ with $\mathbb{G} = \langle g \rangle = \langle h \rangle$ for two independent generators of $\mathbb{G}$ and $\mathbb{G}_T$ denoting a cyclic group of prime order $q$. Fundamentally similar to $PVSS_{DDH}$, the scheme necessitates appropriate algebraic modifications accordingly while the final shared secret is $e(h^s, h)$ rather than $h^s$.
\begin{itemize}
\item $ShareGen(s) \rightarrow (\{Enc(y_i, s_i)\}, \{s'_i\}, \pi)$ with $s'_i$ equal to $Dec(x_i, Enc(y_i, s_i))$ is the same as in $PVSS_{DDH}$ except that both encryption and decryption proofs of correctness are no longer necessary.
\item $ShareVerify(\{Y_i\}, \{s'_i\}, \pi) \rightarrow \{0, 1\}$ instead requires a verifier to essentially replace the encryption and decryption proofs with verifying two pairing equations, respectively. The encryption proof $DLEQ(g, v_i, y_i, Y_i)$ is replaced by verifying the pairing equation $e(v_i, y_i) = e(g, Y_i)$. The decryption proof $DLEQ(h, y_i, s'_i, Y_i)$ is replaced by verifying the pairing equation $e(s'_i, y_i) = e(h, Y_i)$. The same verification test
\[
\prod_{i = 1}^n v_i^{c_i^\perp} = 1
\]
is also run.
\item $Recon(A, \{s'_i\}_{i \in A}) \rightarrow e(h^s, h)$ outputs $e(h^s, h)$ as the shared secret after the corresponding Lagrange interpolation in the exponent outputs $h^s$.
\end{itemize}

\subsection {Albatross}
\label{appendix:albatross}

\noindent\textbf{Packed Shamir Secret Sharing} \\
Packed Shamir secret sharing is a generalization of Shamir secret sharing that allows to secret-share a vector of $\ell$ elements from a field rather than a single element. The key point is that every share is still one element of the field and therefore the sharing has the same computational cost of $\theta(n)$ exponentiations as regular Shamir secret sharing. This is accomplished by having the dealer choose a polynomial $p$ of degree $t+\ell-1$ uniformly at random and use a set of $\ell$ distinct points for secret sharing $\ell$ secrets, e.g. $(s_0, s_1, ..., s_{\ell - 1}) = (p(0), p(-1), ..., p(-(\ell - 1)))$, and another set of $n$ distinct points on the same polynomial for the shares sent by the dealer to each participant, e.g. $(p(1), ..., p(n))$. Any subset of $t+\ell$ points can be used to reconstruct the secret polynomial via Lagrange interpolation and recover the $\ell$ secrets. Note that the usual Shamir secret sharing corresponds to when $\ell = 1$.\\

\noindent\textbf{Linear Perfect $t$-resilient functions}\\
Instead of computing the final randomness from PVSS reconstructions as $\prod_{j \in \mathcal{C}} h^{s^j}$ like in Scrape, Albatross uses a $t$-resilient function for randomness extraction.\\
A $\mathbb{Z}_q$-linear $t$-resilient function is a linear function $\mathbb{Z}_q^r \rightarrow \mathbb{Z}_q^u$ given by a matrix $M \in \mathbb{Z}_q^{u \times r}$ such that the output is uniformly distributed in  $\mathbb{Z}_q^u$ as long as $r-t$ coordinates of the input are uniformly distributed in  $\mathbb{Z}_q^{r-t}$, even if the other $t$ coordinates are completely controlled by the adversary. Such a function can only exist if $u \le r-t$.\\
In the presence of some participant withholding its secret $s$, PVSS only allows us to recover $h^s$ (for some public generator of $h$ of the group) instead of the secret $s$. This would require us to apply $t$-resilient function in the exponent. So, given $h_1, \ldots, h_r$ where $h_i = h^{x_i}$ and $x_i$ is private,  goal is to extract $(\hat{h_1},\ldots, \hat{h_u}) \in \mathbb{G}_q^u$ which is uniformly random. It is achieved by applying the $t$-resilient function given by matrix $M$ to the exponents, i.e., $\hat{h_i} = h^{y_i}$ where $\vec{x} \mapsto \vec{y} = M \cdot \vec{x}$. This can be evaluated efficiently with $O(n^2 \log n)$ exponentiations by choosing $M$ to be a certain type of Vandermonde matrix and adapting the Cooley-Tukey Fast Fourier transform algorithm to work in the exponent (FFTE) \cite{cascudo2020albatross} of the group.\\

In Albatross we assume $n$ participants, of which the static adversary corrupts at most $t$ participants where $t<(n-1)/2$. We then define $\ell = n-2t >0 $. The output of the protocol will be $\ell^2$ elements of $\mathbb{G}_q$. Similar to Scrape, the protocol proceeds in four phases: Commit, Verify, Reveal, Recover and Output.
\begin{enumerate}
    \item \textbf{Commit} Every participant $P_j$ acts as dealer for packed PVSS and publishes encrypted shares and verification information for recovering $\ell$ secrets $h^{s^{(j)}_{0}}, \ldots, h^{s^{(j)}_{\ell-1}}$.
    \item \textbf{Verify} Every participant executes the sharing verification phase on every shared secret. Since verification is public, this fixes the set $\mathcal{C}$ of the first $n-t (= t + \ell)$ participants who have correctly shared.
    \item \textbf{Reveal} Every participant $P_j \in \mathcal{C}$ opens the Shamir secret $(s^{(j)}_{0}, \ldots, s^{(j)}_{\ell-1})$. The other participants verify its consistency with the sharing posted before. The protocol proceeds to the Recover phase only if all the participants in $\mathcal{C}$ have not opened their secrets correctly. Otherwise it proceeds to Case 1 of Output phase.
    \item \textbf{Recover} For each participant $P_a$ that do not open their secret during the Reveal phase, other participants publish the decrypted shares of the secret. Once $t+\ell$ valid shares are published, Lagrange interpolation is used to reconstruct the polynomial and recover the secrets $h^{s^{(a)}_{0}}, \ldots, h^{s^{(a)}_{\ell-1}}$. Then it proceeds to Case 2 of Output phase.
    \item \textbf{Output}
        \begin{itemize}
            \item \textit{Case 1:} When all the participants in $\mathcal{C}$ have opened their secrets correctly, we have a $(n-t) \times \ell$ matrix $S$ with rows indexed by the participants  $P_a \in \mathcal{C}$ and each row corresponding to its $\ell$ opened secrets $(s^{(a)}_{0}, \ldots, s^{(a)}_{\ell-1})$. The final randomness $\mathcal{O}$ with $\ell^2$ elements is computed by each participant as $\mathcal{O} = h^U$, where $U = M \cdot S \in \mathbb{Z}_q^{\ell \times \ell}$.
            
            \item \textit{Case 2:} Otherwise, we have a $(n-t) \times \ell$ matrix $T$ with rows indexed by the participants  $P_a \in \mathcal{C}$ where the row corresponding to $P_a$ is $(h^{s^{(a)}_{0}}, \ldots, h^{s^{(a)}_{\ell-1}})$. The final $\ell \times \ell$ randomness matrix $\mathcal{O}$ is computed as $\mathcal{O} = M \diamond T$ by applying FFTE to each column $T^{(j)}$ of $T$ producing column $\mathcal{O}^{(j)}$ of $\mathcal{O}$.
        \end{itemize}
\end{enumerate}

\section{Threshold Encryption}
\label{appendix:thresholdEnc}
A threshold encryption scheme allows any participant to encrypt a message so that only a subset of size greater than $t$ participants can decrypt the message. It requires a DKG protocol to be run initially to establish the keys used for encrypting and recovering the secret.

$(t, n)$-threshold encryption scheme is composed of the following algorithms:
\begin{itemize}
    \item $DKG(1^\lambda, t, n) \rightarrow (\vec{SK}, \vec{PK}, pk)$ is a distributed key generation algorithm that takes as input a security parameter $1^\lambda$, the number of participants $n$ and the threshold parameter $t$ and outputs a global public key $pk$, individual secret keys $\vec{SK} = \{sk_1, sk_2, \ldots, sk_n\}$, and individual public keys $\vec{PK} = \{pk_1, pk_2, \ldots,pk_n\}$.
    \item $Enc(pk, m) \rightarrow C$ takes as input the global public key and a message, and outputs a ciphertext $C$.
    \item $ShareDec(pk, sk_i, pk_i, C) \rightarrow \mu_i$ takes as input the global public key $pk$, the private key $sk_i$, the public key $pk_i$, a ciphertext $C$ and outputs a decryption share $\mu_i$.
    \item $Rec(pk, \vec{PK}, C, \vec{\mu} )\rightarrow \{m, \mathsf{reject}\}$ is a recovery algorithm that takes as input the global public key $pk$, a ciphertext $C$ and a subset of $t+1$ valid decryption shares $\vec{\mu} = \{\mu_1, \mu_2,\ldots, \mu_{t+1}\}$ together with the public keys $\vec{PK} = \{pk_1, pk_2,\ldots, pk_{t+1}\}$ and outputs a message $m$ or a $\mathsf{reject}$.
\end{itemize}

Following the work of \cite{cortier2013distributed}, a $(t, n)$-threshold encryption scheme should provide the following properties:
\begin{itemize}
    \item Completeness. For any $1\le t\le n$ and for every admissible plaintext $m$, if the keys have been honestly generated with $DKG(1^\lambda, t, n)$, the plaintext encrypted with $Enc(pk, m)$ and a set of at least $t+1$ honest participants have computed the correct decryption shares with $ShareDec(sk_i, pk_i, C)$, then we require $Rec(pk, \vec{PK}, C, \vec{\mu} ) = m$.
    \item Robustness. For any ciphertext $C$ and any two $(t+1)-$subsets of decryption shares $\mu \ne \mu'$ such that $Rec(pk, C, \mu) \ne \mathsf{reject}$ and $Rec(pk, C, \mu') \ne \mathsf{reject}$, then it holds that $Rec(pk, C, \mu) = Rec(pk, C, \mu')$.
    \item IND-CPA against static corruptions. A $(t, n)$ threshold cryptosystem is said to be IND-CPA secure if for any polynomial time adversary $\mathcal{A}$ corrupting at most $t$ participants at the beginning of the protocol, $\mathcal{A}$, who acts on behalf of corrupted nodes, has negligible advantage in a  game $\mathsf{Exp}^{\mathsf{cpa}}_{\mathcal{A}}$ played against challenger, who acts on behalf of the remaining servers. In other words,
    $$|Pr[\mathsf{Exp}_{\mathcal{A}}^{\mathsf{cpa}}(\lambda) = 1] - 1/2| < \mathsf{negl}(\lambda)$$
    
    The game $\mathsf{Exp}^{\mathsf{cpa}}_{\mathcal{A}}$ proceeds as follows:
    \begin{enumerate}
        \item The adversary $\mathcal{A}$ and the challenger run together $DKG(1^\lambda, t, n)$, at the end of which the adversary learns the individual secret keys of all the corrupted nodes $sk_1, sk_2, \ldots, sk_t$. It also obtains the global public key $pk$ and the public keys of all the participants $\vec{PK}$.
        \item $\mathcal{A}$ then chooses two admissible messages $m_0$, $m_1$ of equal length and sends it to the challenger.
        \item The challenger randomly chooses one of them $\beta \leftarrow \{0, 1\}$ and sends $Enc(pk, m_{\beta})$ back to the adversary.
        \item Finally, $\mathcal{A}$ outputs its guess $\beta' \in \{0,1\}$.
    \end{enumerate}
    The output of the game is $1$ if $\beta' = \beta$ and $0$ otherwise and the advantage of $\mathcal{A}$ is defined as $|Pr[\beta' = \beta] - 1/2|$.
\end{itemize}
\subsection{Threshold ElGamal Cryptosystem}
\label{appendix:elGamal}
$(t, n)$-threshold ElGamal cryptosystem \cite{desmedt1990Threshold, cherniaeva2019homomorphic} over an Elliptic Curve $E$ defined in field $\mathbb{F}_p$ ($p$ being a very large prime number), and its cyclic subgroup $\mathbb{G} \in E(\mathbb{F}_p)$ with generator $G$ and prime order $q$, is implemented as follows:
\begin{itemize}
    \item $DKG(1^\lambda, t, n) \rightarrow (\vec{SK}, \vec{PK}, pk)$ runs DKG protocol and generates the common public key $pk$, individual secret keys $\vec{SK}$ and the corresponding individual public keys $\vec{PK}$.
     \item $Enc(pk, M) \rightarrow (A, B)$  takes as input a point $M \in \mathbb{G}$ and the global public key $pk$ and generates ciphertext $C = (A, B) = (rG, M+D) $ where $D = r \cdot pk$.
     \item $ShareDec(pk, sk_i, C) \rightarrow \mu_i$ takes ciphertext $C = (A,B)$, the individual secret key $sk_i$ and the global public key $pk$ as input and generates the decrypted share $\mu_i = sk_i \cdot A$.
     \item $Rec(pk, C, \mu_i, \ldots, \mu_{t+1} ) \rightarrow M$ reconstructs the point $D$ from the public shares $\mu_i, \ldots, \mu_{t+1}$ using Lagrange interpolation and outputs the decrypted message  $M = B - D$.
\end{itemize}

\section{Verifiable Random Function (VRF)}
A VRF \cite{micali1999verifiable,dodis2005verifiable} is a function that, given an input $x$ and a secret key $sk$, generates a unique, pseudorandom output $y$ as well as a proof $\pi$ verifying that the computation has been done correctly. Due to $\pi$, it is possible to repeatedly generate new pseudorandom outputs with one $sk$ and varying inputs in a verifiable manner whereas otherwise (e.g. using a classical pseudorandom function) one needs to divulge the secret key and sacrifice its reusability for public verification purposes. It can be represented by the following tuple of algorithms:
\begin{itemize}
\item $Prove(sk, x) \rightarrow (F_{sk}(x), \pi_{sk}(x))$ generates the pseudorandom output $F_{sk}(x)$ and its proof of correctness $\pi_{sk}(x)$ given input $x$ and secret key $sk$.
\item $Verify(pk, x, y, \pi) \rightarrow \{0, 1\}$ outputs 1 if it is verified that $y = F_{sk}(x)$ using the proof $\pi$ and 0 otherwise.
\end{itemize}

Furthermore, a VRF satisfies the following three properties:
\begin{enumerate}
\item Provability. If $(y, \pi) = Prove(sk, x)$, then the tuple is accepted by the $Verify$ algorithm such that $Verify(pk, x, y, \pi) = 1$.
\item Uniqueness. There does not exist $(y_1, \pi_1) \neq (y_2, \pi_2)$ such that $Verify(pk, x, y_1, \pi_1) = Verify(pk, x, y_2, \pi_2) = 1$.
\item Pseudorandomness. The output is indistinguishable from a random number from a uniform distribution except with negligible probability. This can be written as follows.
\[
Pr\left[b = b' \middle\vert \begin{array}{l}
(x, st) \leftarrow \mathcal{A}^{Prove(\cdot)}_{1}(pk);\\
y_0 = F_{sk}(x);\\
y_1 \leftarrow \{0, 1\}^{\ell_{VRF}};\\
b \leftarrow \{0, 1\};\\
b' \leftarrow \mathcal{A}^{Prove(\cdot)}_{2}(y_b, st)
\end{array}\right] \leq \frac{1}{2} + negl(\lambda)
\]
for any probabilistic polynomial-time algorithm $\mathcal{A} = (\mathcal{A}_1, \mathcal{A}_2)$, which does not query the oracle on $x$.
\end{enumerate}

\subsection{Verifiable Unpredictable Function (VUF)}
A VUF \cite{micali1999verifiable,dodis2005verifiable} is a VRF except the last property of pseudorandomness is replaced by the following unpredictability property.
\begin{itemize}
\item Unpredictability. The output is unpredictable except with negligible probability. In other words:
\[
Pr\left[y = F_{sk}(x) \middle\vert (x, y) \leftarrow \mathcal{A}^{Prove(\cdot)}(pk)\right] \leq negl(\lambda)
\]
for any probabilistic polynomial-time algorithm $\mathcal{A}$, which does not query the oracle on $x$.
\end{itemize}

\subsection{DDH-DVRF}
\subsection{GLOW-DVRF}
\subsection{Dfinity as DVRF}

\section{Sequential Proof of Work}
A modification to Proof of Work (PoW) where the nonce-incrementing portion of its typical mining process is replaced by an iteratively sequential function (such as Sloth \cite{lenstra2015random} or VDF, though we focus on the VDF case here for convenience), Sequential Proof of Work (SeqPoW) \cite{han2020randchain} is a variant of PoW that prevents parallel computing. It can be described by the following tuple of algorithms.
\begin{itemize}
\item $Setup(\lambda, T, \tau) \rightarrow pp$ outputs public parameters $pp$ given security parameter $\lambda$, time step parameter $T$ (which each iteration of $Solve$ would invoke), and difficulty level $\tau$ (to check if a proposed solution is indeed a solution a la PoW).
\item $Gen(pp) \rightarrow (sk, pk)$ is a randomized algorithm outputting a node's secret key $sk$ and a public key $pk$.
\item $Init(pp, sk, x) \rightarrow (S_0, \pi_0)$ outputs initial proposed solution $S_0$ and proof $\pi_0$ given input $x \in X$ and secret key $sk$. Some constructions may use $pk$ in place of $sk$. This also applies to $Solve$.
\item $Solve(pp, sk, S_i) \rightarrow (S_{i + 1}, b_{i + 1})$ outputs $(i + 1)$-th proposed solution $S_{i + 1}$ and result $b_{i + 1} \in \{0, 1\}$ (where $b_{i + 1} = 1$ if the proposed solution is indeed a solution such that $S_{i + 1}$ solves the SeqPoW puzzle with difficulty level $\tau$) via computation of a VDF for $T$ steps given $S_i$ and $sk$ as inputs. This algorithm is the one that conceptually corresponds to the nonce-incrementing portion of solving PoW. Whereas one can choose any nonces and respectively start incrementing them in parallel to find a solution to the PoW puzzle, SeqPoW prevents parallelism due to the nature of VDFs.
\item $Prove(pp, i, S_0, S_i) \rightarrow \pi_i$ outputs a VDF proof $\pi_i$ for computing $S_i$ from $S_0$ in $i \cdot T$ steps.
\item $Verify(pp, pk, i, S_0, S_i, \pi_i) \rightarrow \{0, 1\}$ outputs 1 if $S_i$ passes the VDF verification test with $\pi_i$ and is a valid solution to the SeqPoW puzzle with difficulty level $\tau$. The algorithm outputs 0 otherwise.
\end{itemize}

Note the recursive nature of the $Solve$ algorithm such that a successful mining procedure (i.e. finding a solution to the SeqPoW puzzle with difficulty level $\tau$) would involve iterating it on the initial solution seed $S_0$ until $S_i$ is discovered where $(S_i, 1) = Solve(pp, sk, S_{i - 1})$. In other words, it is expected that most instances of $Solve(pp, sk, S_j)$ would yield $(\cdot, 0)$ and that one would have to perform $Solve(pp, sk, S_{j + 1})$ in that case, a process that is not parallelizable.

The difference between SeqPoW and Proofs of Sequential Work (PoSW) \cite{mahmoody2013publicly,cohen2018simple} is that the miner performs $Solve$ for a randomized number of times in SeqPoW as opposed to for a fixed one. For instance, it is possible to successfully mine and find a solution to the SeqPoW puzzle by performing $Solve$ only once, which would not be the case in PoSW (unless we consider its trivial case).

Furthermore, SeqPoW should satisfy the following four properties.
\begin{enumerate}
\item Completeness. Conforming to the mining process of SeqPoW involving iterations of $Solve$ on the initial seed $S_0$ until discovery of a solution should yield an output accepted by the $Verify$ algorithm. In other words:
\begingroup\makeatletter\def\f@size{8}\check@mathfonts
\[
Pr\left[\begin{array}{l}Verify(pp, pk, i,\\S_0, S_i, \pi_i) = 1\end{array} \middle\vert \begin{array}{l}
pp \leftarrow Setup(\lambda, T, \tau);\\
(sk, pk) \leftarrow Gen(pp);\\
(S_0, \pi_0) \leftarrow Init(pp, sk, x);\\
(S_j, b_j) \leftarrow Solve(pp, sk, S_{j - 1})\\
\phantom{(S_j, b_j) XY} \forall j \in [1, i];\\
b_i = 1;\\
\pi_i \leftarrow Prove(pp, i, S_0, S_i)
\end{array}\right] = 1
\]\endgroup
\item Soundness. An output $(S_i, \pi_i)$ obtained otherwise should be rejected by the $Verify$ algorithm except with negligible probability.
\item Hardness. Each attempt of $Solve$ produces a valid solution with probability $\frac{1}{\tau}$. In other words:
\begingroup\makeatletter\def\f@size{8}\check@mathfonts
\[
Pr\left[b_{i + 1} = 1 \middle\vert \begin{array}{l}
(S_{i + 1}, b_{i + 1}) \leftarrow Solve(pp, sk, S_i)
\end{array}\right] \leq \frac{1}{\tau} + negl(\lambda)
\]\endgroup
\item Sequentiality. The notion of $\sigma$-sequentiality \cite{boneh2018verifiable} is satisfied such that a parallel algorithm $\mathcal{A}$ using at most $poly(\lambda)$ processors and running in time $\sigma(T)$ cannot compute the $Solve$ algorithm except with negligible probability.
\end{enumerate}

\begin{definition}[Distributed verifiable random function]
A distributed verifiable random function (DVRF) is a VRF where multiple nodes cooperate to yield an output in a way that tolerates up to threshold $t$ number of Byzantine nodes such that any $t + 1$ honest nodes are able to yield a DVRF output. Naturally, it should satisfy VRF's properties of provability, uniqueness, and pseudorandomness. Requiring a couple extra steps due to the fact that some nodes can be Byzantine and contribute wrong values to the protocol, it requires the following tuple of algorithms.
\begin{itemize}
\item $DKG(1^\lambda, t, n) \rightarrow (sk_i, pk_i, pk)$ outputs the $i$-th node's secret key, its public key (e.g. $pk_i = g^{sk_i}$), and a global public key $pk$ (e.g. $pk = g^{sk}$) given security parameter $1^\lambda$, total number of nodes $n$, and threshold parameter $t$.
\item $PartialEval(sk_i, x) \rightarrow (y_i, \pi_i)$ outputs the partial evaluation $y_i$ as well as its proof of correctness $\pi_i$ given an input $x$ and a node's secret key $sk_i$.
\item $PartialVerify(pk_i, x, y_i, \pi_i) \rightarrow \{0, 1\}$ verifies the correctness of the partial evaluation $y_i$ given its proof $\pi_i$, an input $x$, and a node's public key $pk_i$.
\item $Combine(A, \{(y_i, \pi_i)\}_{i \in A}) \rightarrow (y, \pi)$ outputs the DVRF evaluation $y$ as well as its proof of correctness $\pi$ given a set $A$ of $t + 1$ nodes and their outputs of $PartialEval(sk_i, x)$, all of which pass the $PartialVerify(pk_i, x, y_i, \pi_i)$ test such that $PartialVerify(pk_i, x, y_i, \pi_i)$ returns 1.
\item $Verify(pk, \{pk_i\}, x, y, \pi) \rightarrow \{0, 1\}$ verifies the correctness of the DVRF evaluation $y$ given $\pi$, input $x$, and public keys.
\end{itemize}

Furthermore, a DVRF satisfies the following properties (some of which are inherited from what a VRF should satisfy).
\begin{itemize}
\item Provability (Robustness). If $(y, \pi)$ is output by the $Combine$ algorithm, then it is accepted by the $Verify$ algorithm.
\item Uniqueness. There does not exist $(y_1, \pi_1) \neq (y_2, \pi_2)$ such that $Verify(pk, \{pk_i\}, x, y_1, \pi_1) = Verify(pk, \{pk_i\}, x, y_2, \pi_2) = 1$.
\item Pseudorandomness. An adversary corrupting $t$ nodes cannot distinguish a DVRF output from a uniformly random value except with negligible probability.
\item Consistency. $Combine(A, \{(y_i, \pi_i)\}_{i \in A})$ should yield the same $y$ for any set $A$ involving $t + 1$ nodes whose outputs of $PartialEval(sk_i, x)$ are accepted by $PartialVerify(pk_i, x, y_i, \pi_i)$.
\end{itemize}
\end{definition}

\section{Other Cryptographic Primitives}
\subsection{Commitment Scheme}
\label{appendix:commitment}
A cryptographic commitment \cite{blum1983coin} to message $m$ can be abstractly seen as a secure box (locked with a padlock) whose content is $m$. Initially, the sender $P$ commits to $m$ by putting it inside the box, locking it, and sending it to the receiver $V$ such that $P$ can later open the commitment (i.e. reveal $m$ to $V$) by sending $V$ the key that unlocks the padlock. These two messages can be represented by the following.
\begin{enumerate}
\item $C = \mathsf{Com}(m, r)$ is a commitment to message $m$ with fresh randomness $r$.
\item $\mathsf{Open}(m, r)$ reveals the opening information necessary to verify the validity of $C$ with respect to $m$ and $r$.
\end{enumerate}

Obviously, such secure box needs to be secure, satisfying the following two properties.
\begin{itemize}
\item \textit{Binding property} requires that it is not possible for $P$ to change $m$ after $\mathsf{Com}(m, r)$ is given to $V$.
\item \textit{Hiding property} requires that it is not possible for $V$ to learn $m$ before $\mathsf{Open}(m, r)$ is given to $V$ by $P$.
\end{itemize}

For further details (e.g. perfectly vs computationally binding and hiding), refer to \cite{damgaard1998commitment}.

\subsection{Lagrange Interpolation}
\label{appendix:lagrange}
Given a non-empty reconstruction set $A \subset \mathbb{Z}_q$, the \textit{Lagrange basis polynomials} are given by $\lambda_{j, A}(x) = \prod_{k \in A \setminus \{j\}} \frac{x - k}{j - k} \in \mathbb{Z}_q[X]$ such that the \textit{Lagrange coefficients} $\lambda_{i, j, A} = \lambda_{j, A}(i) \in \mathbb{Z}_q$ enable the equality $p(i) = \sum_{j \in A} p(j) \lambda_{i, j, A}$ for any polynomial $p \in \mathbb{Z}_q[X]$ of degree at most $|A| - 1$. The process of computing this equality is called \textit{Lagrange interpolation}.

\subsection{BLS Signature}
Introduced by Boneh, Lynn, and Shacham in 2003, the BLS signature scheme \cite{boneh2001short} consists of the following tuple of algorithms given a key pair ($sk$, $pk$).
\begin{enumerate}
\item $Sign_{sk}(m) \rightarrow H_1(m)^{sk}$ outputs a digital signature $\sigma = H_1(m)^{sk}$ given secret key $sk$ and message $m$ where $H_1$ is a hash function such that $H_1: \{0, 1\}^* \rightarrow \mathbb{G}_1$.
\item $Verify_{pk}(m, \sigma) \rightarrow \{0, 1\}$ verifies a signature given signature $\sigma$, message $m$, and public key $pk$. The test checks the equality $e(\sigma, g_2) = e(H_1(m), pk)$.
\end{enumerate}
Note that BLS uses a bilinear pairing $e: \mathbb{G}_1 \times \mathbb{G}_2 \rightarrow \mathbb{G}_T$ with $\mathbb{G}_1 = \langle g_1 \rangle$, $\mathbb{G}_2 = \langle g_2 \rangle$, $\mathbb{G}_T$ denoting a cyclic group of prime order $q$, and the following requirements.
\begin{itemize}
\item Bilinearity. $e(g_1^x, g_2^y) = e(g_1, g_2)^{x y}$ for all $x, y \in \mathbb{Z}^*_q$.
\item Non-degeneracy. $e(g_1, g_2) \neq 1$.
\item Computability. $e(g_1, g_2)$ can be efficiently computed.
\end{itemize}

\subsection{NIZK of Discrete Logarithm Equality (DLEQ)}
\label{appendix:dleq}
Also known as the Chaum-Pedersen protocol \cite{chaum1992wallet}, the $\Sigma$ protocol for proving that the two discrete logarithms are equal without revealing the discrete logarithm value itself can be turned into a NIZK by applying the Fiat-Shamir heuristic \cite{fiat1986prove}. Namely, the prover can non-interactively prove the knowledge of $\alpha$ such that $(h_1, h_2) = (g_1^\alpha, g_2^\alpha)$ via $\pi_{DLEQ} = DLEQ(g_1, h_1, g_2, h_2)$ with group elements in $\mathbb{G}_q$ of prime order $q$.\\

\noindent\underline{$DLEQ(g_1, h_1, g_2, h_2)$}\\
\textit{Input:} $g_1, h_1, g_2, h_2 \in \mathbb{G}_q$, $\alpha \in \mathbb{Z}_q$\\
\textit{Output:} $\pi = (e, s)$
\begin{enumerate}
\item $A_1 = g_1^w, A_2 = g_2^w$ for $w \xleftarrow{R} \mathbb{Z}_q$
\item $e = H(h_1, h_2, A_1, A_2)$
\item $s = w - \alpha \cdot e \pmod q$
\item $\pi = (e, s)$
\end{enumerate}

\noindent\underline{$DLEQ\text{-}Verify(g_1, h_1, g_2, h_2, \pi)$}\\
\textit{Input:} $g_1, h_1, g_2, h_2 \in \mathbb{G}_q$, $\pi = (e, s)$\\
\textit{Output:} $b \in \{0, 1\}$
\begin{enumerate}
\item $A'_1 = g_1^s h_1^e, A'_2 = g_2^s h_2^e$
\item $e' = H(h_1, h_2, A'_1, A'_2)$
\item $b = \begin{cases}
1 & \text{if $e' = e$}\\
0 & \text{otherwise}
\end{cases}$
\end{enumerate}

\subsection{NIZK of Correct ElGamal Encryption (CE)}
\label{appendix:ce}
Via $\pi_{CE} = CE(G, Q, A, B)$ \cite{cherniaeva2019homomorphic} where $G \in \mathbb{G}_q$ of prime order $q$ and $(Q, A, B) = (x G, r G, m G + r Q)$, the prover can non-interactively prove the knowledge of $(m, r)$ and thus prove the legitimacy of an ElGamal encryption (e.g. as opposed to exploiting its malleability). Note that the additive notation is used to reflect the usage of points on an elliptic curve.\\

\noindent\underline{$CE(G, Q, A, B)$}\\
\textit{Input:} $G, Q, A, B \in \mathbb{G}_q$, $m, r \in \mathbb{Z}_q$\\
\textit{Output:} $\pi = (e, z_1, z_2)$
\begin{enumerate}
\item $T = s_1 G + s_2 Q, E = s_2 G$ for $s_1, s_2 \xleftarrow{R} \mathbb{Z}_q$
\item $e = H(A, B, T, E)$
\item $z_1 = s_1 + m \cdot e \pmod q, z_2 = s_2 + r \cdot e \pmod q$
\item $\pi = (e, z_1, z_2)$
\end{enumerate}

\noindent\underline{$CE\text{-}Verify(G, Q, A, B, \pi)$}\\
\textit{Input:} $G, Q, A, B \in \mathbb{G}_q$, $\pi = (e, z_1, z_2)$\\
\textit{Output:} $b \in \{0, 1\}$
\begin{enumerate}
\item $T' = z_1 G + z_2 Q - e B, E' = z_2 G - e A$
\item $e' = H(A, B, T', E')$
\item $b = \begin{cases}
1 & \text{if $e' = e$}\\
0 & \text{otherwise}
\end{cases}$
\end{enumerate}

\begin{table*}[pt]
\caption{Subset-Based DRB Protocols}
\label{table:subset-based}
\begin{tabular}{@{}lllll@{}}
                                          &                          &            & \multicolumn{2}{l}{Step 2: Beacon Output Generation}                  \\
                                          &                          &            & Fresh per-node entropy & $\mathcal{O}_{r - 1}$ \& precommitted per-node entropy \\
\multirow{6}{*}{Step 1: Subset Selection} & \multirow{3}{*}{Public}  & RR         & BRandPiper             &                                              \\
                                          &                          & RS         & Ouroboros              & HydRand, GRandPiper                          \\
                                          &                          & LS         & RandHound, SPURT       &                                              \\
                                          & \multirow{3}{*}{Private} & VRF        & NV                     & Praos, Algorand                              \\
                                          &                          & Hash chain &                        & Caucus                                       \\
                                          &                          & SeqPoW     &                        & RandChain                                   
\end{tabular}
\end{table*}

\begin{table*}[pt]
% \footnotesize
\begin{threeparttable}
\scriptsize
\caption{DRB Comparison}
\label{table:comparison}
\begin{tabularx}{\textwidth}{@{}l*{20}c}
\toprule
\spheading{} & \spheading{Section\\(from paper)} & \spheading{Cryptographic Primitive}   & \spheading{Fault Tolerance (less than)}  & \spheading{Independent Participation}  & \spheading{Per-Round Entropy Provider}  & \spheading{Unpredictability}  & \spheading{Immunity to Withholding}  & \spheading{Adaptive Security}   & \spheading{Verifier Complexity}  & \multicolumn{2}{c}{\spheading{Communication Complexity}}  &  \spheading{Damage}  & \spheading{Recovery Cost}\\ 
\cmidrule(lr){11-12}
 & & & & & & & & & & Optimistic & Worst & & \\
\toprule
Commit-Reveal & \hyperref[subsection:commit-reveal]{2} & Commitment  &  1  & \cmark   & All   &  \xmark  & \xmark    & \cmark   & $O(n)$  & $O(n^3)$   & $O(n^3)$  & Bias & $O(1)$ \\ 
\midrule
Unicorn++ & \multirow{3}{*}{\ref{section:vdf}} & VDF  & $n$   & \cmark   & All   & 1   & \cmark    & \cmark   & $O(n)$  & $O(n^3)$   & $O(n^3)$  & None & $O(1)$ \\ 
Ext. Beacon+VDF &  & VDF  &  $n$  & \cmark  & External   & 1   & \cmark    & \cmark   & $O(1)$  &  $O(n)$  & $O(n)$  & None & $O(1)$ \\ 
RandRunner &  & Trapdoor VDF  & $n$   & \xmark   & None   & $t$   & \cmark    & \xmark   & $O(\log T)$  & $O(n^2)$   & $O(n^2)$  & Predict & $O(n^3)$ \\ 
\midrule
RANDAO & \multirow{2}{*}{\ref{section:commit-reveal-punish}} & Commitment  & $n$   & \cmark    & All   & 1   & \cmark    & \cmark   & $O(n)$  & $O(n)$   & $O(n)$  & Halt & $O(n)$ \\ 
EVR &  & Escrow-DKG & $n/3$   & \xmark   & All   & 1   & \cmark    & \cmark   & $O(n^3)$  & $O(n^2)$   & $O(n^3)$  & Halt & $O(n)$ \\ 
\midrule
Scrape & \multirow{5}{*}{\ref{section:commit-reveal-recover}} & PVSS  & $n/2$   & \xmark   & All   & 1   & \cmark    & \cmark   & $O(n^2)$  & $O(n^3)$   & $O(n^4)$  & Predict & $O(n^2)$ \\ 
Albatross &  & PVSS & $n/2$   & \xmark   & All   & 1   & \cmark    & \cmark   & $O(n^2)$  & $O(n)$   & $O(n^2)$  & Predict & $O(n^2)$ \\ 
RandShare &  & PVSS & $n/3$   & \xmark   & All   & 1   & \cmark    & \cmark   & $O(n^3)$  & $O(n^3)$   & $O(n^4)$  & Predict & $O(1)$ \\ 
SecRand &  & PVSS &  $n/2$  & \xmark   & All   & 1   & \cmark    & \cmark   & $O(n^2)$  & $O(n^3)$   & $O(n^4)$  & Predict & $O(n^2)$ \\ 
HERB &  & Thr. ElGamal & $n/3$   & \xmark   & All   & 1   & \cmark    & \cmark   & $O(n)$  & $O(n^3)$   & $O(n^3)$  & Predict & $O(n^3)$ \\ 
\midrule
HydRand & \multirow{11}{*}{\ref{section:subset-based}} & PVSS & $n/3$   & \xmark   & Leader   & $t$   & \cmark    & \xmark   & $O(n)$  & $O(n^2)$   & $O(n^3)$  & Bias & $O(n^2)$ \\ 
GRandPiper &  & PVSS  & $n/2$   & \xmark   & Leader   & $t$   & \cmark    & \xmark   & $O(n^2)$  & $O(n^2)$   & $O(n^2)$  & Bias & $O(n^2)$ \\ 
BRandPiper &  & PVSS  & $n/2$   & \xmark   & Leader   & 1   & \cmark    & \xmark   & $O(n^2)$  & $O(n^2)$   & $O(n^3)$  & Predict & $O(n^2)$ \\ 
Ouroboros &  & PVSS & $n/2$   & \xmark   & Subset   & 1   & \cmark    & \xmark   & $O(n^3)$  & $O(n^4)$   & $O(n^4)$  & Bias & $O(n^2)$ \\ 
RandHound &  & PVSS & $n/3$   & \xmark   & Subset   & 1   & \xmark    & \xmark   & $O(c^2 n)$  & $O(c^2n)$   & $O(c^2n)$  & Bias & $O(n^2)$ \\ 
SPURT &  & PVSS  & $n/3$   & \xmark   & Subset   & 1   & \cmark    & \cmark   & $O(n)$  & $O(n^2)$   & $O(n^2)$  & Bias & $O(n^2)$ \\ 
Algorand &  & VRF  & $n/3$   & \cmark    & Leader   & $t$   & \xmark    & \cmark   & $O(1)$  & $O(cn)$   & $O(cn)$  & Bias & $O(n^2)$ \\ 
Ouroboros Praos &  & VRF & $n/2$   & \cmark    & Subset   & 1   & \xmark    & \cmark   & $O(1)$  & $O(n)$   & $O(n)$  & Bias & $O(n^2)$ \\ 
Caucus &  & Hash chain &  $n/2$  & \cmark    & Leader   & $t$   & \xmark    & \cmark   & $O(1)$  & $O(n^2)$   & $O(n^2)$  & Bias & $O(n^3)$ \\ 
NV &  & VRF, (thr.) ElGamal &  $n$  & \xmark   & Subset   & $1$   & \xmark    & \xmark   & $O(n)$  & $O(n^3)$   & $O(n^3)$  & Bias & $O(n^2)$ \\ 
RandChain &  & SeqPoW &  $n/3$  & \cmark    & Leader   &  1  & \xmark    & \cmark   & $O(1)$  & $O(n)$   & $O(n)$  & Bias &  $O(1)$\\ 
\midrule
drand & \multirow{4}{*}{\ref{section:dvrf}} & Thr. BLS & $n/2$   & \xmark   & None   & 1   & \cmark    & \cmark   & $O(1)$  & $O(n^2)$   & $O(n^2)$  & Predict & $O(n^3)$ \\ 
RandHerd &  & Thr. Schnorr & $n/3$   & \xmark   & None   & 1   & \xmark    & \xmark   & $O(1)$  & $O(c^2 \log n)$   & $O(n^3)$  & Bias & $O(n^3)$ \\ 
DDH-DVRF &  & DDH-based DVRF  & $n/2$ & \xmark   & None   & 1   & \cmark    & \cmark   & $O(1)$  & $O(n^2)$   & $O(n^2)$  & Predict & $O(n^3)$ \\ 
GLOW-DVRF &  & Pairing-based DVRF  & $n/2$ & \xmark   & None   & 1   & \cmark    & \cmark   & $O(1)$  & $O(n^2)$   & $O(n^2)$  & Predict & $O(n^3)$ \\ 
\bottomrule
\end{tabularx}
% \footnotesize
\begin{tablenotes}
\item $c$ is the size of shards in RandHerd and RandHound and the size of committee in Algorand. Unlike Algorand, $c$ in RandHound/RandHerd depends on $n$ and is not constant.
\end{tablenotes}
\end{threeparttable}
\end{table*}

\end{document}