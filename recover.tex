%!TEX root = main.tex

\section{Commit-Reveal-Recover}
\label{section:commit-reveal-recover}
Without using escrow to enforce desired behavior, \textit{commit-reveal-recover} variants defend against the last-revealer attack by providing a mechanism to \textit{recover} or \textit{reconstruct} a participant's entropy contribution if withheld.
This can be achieved by either \textit{threshold secret sharing} or \textit{threshold encryption}.
Protocols based on commit-reveal-recover assume a $t$-limited adversary and require the cooperation of at least $t + 1$ nodes to reconstruct such that two desirable properties are achieved simultaneously: there is no need for all $n$ nodes to reveal while any subset of $t$ Byzantine nodes cannot collude to preemptively reconstruct.
Note that this creates an inherent trade-off: while a smaller value of $t$ helps tolerate more honest faults, it also means that a smaller subset can collude to predict the beacon output in advance.

\subsection{From Threshold Secret Sharing}
Commit-reveal-recover variants often use \emph{publicly verifiable secret sharing} (PVSS)~\cite{schoenmakers1999simple, cascudo2017scrape} as a subprotocol in order to allow any external party (not just the participants) to verify the correctness of sharing and reconstruction.

\begin{definition}[Publicly verifiable secret sharing]
\textit{Publicly verifiable secret sharing} (PVSS) is a VSS with the following additional algorithms to enable public verification: $\mathsf{PVSS.KeyGen}$ (which generates secret-public key pair per participant), $\mathsf{PVSS.Enc}$ (for public-key encryption), and $\mathsf{PVSS.Dec}$ (decryption).
The idea is that $\mathsf{PVSS.ShareGen}$ uses above to encrypt and decrypt PVSS shares and also to generate public proofs, e.g. non-interactive zero-knowledge (NIZK) proofs.
Then $\mathsf{PVSS.ShareVerify}$ can be run by anyone (not just the participants).
See Appendix~\ref{appendix:pvss} for details.
\end{definition}

The idea in these commit-reveal-recover variants is that each participant generates a secret (i.e. entropy contribution), distributes PVSS shares to each other participant, and receives $n$ respective shares of $n$ other participants' secrets. These shares are then used to compute $\drboutput_\epochv$ via Lagrange interpolation\footnote{In this paper, we assume one Lagrange interpolation at a protocol level incurs $O(n^2)$ and $O(n^3)$ communication cost (bitwise) in the optimistic and worst cases, respectively.} ($\mathsf{PVSS.Recon}$) in case some nodes withhold. Based on when and how such Lagrange interpolation takes place, we subdivide the protocols into the following categories: commit-reveal-recover, share-reconstruct-aggregate, and share-aggregate-reconstruct.

\subsubsection{Commit-Reveal-Recover}
Extending commit-reveal, \textit{commit-reveal-recover} adds a step to the commit phase where every participant is additionally required to distribute PVSS shares of its corresponding secret so that others can reconstruct it via Lagrange interpolation (\textit{recover}) if withheld. The trade-off is additional communication cost, which amplifies if $O(n)$ Lagrange interpolations need to take place. Scrape~\cite{cascudo2017scrape} adopts this technique.

\noindent\textbf{Scrape.} With its own PVSS scheme~\cite{cascudo2017scrape} designed for efficiency, Scrape runs as follows after the initial generation ($\mathsf{PVSS.KeyGen}$) of $(sk_i, pk_i)$ for each of the $n$ nodes.
\begin{enumerate}
\item \textbf{Commit.} Every node $P_j$ runs $\mathsf{PVSS.ShareGen}(s^{(j)})$ as a dealer and publishes the encrypted shares $\mathsf{Enc}(pk_i, s^{(j)}_i)$ for $i \in [n]$ and encryption proofs. $P_j$ also publishes a commitment to the secret exponent $\mathsf{Com}(s^{(j)}, r_j)$ (with fresh randomness $r_j$). Upon receiving encrypted shares and proofs, all nodes run $\mathsf{PVSS.ShareVerify}$ to verify correct encryption. Let $\committee_\epochv$ be the set of nodes with published commitments and valid shares.
\item \textbf{Reveal.} Once $t + 1$ nodes have distributed their commitments and valid shares, every node $P_j$, $j \in \committee_\epochv$, opens its commitment by revealing $(s^{(j)}, r_j)$.
\item \textbf{Recover.} For every node $P_a \in \committee_\epochv$ that withholds $(s^{(a)}, r_a)$ in Reveal, other nodes $P_j$ for $j \neq a$ reconstruct $h^{s^{(a)}}$ via $\mathsf{PVSS.Recon}$, which requires each node to publish its decrypted share $h^{s_j^{(a)}}$ and the proof of correct decryption passing $\mathsf{PVSS.ShareVerify}$.
\item \textbf{Aggregate.} The final randomness is $\drboutput_\epochv = \prod_{j \in \committee_\epochv} h^{s^{(j)}}$.
\end{enumerate}

Note that Scrape, in the optimistic case (without Recover), is just a commit-reveal with $O(n^2)$ PVSS shares distributed in the network during commit, $O(n)$ per node. In the worst case (with Recover), it requires an entirely new round of communication and potentially $O(n)$ Lagrange interpolations.

\noindent\textbf{Albatross.} Extending Scrape, Albatross~\cite{cascudo2020albatross} provides an improved amortized communication complexity of $O(n)$ per beacon output by generating a batch of $O(n^2)$ beacon outputs per \epoch (as opposed to one).
This is achieved by two techniques: packed Shamir secret sharing and linear $t$-resilient functions~\cite{cascudo2020albatross}.
As packed Shamir secret sharing allows sharing of $O(n)$ secrets (as opposed to one) per instance while linear $t$-resilient functions allow outputting of $O(n)$ values (as opposed to one) in the final randomness aggregation step, each of these techniques multiplicatively contributes $O(n)$ to the number of beacon outputs produced per \epoch.

\subsubsection{Share-Reconstruct-Aggregate}
Another approach is to skip the commit-reveal phase and by default reconstruct each secret shared via PVSS. In other words, all nodes can distribute their PVSS shares (\textit{share}), perform Lagrange interpolation per secret for a total of $O(n)$ times (\textit{reconstruct}), and aggregate the interpolated secrets to output $\drboutput_\epochv$ (\textit{aggregate}). While the resulting \textit{share-reconstruct-aggregate} saves a round of communication (Reveal) from Scrape's worst case, its average case does incur substantial communication cost due to $O(n)$ Lagrange interpolations, each of which requires cooperation of $t + 1$ nodes. Hence, this approach is preferable when it can be assumed that most \epochs will require recovery due to faulty participants. RandShare~\cite{syta2017scalable} uses this technique.

\subsubsection{Share-Aggregate-Reconstruct}
Another alternative is to harness the homomorphic property of PVSS, due to which only one, as opposed to $O(n)$, Lagrange interpolation reconstructs $\drboutput_\epochv$ if nodes perform \textit{aggregate} before \textit{reconstruct}, hence \textit{share-aggregate-reconstruct}. SecRand~\cite{guo2020secRand} uses this technique to reduce communication overhead accordingly.

\subsection{From Threshold Encryption}
While protocols based on threshold secret sharing can incur high communication cost of $O(n^4)$ due to $O(n)$ Lagrange interpolations, protocols relying on a different cryptographic primitive, namely threshold encryption~\cite{desmedt1990Threshold} (which does not rely on PVSS), offer a variant where only one Lagrange interpolation suffices even in the worst case. Though reminiscent of share-aggregate-reconstruct, these protocols differ in that they require a DKG, which may be run multiple times to refresh keys. In this section, we summarize how a protocol like HERB~\cite{cherniaeva2019homomorphic} uses threshold encryption to construct a DRB.

The main idea is simple: $n$ participating nodes run a DKG, encrypt their respective entropy contributions under the group public key $pk$, homomorphically combine all ciphertexts into one group ciphertext, and jointly (requiring at least $t + 1$ nodes) decrypt the group ciphertext via one Lagrange interpolation. Effectively, the DKG is what makes this possible, as it allows the usage of $sk$ (to decrypt a ciphertext under $pk$) without knowing it (recall from Definition~\ref{def:dkg}).

% \begin{definition}[$(t, n)$-threshold encryption]
% A \textit{$(t, n)$-threshold encryption} scheme uses DKG among $n$ nodes as a subroutine and allows encryption of a message under the resulting group public key $pk$ such that the message can be decrypted by any $t + 1$ of the $n$ nodes, but not less. The scheme ($\mathsf{ThrEnc}$) is composed of the following algorithms.
% \begin{itemize}
%     \item $\mathsf{DKG}(1^\lambda, t, n) \rightarrow (sk_i, pk_i, pk)$ runs a typical DKG.
%     \item $\mathsf{Enc}(pk, m) \rightarrow c$ encrypts message $m$ with group public key $pk$ and outputs ciphertext $c$.
%     \item $\mathsf{DecShare}(sk_i, c) \rightarrow d_i$ generates decryption share $d_i$ for ciphertext $c$ using individual secret key $sk_i$.
%     \item $\mathsf{Rec}(A, c, pk, \{pk_i\}_{i \in A}, \{d_i\}_{i \in A}) \rightarrow m$ takes ciphertext $c$, $pk$, and a set $A$ of $t + 1$ nodes with valid decryption shares along with their individual public keys and recovers the message $m$ via Lagrange interpolation.
% \end{itemize}
% \end{definition}

% HERB uses threshold ElGamal encryption~\cite{desmedt1990Threshold, fouque2001threshold} (see Appendix~\ref{appendix:thrElGamal} for details) though it can be replaced with any other threshold homomorphic encryption scheme. After an initial DKG ($\mathsf{ThrEnc.DKG}$), the protocol proceeds in two phases. In the first phase, nodes play the role of \textit{entropy providers} each offering some entropy contribution to generate a group ciphertext. In the second phase, nodes play the role of \textit{key holders} to perform decryption via Lagrange interpolation. While entropy providers and key holders could technically be different nodes, we assume they are the same below.

% \begin{enumerate}
%     \item \textbf{Publication.} Each entropy provider $P_j$ encrypts its entropy contribution $m_j$ using $\mathsf{ThrEnc.Enc}$ to generate a ciphertext share $c_j$, published along with a proof of correct encryption $\pi_{CE}^{(j)}$ (Appendix~\ref{appendix:ce}) to account for malleability~\cite{dolev2003nonmalleable}. When $\committee_\epochv$ (the agreed set of nodes with verified published $c_j$'s) reaches a certain size (based on system parameters), the included $c_j$'s are summed into group ciphertext $c$ corresponding to group plaintext $m$ (which is in turn a sum of $m_j$'s).
%     \item \textbf{Disclosure.} Each key holder $P_i$ uses $\mathsf{ThrEnc.DecShare}$ to generate a decryption share $d_i$, published along with a proof of correct decryption $\pi_{DLEQ}^{(i)}$ (Appendix~\ref{appendix:dleq}). When $t + 1$ decryption shares are published and verified, nodes use $\mathsf{ThrEnc.Rec}$ to output $\drboutput_\epochv = m$.
% \end{enumerate}

HERB achieves a communication complexity of $O(n^2)$ and $O(n^3)$ in the optimistic and worst cases, respectively. Its requirement of DKG in the setup presents a caveat however, as a new DKG must take place for any attempt to refresh keys of participants, e.g. in case of a suspected hack or a simple \textit{reconfiguration} (in which the set of participants changes). This can incur additional cost per DKG.
% On the flip side, HERB provides the advantage that entropy providers need not be key holders (as noted before), meaning that the level of security and randomness quality can be adjusted independently if necessary.
