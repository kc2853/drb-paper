%!TEX root = main.tex

\section{Commit-Reveal-Recover}
\label{section:commit-reveal-recover}
Without an escrow to enforce desired behaviors, commit-reveal-recover variants extend commit-reveal and defend against the last-revealer attack by providing a mechanism to \textit{recover} or \textit{reconstruct} a participant's entropy contribution if withheld. This can be achieved by either threshold secret sharing or threshold encryption. Protocols based on commit-reveal-recover assume a $t$-limited adversary and require the cooperation of at least $t + 1$ nodes to reconstruct such that two desirable properties are achieved simultaneously: there is no need for all $n$ nodes to reveal while any subset of $t$ Byzantine nodes cannot collude to preemptively reconstruct. Note that there is an inherent tradeoff here: while a smaller value of $t$ provides greater fault tolerance, it also means that a smaller subset can collude to predict the beacon output in advance.
% "greater honest fault tolerance"

\subsection{From Threshold Secret Sharing}
Building on $(t, n)$-secret sharing, commit-reveal-recover variants based on threshold secret sharing often use PVSS (publicly verifiable secret sharing)~\cite{schoenmakers1999simple, cascudo2017scrape} as a subprotocol in order to allow any external party (not just the participants) to verify the correctness of sharing and reconstruction.

\begin{definition}[Publicly verifiable secret sharing]
\textit{Publicly verifiable secret sharing} (PVSS) is a VSS with the following additional functionalities that enable public verification: $\mathsf{PVSS.KeyGen}$ (which generates secret-public key pair per participant), $\mathsf{PVSS.Enc}$ (for public-key encryption), and $\mathsf{PVSS.Dec}$ (decryption).
The idea is that $\mathsf{PVSS.ShareGen}$ uses above to encrypt and decrypt PVSS shares and also to generate public proofs, e.g. NIZK (non-interactive zero-knowledge) proofs.
Then $\mathsf{PVSS.ShareVerify}$ can be run by anyone (not just the participants).
See Appendix~\ref{appendix:pvss} for details.
\end{definition}

The idea in these commit-reveal-recover variants is that each participant generates a secret (i.e. entropy contribution), distributes PVSS shares to each other participant, and receives $n$ respective shares of $n$ other participants' secrets. These shares are then used to compute $\drboutput_\epochv$ via Lagrange interpolation ($\mathsf{PVSS.Recon}$) in case some nodes withhold. Based on when and how such Lagrange interpolation takes place, we subdivide the protocols into the following categories: commit-reveal-recover, share-reconstruct-aggregate, and share-aggregate-reconstruct.

\subsubsection{Commit-Reveal-Recover}
Extending commit-reveal, \textit{commit-reveal-recover} adds another step to the commit phase where every participant is additionally required to distribute PVSS shares of its corresponding secret so that others can reconstruct it via Lagrange interpolation (\textit{recover}) if withheld during reveal. The tradeoff is additional communication cost, which could be amplified multiplicatively in the recover phase if $O(n)$ Lagrange interpolations need to take place. Scrape~\cite{cascudo2017scrape} adopts this technique.\\

\noindent\textbf{Scrape.} With its own PVSS scheme~\cite{cascudo2017scrape} designed for efficiency, Scrape runs as follows after the initial generation ($\mathsf{PVSS.KeyGen}$) of $(sk_i, pk_i)$ for each of the $n$ nodes.
\begin{enumerate}
\item \textbf{Commit.} Every node $P_j$ runs $\mathsf{PVSS.ShareGen}(s^{(j)})$ as a dealer and publishes the encrypted shares $\mathsf{Enc}(pk_i, s^{(j)}_i)$ for $i \in [n]$ and encryption proofs. $P_j$ also publishes a commitment to the secret exponent $\mathsf{Com}(s^{(j)}, r_j)$ (with fresh randomness $r_j$). Upon receiving encrypted shares and proofs, all nodes run $\mathsf{PVSS.ShareVerify}$ to verify correct encryption. Let $\committee_\epochv$ be the set of nodes with published commitments and valid shares.
\item \textbf{Reveal.} Once $t + 1$ nodes have distributed their commitments and valid shares, every node $P_j$, $j \in \committee_\epochv$, opens its commitment by revealing $(s^{(j)}, r_j)$.
\item \textbf{Recover.} For every node $P_a \in \committee_\epochv$ that withholds $(s^{(a)}, r_a)$ in Reveal phase, other nodes $P_j$ for $j \neq a$ reconstruct $h^{s^{(a)}}$ via $\mathsf{PVSS.Recon}$, which requires each node to publish its decrypted share $h^{s_j^{(a)}}$ and the proof of correct decryption passing $\mathsf{PVSS.ShareVerify}$.
\item \textbf{Aggregate.} The final randomness is $\drboutput_\epochv = \prod_{j \in \committee_\epochv} h^{s^{(j)}}$.
\end{enumerate}

Note that Scrape, in the optimistic case (without Recover), is just a commit-reveal with $O(n^2)$ PVSS shares distributed in the network during commit, $O(n)$ per node. In the worst case (with Recover), it requires an entirely new round of communication and potentially $O(n)$ Lagrange interpolations.\\

\noindent\textbf{Albatross.} Extending Scrape, Albatross~\cite{cascudo2020albatross} provides an improved amortized communication complexity of $O(n)$ per beacon output by generating a batch of $O(n^2)$ beacon outputs per \epoch (as opposed to one). This is achieved by two techniques: packed Shamir secret sharing and linear $t$-resilient functions~\cite{cascudo2020albatross}, each of which multiplicatively contributes $O(n)$ to the number of beacon outputs produced per \epoch.

\subsubsection{Share-Reconstruct-Aggregate}
Another approach is to skip the commit-reveal phase and by default reconstruct each secret shared via PVSS. In other words, all nodes can distribute their PVSS shares (\textit{share}), perform Lagrange interpolation per secret for a total of $O(n)$ times (\textit{reconstruct}), and aggregate the interpolated secrets to output $\drboutput_\epochv$ (\textit{aggregate}). While the resulting \textit{share-reconstruct-aggregate} saves a round of communication (Reveal) from Scrape's worst case, its average case does incur substantial communication cost due to $O(n)$ Lagrange interpolations, each of which requires cooperation of $t + 1$ nodes. Hence, this approach is preferable when it can be assumed that most \epochs will require recovery due to faulty participants. RandShare~\cite{syta2017scalable} uses this technique.

\subsubsection{Share-Aggregate-Reconstruct}
An alternative is to harness the homomorphic property of PVSS, due to which only one, as opposed to $O(n)$, Lagrange interpolation reconstructs $\drboutput_\epochv$ if nodes perform \textit{aggregate} before \textit{reconstruct}, hence \textit{share-aggregate-reconstruct}. SecRand~\cite{guo2020secRand} uses this technique to reduce the communication complexity by a factor of $n$.

\subsection{From Threshold Encryption}
While protocols based on threshold secret sharing can incur high communication cost of $O(n^4)$ due to $O(n)$ Lagrange interpolations, protocols relying on a different cryptographic primitive, namely threshold encryption~\cite{desmedt1990Threshold}, offer a variant where only one Lagrange interpolation suffices even in the worst case. Though reminiscent of share-aggregate-reconstruct, these protocols differ in that they require a DKG, which may be run multiple times to refresh keys. In this section, we define threshold encryption and summarize how a protocol like HERB~\cite{cherniaeva2019homomorphic} uses it to construct a DRB.

\begin{definition}[$(t, n)$-threshold encryption]
A \textit{$(t, n)$-threshold encryption} scheme uses DKG among $n$ nodes as a subroutine and allows encryption of a message under the resulting group public key $pk$ such that the message can be decrypted by any $t + 1$ of the $n$ nodes, but not less. The scheme ($\mathsf{ThrEnc}$) is composed of the following algorithms.
\begin{itemize}
    \item $\mathsf{DKG}(1^\lambda, t, n) \rightarrow (sk_i, pk_i, pk)$ runs a typical DKG.
    \item $\mathsf{Enc}(pk, m) \rightarrow c$ encrypts message $m$ with group public key $pk$ and outputs ciphertext $c$.
    \item $\mathsf{DecShare}(sk_i, c) \rightarrow d_i$ generates decryption share $d_i$ for ciphertext $c$ using individual secret key $sk_i$.
    \item $\mathsf{Rec}(A, c, pk, \{pk_i\}_{i \in A}, \{d_i\}_{i \in A}) \rightarrow m$ takes ciphertext $c$, $pk$, and a set $A$ of $t + 1$ nodes with valid decryption shares along with their individual public keys and recovers the message $m$ via Lagrange interpolation.
\end{itemize}
\end{definition}

HERB uses threshold ElGamal encryption~\cite{desmedt1990Threshold, fouque2001threshold} (see Appendix~\ref{appendix:thrElGamal} for details) though it can be replaced with any other threshold homomorphic encryption scheme. After an initial DKG ($\mathsf{ThrEnc.DKG}$), the protocol proceeds in two phases. In the first phase, nodes play the role of \textit{entropy providers} each offering some entropy contribution to generate a group ciphertext. In the second phase, nodes play the role of \textit{key holders} to perform decryption via Lagrange interpolation. While entropy providers and key holders could technically be different nodes, we assume they are the same below.

\begin{enumerate}
    \item \textbf{Publication.} Each entropy provider $P_j$ encrypts its entropy contribution $m_j$ using $\mathsf{ThrEnc.Enc}$ to generate a ciphertext share $c_j$, published along with a proof of correct encryption $\pi_{CE}^{(j)}$ (Appendix~\ref{appendix:ce}) to account for malleability~\cite{dolev2003nonmalleable}. When $\committee_\epochv$ (the agreed set of nodes with verified published $c_j$'s) reaches a certain size (based on system parameters), the included $c_j$'s are summed into group ciphertext $c$ corresponding to group plaintext $m$ (which is in turn a sum of $m_j$'s).
    \item \textbf{Disclosure.} Each key holder $P_i$ uses $\mathsf{ThrEnc.DecShare}$ to generate a decryption share $d_i$, published along with a proof of correct decryption $\pi_{DLEQ}^{(i)}$ (Appendix~\ref{appendix:dleq}). When $t + 1$ decryption shares are published and verified, nodes use $\mathsf{ThrEnc.Rec}$ to output $\drboutput_\epochv = m$.
\end{enumerate}

Similar to SecRand's share-aggregate-recover, HERB achieves a communication complexity of $O(n^2)$ and $O(n^3)$ in the optimistic and worst cases, respectively, due to one needed Lagrange interpolation per $\drboutput_\epochv$. Its requirement of DKG in the setup presents a caveat however, as a new DKG must take place for any attempt to refresh keys of participants, e.g. in case of a suspected hack or a simple \textit{reconfiguration} in which the set of participants changes. This can incur additional cost per DKG. On the flip side, HERB provides the advantage that entropy providers need not be key holders (as noted before), meaning that the level of security and randomness quality can be adjusted independently if necessary.
